{
    "huggingface_papers": [
        {
            "Title": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual   Mathematical Reasoning",
            "HF_Link": "https://hf-mirror.com/papers/2508.10433",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10433",
            "Summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across various tasks, but still struggle with complex mathematical reasoning. Existing research primarily focuses on dataset construction and method optimization, often overlooking two critical aspects: comprehensive knowledge-driven design and model-centric data space modeling. In this paper, we introduce We-Math 2.0, a unified system that integrates a structured mathematical knowledge system, model-centric data space modeling, and a reinforcement learning (RL)-based training paradigm to comprehensively enhance the mathematical reasoning abilities of MLLMs. The key contributions of We-Math 2.0 are fourfold: (1) MathBook Knowledge System: We construct a five-level hierarchical system encompassing 491 knowledge points and 1,819 fundamental principles. (2) MathBook-Standard & Pro: We develop MathBook-Standard, a dataset that ensures broad conceptual coverage and flexibility through dual expansion. Additionally, we define a three-dimensional difficulty space and generate 7 progressive variants per problem to build MathBook-Pro, a challenging dataset for robust training. (3) MathBook-RL: We propose a two-stage RL framework comprising: (i) Cold-Start Fine-tuning, which aligns the model with knowledge-oriented chain-of-thought reasoning; and (ii) Progressive Alignment RL, leveraging average-reward learning and dynamic data scheduling to achieve progressive alignment across difficulty levels. (4) MathBookEval: We introduce a comprehensive benchmark covering all 491 knowledge points with diverse reasoning step distributions. Experimental results show that MathBook-RL performs competitively with existing baselines on four widely-used benchmarks and achieves strong results on MathBookEval, suggesting promising generalization in mathematical reasoning.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10433v1"
        },
        {
            "Title": "NextStep-1: Toward Autoregressive Image Generation with Continuous   Tokens at Scale",
            "HF_Link": "https://hf-mirror.com/papers/2508.10711",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10711",
            "Summary": "Prevailing autoregressive (AR) models for text-to-image generation either rely on heavy, computationally-intensive diffusion models to process continuous image tokens, or employ vector quantization (VQ) to obtain discrete tokens with quantization loss. In this paper, we push the autoregressive paradigm forward with NextStep-1, a 14B autoregressive model paired with a 157M flow matching head, training on discrete text tokens and continuous image tokens with next-token prediction objectives. NextStep-1 achieves state-of-the-art performance for autoregressive models in text-to-image generation tasks, exhibiting strong capabilities in high-fidelity image synthesis. Furthermore, our method shows strong performance in image editing, highlighting the power and versatility of our unified approach. To facilitate open research, we will release our code and models to the community.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10711v1"
        },
        {
            "Title": "ToonComposer: Streamlining Cartoon Production with Generative   Post-Keyframing",
            "HF_Link": "https://hf-mirror.com/papers/2508.10881",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10881",
            "Summary": "Traditional cartoon and anime production involves keyframing, inbetweening, and colorization stages, which require intensive manual effort. Despite recent advances in AI, existing methods often handle these stages separately, leading to error accumulation and artifacts. For instance, inbetweening approaches struggle with large motions, while colorization methods require dense per-frame sketches. To address this, we introduce ToonComposer, a generative model that unifies inbetweening and colorization into a single post-keyframing stage. ToonComposer employs a sparse sketch injection mechanism to provide precise control using keyframe sketches. Additionally, it uses a cartoon adaptation method with the spatial low-rank adapter to tailor a modern video foundation model to the cartoon domain while keeping its temporal prior intact. Requiring as few as a single sketch and a colored reference frame, ToonComposer excels with sparse inputs, while also supporting multiple sketches at any temporal location for more precise motion control. This dual capability reduces manual workload and improves flexibility, empowering artists in real-world scenarios. To evaluate our model, we further created PKBench, a benchmark featuring human-drawn sketches that simulate real-world use cases. Our evaluation demonstrates that ToonComposer outperforms existing methods in visual quality, motion consistency, and production efficiency, offering a superior and more flexible solution for AI-assisted cartoon production.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10881v1"
        },
        {
            "Title": "PRELUDE: A Benchmark Designed to Require Global Comprehension and   Reasoning over Long Contexts",
            "HF_Link": "https://hf-mirror.com/papers/2508.09848",
            "Arxiv_Link": "https://arxiv.org/abs/2508.09848",
            "Summary": "We introduce PRELUDE, a benchmark for evaluating long-context understanding through the task of determining whether a character's prequel story is consistent with the canonical narrative of the original book. Our task poses a stronger demand for global comprehension and deep reasoning than existing benchmarks -- as the prequels are not part of the original story, assessing their plausibility typically requires searching and integrating information that is only indirectly related. Empirically, 88% of instances require evidence from multiple parts of the narrative. Experimental results highlight the challenge of our task: in-context learning, RAG and in-domain training with state-of-the-art LLMs, and commercial DeepResearch services, lag behind humans by >15%. A further human study reveals that models often produce correct answers with flawed reasoning, leading to an over 30% gap in reasoning accuracy compared to humans. These findings underscore the substantial room for improvement in long-context understanding and reasoning.",
            "PDF_Link": "http://arxiv.org/pdf/2508.09848v2"
        },
        {
            "Title": "UI-Venus Technical Report: Building High-performance UI Agents with RFT",
            "HF_Link": "https://hf-mirror.com/papers/2508.10833",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10833",
            "Summary": "We present UI-Venus, a native UI agent that takes only screenshots as input based on a multimodal large language model. UI-Venus achieves SOTA performance on both UI grounding and navigation tasks using only several hundred thousand high-quality training samples through reinforcement finetune (RFT) based on Qwen2.5-VL. Specifically, the 7B and 72B variants of UI-Venus obtain 94.1% / 50.8% and 95.3% / 61.9% on the standard grounding benchmarks, i.e., Screenspot-V2 / Pro, surpassing the previous SOTA baselines including open-source GTA1 and closed-source UI-TARS-1.5. To show UI-Venus's summary and planing ability, we also evaluate it on the AndroidWorld, an online UI navigation arena, on which our 7B and 72B variants achieve 49.1% and 65.9% success rate, also beating existing models. To achieve this, we introduce carefully designed reward functions for both UI grounding and navigation tasks and corresponding efficient data cleaning strategies. To further boost navigation performance, we propose Self-Evolving Trajectory History Alignment & Sparse Action Enhancement that refine historical reasoning traces and balances the distribution of sparse but critical actions, leading to more coherent planning and better generalization in complex UI tasks. Our contributions include the publish of SOTA open-source UI agents, comprehensive data cleaning protocols and a novel self-evolving framework for improving navigation performance, which encourage further research and development in the community. Code is available at https://github.com/inclusionAI/UI-Venus.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10833v2"
        },
        {
            "Title": "Puppeteer: Rig and Animate Your 3D Models",
            "HF_Link": "https://hf-mirror.com/papers/2508.10898",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10898",
            "Summary": "Modern interactive applications increasingly demand dynamic 3D content, yet the transformation of static 3D models into animated assets constitutes a significant bottleneck in content creation pipelines. While recent advances in generative AI have revolutionized static 3D model creation, rigging and animation continue to depend heavily on expert intervention. We present Puppeteer, a comprehensive framework that addresses both automatic rigging and animation for diverse 3D objects. Our system first predicts plausible skeletal structures via an auto-regressive transformer that introduces a joint-based tokenization strategy for compact representation and a hierarchical ordering methodology with stochastic perturbation that enhances bidirectional learning capabilities. It then infers skinning weights via an attention-based architecture incorporating topology-aware joint attention that explicitly encodes inter-joint relationships based on skeletal graph distances. Finally, we complement these rigging advances with a differentiable optimization-based animation pipeline that generates stable, high-fidelity animations while being computationally more efficient than existing approaches. Extensive evaluations across multiple benchmarks demonstrate that our method significantly outperforms state-of-the-art techniques in both skeletal prediction accuracy and skinning quality. The system robustly processes diverse 3D content, ranging from professionally designed game assets to AI-generated shapes, producing temporally coherent animations that eliminate the jittering issues common in existing methods.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10898v1"
        },
        {
            "Title": "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer",
            "HF_Link": "https://hf-mirror.com/papers/2508.10893",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10893",
            "Summary": "We present STream3R, a novel approach to 3D reconstruction that reformulates pointmap prediction as a decoder-only Transformer problem. Existing state-of-the-art methods for multi-view reconstruction either depend on expensive global optimization or rely on simplistic memory mechanisms that scale poorly with sequence length. In contrast, STream3R introduces an streaming framework that processes image sequences efficiently using causal attention, inspired by advances in modern language modeling. By learning geometric priors from large-scale 3D datasets, STream3R generalizes well to diverse and challenging scenarios, including dynamic scenes where traditional methods often fail. Extensive experiments show that our method consistently outperforms prior work across both static and dynamic scene benchmarks. Moreover, STream3R is inherently compatible with LLM-style training infrastructure, enabling efficient large-scale pretraining and fine-tuning for various downstream 3D tasks. Our results underscore the potential of causal Transformer models for online 3D perception, paving the way for real-time 3D understanding in streaming environments. More details can be found in our project page: https://nirvanalan.github.io/projects/stream3r.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10893v1"
        },
        {
            "Title": "A Survey on Diffusion Language Models",
            "HF_Link": "https://hf-mirror.com/papers/2508.10875",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10875",
            "Summary": "Diffusion Language Models (DLMs) are rapidly emerging as a powerful and promising alternative to the dominant autoregressive (AR) paradigm. By generating tokens in parallel through an iterative denoising process, DLMs possess inherent advantages in reducing inference latency and capturing bidirectional context, thereby enabling fine-grained control over the generation process. While achieving a several-fold speed-up, recent advancements have allowed DLMs to show performance comparable to their autoregressive counterparts, making them a compelling choice for various natural language processing tasks. In this survey, we provide a holistic overview of the current DLM landscape. We trace its evolution and relationship with other paradigms, such as autoregressive and masked language models, and cover both foundational principles and state-of-the-art models. Our work offers an up-to-date, comprehensive taxonomy and an in-depth analysis of current techniques, from pre-training strategies to advanced post-training methods. Another contribution of this survey is a thorough review of DLM inference strategies and optimizations, including improvements in decoding parallelism, caching mechanisms, and generation quality. We also highlight the latest approaches to multimodal extensions of DLMs and delineate their applications across various practical scenarios. Furthermore, our discussion addresses the limitations and challenges of DLMs, including efficiency, long-sequence handling, and infrastructure requirements, while outlining future research directions to sustain progress in this rapidly evolving field. Project GitHub is available at https://github.com/VILA-Lab/Awesome-DLMs.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10875v1"
        },
        {
            "Title": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of   Large Reasoning Models",
            "HF_Link": "https://hf-mirror.com/papers/2508.10751",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10751",
            "Summary": "Reinforcement learning with verifiable rewards (RLVR), which typically adopts Pass@1 as the reward, has faced the issues in balancing exploration and exploitation, causing policies to prefer conservative actions, converging to a local optimum. Identifying an appropriate reward metric is therefore crucial. Regarding the prior work, although Pass@k has been used in evaluation, its connection to LLM exploration ability in RLVR remains largely overlooked. To investigate this, we first use Pass@k as the reward to train the policy model (i.e., $\\textbf{Pass@k Training}$), and observe the improvement on its exploration ability. Next, we derive an analytical solution for the advantage of Pass@k Training, leading to an efficient and effective process. Building on this, our analysis reveals that exploration and exploitation are not inherently conflicting objectives, while they can mutually enhance each other. Moreover, Pass@k Training with analytical derivation essentially involves directly designing the advantage function. Inspired by this, we preliminarily explore the advantage design for RLVR, showing promising results and highlighting a potential future direction.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10751v1"
        },
        {
            "Title": "HumanSense: From Multimodal Perception to Empathetic Context-Aware   Responses through Reasoning MLLMs",
            "HF_Link": "https://hf-mirror.com/papers/2508.10576",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10576",
            "Summary": "While Multimodal Large Language Models (MLLMs) show immense promise for achieving truly human-like interactions, progress is hindered by the lack of fine-grained evaluation frameworks for human-centered scenarios, encompassing both the understanding of complex human intentions and the provision of empathetic, context-aware responses. Here we introduce HumanSense, a comprehensive benchmark designed to evaluate the human-centered perception and interaction capabilities of MLLMs, with a particular focus on deep understanding of extended multimodal contexts and the formulation of rational feedback. Our evaluation reveals that leading MLLMs still have considerable room for improvement, particularly for advanced interaction-oriented tasks. Supplementing visual input with audio and text information yields substantial improvements, and Omni-modal models show advantages on these tasks. Furthermore, we argue that appropriate feedback stems from a contextual analysis of the interlocutor's needs and emotions, with reasoning ability serving as the key to unlocking it. Accordingly, we employ a multi-stage, modality-progressive reinforcement learning to enhance the reasoning abilities of an Omni model, achieving substantial gains on evaluation results. Additionally, we observe that successful reasoning processes exhibit highly consistent thought patterns. By designing corresponding prompts, we also enhance the performance of non-reasoning models in a training-free manner. Project page: \\textcolor{brightpink}https://digital-avatar.github.io/ai/HumanSense/",
            "PDF_Link": "http://arxiv.org/pdf/2508.10576v1"
        },
        {
            "Title": "Processing and acquisition traces in visual encoders: What does CLIP   know about your camera?",
            "HF_Link": "https://hf-mirror.com/papers/2508.10637",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10637",
            "Summary": "Prior work has analyzed the robustness of visual encoders to image transformations and corruptions, particularly in cases where such alterations are not seen during training. When this occurs, they introduce a form of distribution shift at test time, often leading to performance degradation. The primary focus has been on severe corruptions that, when applied aggressively, distort useful signals necessary for accurate semantic predictions.   We take a different perspective by analyzing parameters of the image acquisition process and transformations that may be subtle or even imperceptible to the human eye. We find that such parameters are systematically encoded in the learned visual representations and can be easily recovered. More strikingly, their presence can have a profound impact, either positively or negatively, on semantic predictions. This effect depends on whether there is a strong correlation or anti-correlation between semantic labels and these acquisition-based or processing-based labels. Our code and data are available at: https://github.com/ryan-caesar-ramos/visual-encoder-traces",
            "PDF_Link": "http://arxiv.org/pdf/2508.10637v1"
        },
        {
            "Title": "From Black Box to Transparency: Enhancing Automated Interpreting   Assessment with Explainable AI in College Classrooms",
            "HF_Link": "https://hf-mirror.com/papers/2508.10860",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10860",
            "Summary": "Recent advancements in machine learning have spurred growing interests in automated interpreting quality assessment. Nevertheless, existing research suffers from insufficient examination of language use quality, unsatisfactory modeling effectiveness due to data scarcity and imbalance, and a lack of efforts to explain model predictions. To address these gaps, we propose a multi-dimensional modeling framework that integrates feature engineering, data augmentation, and explainable machine learning. This approach prioritizes explainability over ``black box'' predictions by utilizing only construct-relevant, transparent features and conducting Shapley Value (SHAP) analysis. Our results demonstrate strong predictive performance on a novel English-Chinese consecutive interpreting dataset, identifying BLEURT and CometKiwi scores to be the strongest predictive features for fidelity, pause-related features for fluency, and Chinese-specific phraseological diversity metrics for language use. Overall, by placing particular emphasis on explainability, we present a scalable, reliable, and transparent alternative to traditional human evaluation, facilitating the provision of detailed diagnostic feedback for learners and supporting self-regulated learning advantages not afforded by automated scores in isolation.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10860v1"
        },
        {
            "Title": "When Explainability Meets Privacy: An Investigation at the Intersection   of Post-hoc Explainability and Differential Privacy in the Context of Natural   Language Processing",
            "HF_Link": "https://hf-mirror.com/papers/2508.10482",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10482",
            "Summary": "In the study of trustworthy Natural Language Processing (NLP), a number of important research fields have emerged, including that of explainability and privacy. While research interest in both explainable and privacy-preserving NLP has increased considerably in recent years, there remains a lack of investigation at the intersection of the two. This leaves a considerable gap in understanding of whether achieving both explainability and privacy is possible, or whether the two are at odds with each other. In this work, we conduct an empirical investigation into the privacy-explainability trade-off in the context of NLP, guided by the popular overarching methods of Differential Privacy (DP) and Post-hoc Explainability. Our findings include a view into the intricate relationship between privacy and explainability, which is formed by a number of factors, including the nature of the downstream task and choice of the text privatization and explainability method. In this, we highlight the potential for privacy and explainability to co-exist, and we summarize our findings in a collection of practical recommendations for future work at this important intersection.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10482v2"
        }
    ],
    "gh_trendings": [
        {
            "url": "https://github.com/coleam00/Archon",
            "language": "Python",
            "description": "Beta release of Archon OS - the knowledge and task management backbone for AI coding assistants.",
            "readme_summary": "<p align=\"center\">\n  <img src=\"./archon-ui-main/public/archon-main-graphic.png\" alt=\"Archon Main Graphic\" width=\"853\" height=\"422\">\n</p>\n\n<p align=\"center\">\n  <em>Power up your AI coding assistants with your own custom knowledge base and task management as an MCP server</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"#quick-start\">Quick Start</a> •\n  <a href=\"#whats-included\">What's Included</a> •\n  <a href=\"#architecture\">Architecture</a>\n</p>\n\n---\n\n## 🎯 What is Archon?\n\n> Archon is currently in beta! Expect things to not work 100%, and please feel free to share any feedback and contribute with fixes/new features! Thank you to everyone for all the excitement we have for Archon already, as well as the bug reports, PRs, and discussions. It's a lot for our small team to get through but we're committed to addressing everything and making Archon into the best tool it possibly can be!\n\nArchon is the **command center** for AI coding assistants. For you, it's a sleek interface to manage knowledge, context, and tasks for your projects. For the AI coding assistant(s), it's a **Model Context Protocol (MCP) server** to collaborate on and leverage the same knowledge, context, and tasks. Connect Claude Code, Kiro, Cursor, Windsurf, etc. to give your AI agents access to:\n\n- **Your documentation** (crawled websites, uploaded PDFs/docs)\n- **Smart search capabilities** with advanced RAG strategies  \n- **Task management** integrated with your knowledge base\n- **Real-time updates** as you add new content and collaborate with your coding assistant on tasks\n- **Much more** coming soon to build Archon into an integrated environment for all context engineering\n\nThis new vision for Archon replaces the old one (the agenteer). Archon used to be the AI agent that builds other agents, and now you can use Archon to do that and more.\n\n> It doesn't matter what you're building or if it's a new/existing codebase - Archon's knowledge and task management capabilities will improve the output of **any** AI driven coding.\n\n## 🔗 Important Links\n\n- **[GitHub Discussions](https://github.com/coleam00/Archon/discussions)** - Join the conversation and share ideas about Archon\n- **[Contributing Guide](CONTRIBUTING.md)** - How to get involved and contribute to Archon\n- **[Introduction Video](https://youtu.be/8pRc_s2VQIo)** - Getting Started Guide and Vision for Archon\n- **[Dynamous AI Mastery](https://dynamous.ai)** - The birthplace of Archon - come join a vibrant community of other early AI adopters all helping each other transform their careers and businesses!\n\n## Quick Start\n\n### Prerequisites\n- [Docker Desktop](https://www.docker.com/products/docker-desktop/)\n- [Supabase](https://supabase.com/) account (free tier or local Supabase both work)\n- [OpenAI API key](https://platform.openai.com/api-keys) (Gemini and Ollama are supported too!)\n\n### Setup Instructions\n\n1. **Clone Repository**:\n   ```bash\n   git clone https://github.com/coleam00/archon.git\n   cd archon\n   ```\n\n2. **Environment Configuration**:\n   ```bash\n   cp .env.example .env\n   # Edit .env and add your Supabase credentials:\n   # SUPABASE_URL=https://your-project.supabase.co\n   # SUPABASE_SERVICE_KEY=your-service-key-here\n   ```\n\n   NOTE: Supabase introduced a new type of service key but use the legacy one (the longer one).\n\n   OPTIONAL: If you want to enable the reranking RAG strategy, uncomment lines 20-22 in `python\\requirements.server.txt`. This will significantly increase the size of the Archon Server container which is why it's off by default.\n\n3. **Database Setup**: In your [Supabase project](https://supabase.com/dashboard) SQL Editor, copy, paste, and execute the contents of `migration/complete_setup.sql`\n\n4. **Start Services**:\n   ```bash\n   docker-compose up --build -d\n   ```\n   \n   This starts the core microservices:\n   - **Server**: Core API and business logic (Port: 8181)\n   - **MCP Server**: Protocol interface for AI clients (Port: 8051)\n   - **Agents (coming soon!)**: AI operations and streaming (Port: 8052)\n   - **UI**: Web interface (Port: 3737)\n\n   Ports are configurable in your .env as well!\n\n5. **Configure API Keys**:\n   - Open http://localhost:3737\n   - Go to **Settings** → Select your LLM/embedding provider and set the API key (OpenAI is default)\n   - Test by uploading a document or crawling a website\n\n## 🔄 Database Reset (Start Fresh if Needed)\n\nIf you need to completely reset your database and start fresh:\n\n<details>\n<summary>⚠️ <strong>Reset Database - This will delete ALL data for Archon!</strong></summary>\n\n1. **Run Reset Script**: In your Supabase SQL Editor, run the contents of `migration/RESET_DB.sql`\n   \n   ⚠️ WARNING: This will delete all Archon specific tables and data! Nothing else will be touched in your DB though.\n\n2. **Rebuild Database**: After reset, run `migration/complete_setup.sql` to create all the tables again.\n\n3. **Restart Services**:\n   ```bash\n   docker-compose up -d\n   ```\n\n4. **Reconfigure**: \n   - Select your LLM/embedding provider and set the API key again\n   - Re-upload any documents or re-crawl websites\n\nThe reset script safely removes all tables, functions, triggers, and policies with proper dependency handling.\n\n</details>\n\n## ⚡ Quick Test\n\nOnce everything is running:\n\n1. **Test Web Crawling**: Go to http://localhost:3737 → Knowledge Base → \"Crawl Website\" → Enter a doc URL (such as https://ai.pydantic.dev/llms-full.txt)\n2. **Test Document Upload**: Knowledge Base → Upload a PDF\n3. **Test Projects**: Projects → Create a new project and add tasks\n4. **Integrate with your AI coding assistant**: MCP Dashboard → Copy connection config for your AI coding assistant\n\n## 📚 Documentation\n\n### Core Services\n\n| Service | Container Name | Default URL | Purpose |\n|---------|---------------|-------------|---------|\n| **Web Interface** | archon-ui | http://localhost:3737 | Main dashboard and controls |\n| **API Service** | archon-server | http://localhost:8181 | Web crawling, document processing |\n| **MCP Server** | archon-mcp | http://localhost:8051 | Model Context Protocol interface |\n| **Agents Service** | archon-agents | http://localhost:8052 | AI/ML operations, reranking |\n\n## What's Included\n\n### 🧠 Knowledge Management\n- **Smart Web Crawling**: Automatically detects and crawls entire documentation sites, sitemaps, and individual pages\n- **Document Processing**: Upload and process PDFs, Word docs, markdown files, and text documents with intelligent chunking\n- **Code Example Extraction**: Automatically identifies and indexes code examples from documentation for enhanced search\n- **Vector Search**: Advanced semantic search with contextual embeddings for precise knowledge retrieval\n- **Source Management**: Organize knowledge by source, type, and tags for easy filtering\n\n### 🤖 AI Integration  \n- **Model Context Protocol (MCP)**: Connect any MCP-compatible client (Claude Code, Cursor, even non-AI coding assistants like Claude Desktop)\n- **10 MCP Tools**: Comprehensive yet simple set of tools for RAG queries, task management, and project operations\n- **Multi-LLM Support**: Works with OpenAI, Ollama, and Google Gemini models\n- **RAG Strategies**: Hybrid search, contextual embeddings, and result reranking for optimal AI responses\n- **Real-time Streaming**: Live responses from AI agents with progress tracking\n\n### 📋 Project & Task Management\n- **Hierarchical Projects**: Organize work with projects, features, and tasks in a structured workflow\n- **AI-Assisted Creation**: Generate project requirements and tasks using integrated AI agents  \n- **Document Management**: Version-controlled documents with collaborative editing capabilities\n- **Progress Tracking**: Real-time updates and status management across all project activities\n\n### 🔄 Real-time Collaboration\n- **WebSocket Updates**: Live progress tracking for crawling, processing, and AI operations\n- **Multi-user Support**: Collaborative knowledge building and project management\n- **Background Processing**: Asynchronous operations that don't block the user interface\n- **Health Monitoring**: Built-in service health checks and automatic reconnection\n\n## Architecture\n\n### Microservices Structure\n\nArchon uses true microservices architecture with clear separation of concerns:\n\n```\n┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n│   Frontend UI   │    │  Server (API)   │    │   MCP Server    │    │ Agents Service  │\n│                 │    │                 │    │                 │    │                 │\n│  React + Vite   │◄──►│    FastAPI +    │◄──►│    Lightweight  │◄──►│   PydanticAI    │\n│  Port 3737      │    │    SocketIO     │    │    HTTP Wrapper │    │   Port 8052     │\n│                 │    │    Port 8181    │    │    Port 8051    │    │                 │\n└─────────────────┘    └─────────────────┘    └─────────────────┘    └─────────────────┘\n         │                        │                        │                        │\n         └────────────────────────┼────────────────────────┼────────────────────────┘\n                                  │                        │\n                         ┌─────────────────┐               │\n                         │    Database     │               │\n                         │                 │               │\n                         │    Supabase     │◄──────────────┘\n                         │    PostgreSQL   │\n                         │    PGVector     │\n                         └─────────────────┘\n```\n\n### Service Responsibilities\n\n| Service | Location | Purpose | Key Features |\n|---------|----------|---------|--------------|\n| **Frontend** | `archon-ui-main/` | Web interface and dashboard | React, TypeScript, TailwindCSS, Socket.IO client |\n| **Server** | `python/src/server/` | Core business logic and APIs | FastAPI, service layer, Socket.IO broadcasts, all ML/AI operations |\n| **MCP Server** | `python/src/mcp/` | MCP protocol interface | Lightweight HTTP wrapper, 10 MCP tools, session management |\n| **Agents** | `python/src/agents/` | PydanticAI agent hosting | Document and RAG agents, streaming responses |\n\n### Communication Patterns\n\n- **HTTP-based**: All inter-service communication uses HTTP APIs\n- **Socket.IO**: Real-time updates from Server to Frontend  \n- **MCP Protocol**: AI clients connect to MCP Server via SSE or stdio\n- **No Direct Imports**: Services are truly independent with no shared code dependencies\n\n### Key Architectural Benefits\n\n- **Lightweight Containers**: Each service contains only required dependencies\n- **Independent Scaling**: Services can be scaled independently based on load\n- **Development Flexibility**: Teams can work on different services without conflicts\n- **Technology Diversity**: Each service uses the best tools for its specific purpose\n\n## 🔧 Configuring Custom Ports & Hostname\n\nBy default, Archon services run on the following ports:\n- **Archon-UI**: 3737\n- **Archon-Server**: 8181  \n- **Archon-MCP**: 8051\n- **Archon-Agents**: 8052\n- **Archon-Docs**: 3838 (optional)\n\n### Changing Ports\n\nTo use custom ports, add these variables to your `.env` file:\n\n```bash\n# Service Ports Configuration\nARCHON_UI_PORT=3737\nARCHON_SERVER_PORT=8181\nARCHON_MCP_PORT=8051\nARCHON_AGENTS_PORT=8052\nARCHON_DOCS_PORT=3838\n```\n\nExample: Running on different ports:\n```bash\nARCHON_SERVER_PORT=8282\nARCHON_MCP_PORT=8151\n```\n\n### Configuring Hostname\n\nBy default, Archon uses `localhost` as the hostname. You can configure a custom hostname or IP address by setting the `HOST` variable in your `.env` file:\n\n```bash\n# Hostname Configuration\nHOST=localhost  # Default\n\n# Examples of custom hostnames:\nHOST=192.168.1.100     # Use specific IP address\nHOST=archon.local      # Use custom domain\nHOST=myserver.com      # Use public domain\n```\n\nThis is useful when:\n- Running Archon on a different machine and accessing it remotely\n- Using a custom domain name for your installation\n- Deploying in a network environment where `localhost` isn't accessible\n\nAfter changing hostname or ports:\n1. Restart Docker containers: `docker-compose down && docker-compose up -d`\n2. Access the UI at: `http://${HOST}:${ARCHON_UI_PORT}`\n3. Update your AI client configuration with the new hostname and MCP port\n\n## 🔧 Development\n\nFor development with hot reload:\n\n```bash\n# Backend services (with auto-reload)\ndocker-compose up archon-server archon-mcp archon-agents --build\n\n# Frontend (with hot reload) \ncd archon-ui-main && npm run dev\n\n# Documentation (with hot reload)\ncd docs && npm start\n```\n\n**Note**: The backend services are configured with `--reload` flag in their uvicorn commands and have source code mounted as volumes for automatic hot reloading when you make changes.\n\n## 📄 License\n\nArchon Community License (ACL) v1.2 - see [LICENSE](LICENSE) file for details.\n\n**TL;DR**: Archon is free, open, and hackable. Run it, fork it, share it - just don't sell it as-a-service without permission.\n"
        },
        {
            "url": "https://github.com/emcie-co/parlant",
            "language": "Python",
            "description": "LLM agents built for control. Designed for real-world use. Deployed in minutes.",
            "readme_summary": "<div align=\"center\">\n\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true\">\n  <img alt=\"Parlant - AI Agent Framework\" src=\"https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentDark.png?raw=true\" width=400 />\n</picture>\n\n<h3>Finally, LLM agents that actually follow instructions</h3>\n\n<p>\n  <a href=\"https://www.parlant.io/\" target=\"_blank\">🌐 Website</a> •\n  <a href=\"https://www.parlant.io/docs/quickstart/installation\" target=\"_blank\">⚡ Quick Start</a> •\n  <a href=\"https://discord.gg/duxWqxKk6J\" target=\"_blank\">💬 Discord</a> •\n  <a href=\"https://www.parlant.io/docs/quickstart/examples\" target=\"_blank\">📖 Examples</a>\n</p>\n\n<p>\n  <a href=\"https://pypi.org/project/parlant/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/parlant?color=blue\"></a>\n  <img alt=\"Python 3.10+\" src=\"https://img.shields.io/badge/python-3.10+-blue\">\n  <a href=\"https://opensource.org/licenses/Apache-2.0\"><img alt=\"License\" src=\"https://img.shields.io/badge/license-Apache%202.0-green\"></a>\n  <a href=\"https://discord.gg/duxWqxKk6J\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1312378700993663007?color=7289da&logo=discord&logoColor=white\"></a>\n  <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/emcie-co/parlant?style=social\">\n</p>\n\n<a href=\"https://trendshift.io/repositories/12768\" target=\"_blank\">\n  <img src=\"https://trendshift.io/api/badge/repositories/12768\" alt=\"Trending on TrendShift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/>\n</a>\n\n</div>\n\n## 🎯 The Problem Every AI Developer Faces\n\nYou build an AI agent. It works great in testing. Then real users start talking to it and...\n\n- ❌ It ignores your carefully crafted system prompts\n- ❌ It hallucinates responses in critical moments\n- ❌ It can't handle edge cases consistently\n- ❌ Each conversation feels like a roll of the dice\n\n**Sound familiar?** You're not alone. This is the #1 pain point for developers building production AI agents.\n\n## ⚡ The Solution: Teach Principles, Not Scripts\n\nParlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, **Parlant guarantees it**.\n\n```python\n# Traditional approach: Cross your fingers 🤞\nsystem_prompt = \"You are a helpful assistant. Please follow these 47 rules...\"\n\n# Parlant approach: Guaranteed compliance ✅\nawait agent.create_guideline(\n    condition=\"Customer asks about refunds\",\n    action=\"Check order status first to see if eligible\",\n    tools=[check_order_status],\n)\n```\n\n<div align=\"center\">\n\n## 🚀 Get Your Agent Running in 60 Seconds\n\n</div>\n\n```bash\npip install parlant\n```\n\n```python\nimport parlant.sdk as p\n\n@p.tool\nasync def get_weather(context: p.ToolContext, city: str) -> p.ToolResult:\n    # Your weather API logic here\n    return p.ToolResult(f\"Sunny, 72°F in {city}\")\n\nasync def main():\n    async with p.Server() as server:\n        agent = await server.create_agent(\n            name=\"WeatherBot\",\n            description=\"Helpful weather assistant\"\n        )\n\n        # Define behavior with natural language\n        await agent.create_guideline(\n            condition=\"User asks about weather\",\n            action=\"Get current weather and provide a friendly response with suggestions\",\n            tools=[get_weather]\n        )\n\n        # 🎉 Test playground ready at http://localhost:8800\n        # Integrate the official React widget into your app,\n        # or follow the tutorial to build your own frontend!\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n```\n\n**That's it!** Your agent is running with guaranteed rule-following behavior.\n\n## 🎬 See It In Action\n\n<img alt=\"Parlant Demo\" src=\"https://github.com/emcie-co/parlant/blob/develop/docs/demo.gif?raw=true\" width=\"100%\" />\n\n## 🔥 Why Developers Are Switching to Parlant\n\n<table width=\"100%\">\n<tr>\n  <td width=\"50%\">\n\n### 🏗️ **Traditional AI Frameworks**\n\n  </td>\n  <td width=\"50%\">\n\n### ⚡ **Parlant**\n\n  </td>\n</tr>\n<tr>\n<td width=\"50%\">\n\n- Write complex system prompts\n- Hope the LLM follows them\n- Debug unpredictable behaviors\n- Scale by prompt engineering\n- Cross fingers for reliability\n\n</td>\n<td width=\"50%\">\n\n- Define rules in natural language\n- **Guaranteed** rule compliance\n- Predictable, consistent behavior\n- Scale by adding guidelines\n- Production-ready from day one\n\n</td>\n</tr>\n</table>\n\n## 🎯 Perfect For Your Use Case\n\n<div align=\"center\">\n\n|  **Financial Services**  |     **Healthcare**      |       **E-commerce**        |       **Legal Tech**       |\n| :----------------------: | :---------------------: | :-------------------------: | :------------------------: |\n| Compliance-first design  |   HIPAA-ready agents    |  Customer service at scale  |   Precise legal guidance   |\n| Built-in risk management | Patient data protection | Order processing automation | Document review assistance |\n\n</div>\n\n## 🛠️ Enterprise-Grade Features\n\n- **🧭 Conversational Journeys** - Lead the customer step-by-step to a goal\n- **🎯 Dynamic Guideline Matching** - Context-aware rule application\n- **🔧 Reliable Tool Integration** - APIs, databases, external services\n- **📊 Conversation Analytics** - Deep insights into agent behavior\n- **🔄 Iterative Refinement** - Continuously improve agent responses\n- **🛡️ Built-in Guardrails** - Prevent hallucination and off-topic responses\n- **📱 React Widget** - [Drop-in chat UI for any web app](https://github.com/emcie-co/parlant-chat-react)\n- **🔍 Full Explainability** - Understand every decision your agent makes\n\n## 📈 Join 5,000+ Developers Building Better AI\n\n<div align=\"center\">\n\n**Companies using Parlant in production:**\n\n_Financial institutions • Healthcare providers • Legal firms • E-commerce platforms_\n\n[![Star History Chart](https://api.star-history.com/svg?repos=emcie-co/parlant&type=Date)](https://star-history.com/#emcie-co/parlant&Date)\n\n</div>\n\n## 🏃‍♂️ Quick Start Paths\n\n<table border=\"0\">\n<tr>\n<td><strong>🎯 I want to test it myself</strong></td>\n<td><a href=\"https://www.parlant.io/docs/quickstart/installation\">→ 5-minute quickstart</a></td>\n</tr>\n<tr>\n<td><strong>🛠️ I want to see an example</strong></td>\n<td><a href=\"https://www.parlant.io/docs/quickstart/examples\">→ Healthcare agent example</a></td>\n</tr>\n<tr>\n<td><strong>🚀 I want to get involved</strong></td>\n<td><a href=\"https://discord.gg/duxWqxKk6J\">→ Join our Discord community</a></td>\n</tr>\n</table>\n\n## 🌟 What Developers Are Saying\n\n> _\"By far the most elegant conversational AI framework that I've come across! Developing with Parlant is pure joy.\"_ **— Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase**\n\n## 🤝 Community & Support\n\n- 💬 **[Discord Community](https://discord.gg/duxWqxKk6J)** - Get help from the team and community\n- 📖 **[Documentation](https://parlant.io/docs/quickstart/installation)** - Comprehensive guides and examples\n- 🐛 **[GitHub Issues](https://github.com/emcie-co/parlant/issues)** - Bug reports and feature requests\n- 📧 **[Direct Support](https://parlant.io/contact)** - Direct line to our engineering team\n\n## 📄 License\n\nApache 2.0 - Use it anywhere, including commercial projects.\n\n---\n\n<div align=\"center\">\n\n**Ready to build AI agents that actually work?**\n\n⭐ **Star this repo** • 🚀 **[Try Parlant now](https://parlant.io/)** • 💬 **[Join Discord](https://discord.gg/duxWqxKk6J)**\n\n_Built with ❤️ by the team at [Emcie](https://emcie.co)_\n\n</div>\n"
        },
        {
            "url": "https://github.com/DataExpert-io/data-engineer-handbook",
            "language": "Jupyter Notebook",
            "description": "This is a repo with links to everything you'd ever want to learn about data engineering",
            "readme_summary": "# The Data Engineering Handbook\n<a href=\"https://trendshift.io/repositories/8755\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/8755\" alt=\"DataExpert-io%2Fdata-engineer-handbook | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\nThis repo has all the resources you need to become an amazing data engineer!\n\n## Getting started\n\nIf you are new to data engineering, start by following this [2024 breaking into data engineering roadmap](https://blog.dataengineer.io/p/the-2024-breaking-into-data-engineering)\n\nIf you are here for the [6-week free YouTube boot camp](https://youtu.be/myhe0LXpCeo) you can check out\n- [introduction](bootcamp/introduction.md)\n- [software needed](bootcamp/software.md)\n\n\nFor more applied learning:\n- Check out the [projects](projects.md) section for more hands-on examples!\n- Check out the [interviews](interviews.md) section for more advice on how to pass data engineering interviews!\n- Check out the [books](books.md) section for a list of high quality data engineering books\n- Check out the [communities](communities.md) section for a list of high quality data engineering communities to join\n- Check out the [newsletter](newsletters.md) section to learn via email \n\n\n## Resources\n\n### Great [list of over 25 books](books.md)\n\nTop 3 must read books are:\n- [Fundamentals of Data Engineering](https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302/)\n- [Designing Data-Intensive Applications](https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321/)\n- [Designing Machine Learning Systems](https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969)\n\n### Great [list of over 10 communities to join](communities.md):\n\nTop must-join communities for DE:\n- [DataExpert.io Community Discord](https://discord.gg/JGumAXncAK)\n- [Data Talks Club Slack](https://datatalks.club/slack)\n- [Data Engineer Things Community](https://www.dataengineerthings.org/)\n\nTop must-join communities for ML:\n- [AdalFlow Discord](https://discord.com/invite/ezzszrRZvT)\n- [Chip Huyen MLOps Discord](https://discord.gg/dzh728c5t3)\n\n### Companies:\n\n- Orchestration  \n  - [Mage](https://www.mage.ai)\n  - [Astronomer](https://www.astronomer.io)\n  - [Prefect](https://www.prefect.io)\n  - [Dagster](https://www.dagster.io)\n  - [Airflow](https://airflow.apache.org/)\n  - [Kestra](https://kestra.io/) \n  - [Shipyard](https://www.shipyardapp.com/)\n  - [Hamilton](https://github.com/dagworks-inc/hamilton)\n- Data Lake / Cloud\n  - [Tabular](https://www.tabular.io)\n  - [Microsoft](https://www.microsoft.com)\n  - [Databricks](https://www.databricks.com/company/about-us)\n  - [Onehouse](https://www.onehouse.ai)\n  - [Delta Lake](https://delta.io/)\n  - [Ilum](https://ilum.cloud/)\n  - [DuckLake](https://ducklake.select/)\n  - [Apache Iceberg](https://iceberg.apache.org/)\n  - [Apache Polaris](https://polaris.apache.org/)\n  - [Lakekeeper](https://lakekeeper.io/)\n- Data Warehouse\n  - [Snowflake](https://www.snowflake.com/en/)\n  - [Firebolt](https://www.firebolt.io/)\n  - [Databend](https://www.databend.com/)\n- Data Quality\n  - [dbt](https://www.getdbt.com/)\n  - [Metaplane](https://www.metaplane.dev/)\n  - [Gable](https://www.gable.ai)\n  - [Great Expectations](https://www.greatexpectations.io)\n  - [Streamdal](https://streamdal.com)\n  - [Coalesce](https://coalesce.io/)\n  - [Soda](https://www.soda.io/)\n  - [DQOps](https://dqops.com/)\n  - [HEDDA.IO](https://hedda.io)\n  - [Dingo](https://github.com/MigoXLab/dingo)\n- Education Companies\n  - [DataExpert.io](https://www.dataexpert.io)\n  - [LearnDataEngineering.com](https://www.learndataengineering.com)\n  - [AlgoExpert](https://www.algoexpert.io)\n  - [ByteByteGo](https://www.bytebytego.com)\n- Analytics / Visualization\n  - [Preset](https://www.preset.io)\n  - [Starburst](https://www.starburst.io)\n  - [Metabase](https://www.metabase.com/)\n  - [Looker Studio](https://lookerstudio.google.com/overview)\n  - [Tableau](https://www.tableau.com/)\n  - [Power BI](https://powerbi.microsoft.com/)\n  - [Hex](https://hex.ai/)\n  - [Apache Superset](https://superset.apache.org/)\n  - [Evidence](https://evidence.dev)\n  - [Redash](https://redash.io/)\n  - [Lightdash](https://lightdash.com/)\n- Data Integration\n  - [Cube](https://cube.dev)\n  - [Fivetran](https://www.fivetran.com)\n  - [Airbyte](https://airbyte.io)\n  - [dlt](https://dlthub.com/)\n  - [Sling](https://slingdata.io/)\n  - [Meltano](https://meltano.com/)\n  - [Estuary](https://estuary.dev/)\n- Semantic Layers\n  - [Cube](https://cube.dev)\n  - [dbt Semantic Layer](https://www.getdbt.com/product/semantic-layer) \n- Modern OLAP\n  - [Apache Druid](https://druid.apache.org/)\n  - [ClickHouse](https://clickhouse.com/)\n  - [Apache Pinot](https://pinot.apache.org/)\n  - [Apache Kylin](https://kylin.apache.org/)\n  - [DuckDB](https://duckdb.org/)\n  - [QuestDB](https://questdb.io/)\n  - [StarRocks](https://www.starrocks.io/)\n- LLM application library\n  - [AdalFlow](https://github.com/SylphAI-Inc/AdalFlow)\n  - [LangChain](https://github.com/langchain-ai/langchain)\n  - [LlamaIndex](https://github.com/run-llama/llama_index)\n- Real-Time Data\n  - [Aggregations.io](https://aggregations.io)\n  - [Responsive](https://www.responsive.dev/)\n  - [RisingWave](https://risingwave.com/)\n  - [Striim](https://www.striim.com/)\n- Data Lineage\n  - [OpenLineage](https://openlineage.io/)\n\n\n### Data Engineering blogs of companies:\n\n- [Netflix](https://netflixtechblog.com/tagged/big-data)\n- [Uber](https://www.uber.com/blog/houston/data/?uclick_id=b2f43229-f3f4-4bae-bd5d-10a05db2f70c)\n- [Databricks](https://www.databricks.com/blog/category/engineering/data-engineering)\n- [Airbnb](https://medium.com/airbnb-engineering/data/home)\n- [Amazon AWS Blog](https://aws.amazon.com/blogs/big-data/)\n- [Microsoft Data Architecture Blogs](https://techcommunity.microsoft.com/t5/data-architecture-blog/bg-p/DataArchitectureBlog)\n- [Microsoft Fabric Blog](https://blog.fabric.microsoft.com/)\n- [Oracle](https://blogs.oracle.com/datawarehousing/)\n- [Meta](https://engineering.fb.com/category/data-infrastructure/)\n- [Onehouse](https://www.onehouse.ai/blog)\n- [Estuary Blog](https://estuary.dev/blog/)\n\n### Data Engineering Whitepapers:\n\n- [A Five-Layered Business Intelligence Architecture](https://ibimapublishing.com/articles/CIBIMA/2011/695619/695619.pdf)\n- [Lakehouse:A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics](https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf)\n- [Big Data Quality: A Data Quality Profiling Model](https://link.springer.com/chapter/10.1007/978-3-030-23381-5_5)\n- [The Data Lakehouse: Data Warehousing and More](https://arxiv.org/abs/2310.08697)\n- [Spark: Cluster Computing with Working Sets](https://dl.acm.org/doi/10.5555/1863103.1863113)\n- [The Google File System](https://research.google/pubs/the-google-file-system/)\n- [Building a Universal Data Lakehouse](https://www.onehouse.ai/whitepaper/onehouse-universal-data-lakehouse-whitepaper)\n- [XTable in Action: Seamless Interoperability in Data Lakes](https://arxiv.org/abs/2401.09621)\n- [MapReduce: Simplified Data Processing on Large Clusters](https://research.google/pubs/mapreduce-simplified-data-processing-on-large-clusters/)\n- [Tidy Data](https://vita.had.co.nz/papers/tidy-data.pdf)\n- [Data Engineering Whitepapers](https://www.ssp.sh/brain/data-engineering-whitepapers/)\n\n### Social Media Accounts\n\nHere's the mostly comprehensive list of data engineering creators: \n**(You have to have at least 5k followers somewhere to be added!)**\n\n\n#### YouTube \n| Name                        | YouTube Channel                                                                                         | Follower Count |\n|----------------------------|---------------------------------------------------------------------------------------------------------|---------------:|\n| ByteByteGo                 | [ByteByteGo](https://www.youtube.com/c/ByteByteGo)                                             | 1,000,000+     |\n| Zach Wilson                | [Data with Zach](https://www.youtube.com/@eczachly_)                                          | 150,000+       |\n| Shashank Mishra            | [E-learning Bridge](https://www.youtube.com/@shashank_mishra)                                   | 100,000+       |\n| Seattle Data Guy           | [Seattle Data Guy](https://www.youtube.com/c/SeattleDataGuy)                                  | 100,000+       |\n| TrendyTech                 | [TrendyTech](https://www.youtube.com/c/TrendytechInsights)                                   | 100,000+       |\n| Darshil Parmar             | [Darshil Parmar](https://www.youtube.com/@DarshilParmar)                                       | 100,000+       |\n| Andreas Kretz              | [Andreas Kretz](https://www.youtube.com/c/andreaskayy)                                          | 100,000+       |\n| The Ravit Show             | [The Ravit Show](https://youtube.com/@theravitshow)                                           | 100,000+       |\n| Guy in a Cube              | [Guy in a Cube](https://www.youtube.com/@GuyInACube)                                            | 100,000+       |\n| Adam Marczak               | [Adam Marczak](https://www.youtube.com/@AdamMarczakYT)                                         | 100,000+       |\n| nullQueries                | [nullQueries](https://www.youtube.com/@nullQueries)                                             | 100,000+       |\n| TECHTFQ by Thoufiq         | [TECHTFQ by Thoufiq](https://www.youtube.com/@techTFQ)                                         | 100,000+       |\n| SQLBI                       | [SQLBI](https://www.youtube.com/@SQLBI)                                                     | 100,000+       |\n| Alex Freberg               | [Alex The Analyst](https://www.youtube.com/@AlexTheAnalyst)                                     | 100,000+       |\n| Ankur Ranjan               | [Big Data Show](https://www.youtube.com/@TheBigDataShow)                                        | 100,000+       |\n| Prashanth Kumar Pandey     | [ScholarNest](https://www.youtube.com/@ScholarNest)                                              | 77,000+        |\n| ITVersity                  | [ITVersity](https://www.youtube.com/@itversity)                                                  | 67,000+        |\n| Soumil Shah                | [Soumil Shah](https://www.youtube.com/@SoumilShah)                                               | 50,000         |\n| Ansh Lamba                 | [Ansh Lamba](https://www.youtube.com/@AnshLambaJSR)                                              | 18,000+        |\n| Azure Lib                  | [Azure Lib](https://www.youtube.com/@azurelib-academy)                                        | 10,000+        |\n| Advancing Analytics        | [Advancing Analytics](https://www.youtube.com/@AdvancingAnalytics)                               | 10,000+        |\n| Kahan Data Solutions       | [Kahan Data Solutions](https://www.youtube.com/@KahanDataSolutions)                               | 10,000+        |\n| Ankit Bansal               | [Ankit Bansal](https://youtube.com/@ankitbansal6)                                               | 10,000+        |\n| Mr. K Talks Tech           | [Mr. K Talks Tech](https://www.youtube.com/channel/UCzdOan4AmF65PmLLks8Lmww)                      | 10,000+        |\n| Samuel Focht               | [Python Basics](https://www.youtube.com/@PythonBasics)                                           | 10,000+        |\n| Mehdi Ouazza              | [Mehdio DataTV](https://www.youtube.com/@mehdio)                                                    | 3,000+         |\n| Alex Merced                | [Alex Merced Data](https://www.youtube.com/@alexmerceddata_)                                            | N/A           |\n| John Kutay                 | [John Kutay](https://www.youtube.com/@striiminc) | N/A           |\n| Emil Kaminski              | [Databricks For Professionals](https://www.youtube.com/@DatabricksPro)                           | 5,000+          |\n\n\n#### LinkedIn\n\n| Name                      | LinkedIn Profile                                                                                         | Follower Count |\n|--------------------------|----------------------------------------------------------------------------------------------------------|---------------:|\n| Zach Wilson              | [Zach Wilson](https://www.linkedin.com/in/eczachly)                                                     | 400,000+       |\n| Chip Huyen               | [Chip Huyen](https://www.linkedin.com/in/chiphuyen/)                                    | 250,000+       |\n| Shashank Mishra          | [Shashank Mishra](https://www.linkedin.com/in/shashank219/)                                     | 100,000+       |\n| Seattle Data Guy         | [Ben Rogojan](https://www.linkedin.com/in/benjaminrogojan)                                        | 100,000+       |\n| TrendyTech               | [Sumit Mittal](https://www.linkedin.com/in/bigdatabysumit/)                                   | 100,000+       |\n| Darshil Parmar           | [Darshil Parmar](https://www.linkedin.com/in/darshil-parmar/)                                   | 100,000+       |\n| Andreas Kretz            | [Andreas Kretz](https://www.linkedin.com/in/andreas-kretz)                                     | 100,000+       |\n| ByteByteGo (Alex Xu)     | [Alex Xu](https://www.linkedin.com/in/alexxubyte)                                             | 100,000+       |\n| Azure Lib (Deepak Goyal) | [Deepak Goyal](https://www.linkedin.com/in/deepak-goyal-93805a17/)                              | 100,000+       |\n| Alex Freberg             | [Alex Freberg](https://www.linkedin.com/in/alex-freberg/)                                     | 100,000+       |\n| SQLBI (Marco Russo)      | [Marco Russo](https://www.linkedin.com/in/sqlbi)                                                  | 50,000+        |\n| Ankit Bansal             | [Ankit Bansal](https://www.linkedin.com/in/ankitbansal6/)                                        | 50,000+        |\n| Marc Lamberti            | [Marc Lamberti](https://www.linkedin.com/in/marclamberti)                                       | 50,000+        |\n| Ankur Ranjan             | [Ankur Ranjan](https://www.linkedin.com/in/thebigdatashow/)                                       | 48,000+        |\n| ITVersity (Durga Gadiraju)| [Durga Gadiraju](https://www.linkedin.com/in/durga0gadiraju/)                                   | 48,000+        |\n| Prashanth Kumar Pandey   | [Prashanth Kumar Pandey](https://www.linkedin.com/in/prashant-kumar-pandey/)                       | 37,000+        |\n| Alex Merced              | [Alex Merced](https://www.linkedin.com/in/alexmerced)                                           | 30,000+        |\n| Ijaz Ali                 | [Ijaz Ali](https://www.linkedin.com/in/ijaz-ali-6aaa87122/)                                       | 24,000+        |\n| Mehdi Ouazza             | [Mehdi Ouazza](https://www.linkedin.com/in/mehd-io/)                                        | 20,000+        |\n| Ananth Packkildurai      | [Ananth Packkildurai](https://www.linkedin.com/in/ananthdurai/)                                    | 18,000+        |\n| Ansh Lamba               | [Ansh Lamba](https://www.linkedin.com/in/ansh-lamba-793681184/)                                    | 13,000+        |\n| Manojkumar Vadivel       | [Manojkumar Vadivel](https://www.linkedin.com/in/manojvsj/)                                        | 12,000+        |\n| Advancing Analytics      | [Simon Whiteley](https://www.linkedin.com/in/simon-whiteley-uk/)                                  | 10,000+        |\n| Li Yin                   | [Li Yin](https://www.linkedin.com/in/li-yin-ai/)                                                  | 10,000+        |\n| Jaco van Gelder          | [Jaco van Gelder](https://www.linkedin.com/in/jwvangelder/)                                       | 10,000+        |\n| Joseph Machado           | [Joseph Machado](https://www.linkedin.com/in/josephmachado1991/)                                  | 10,000+        |\n| Eric Roby                | [Eric Roby](https://www.linkedin.com/in/codingwithroby/)                                           | 10,000+        |\n| Simon Späti              | [Simon Späti](https://www.linkedin.com/in/sspaeti/)                                            | 10,000+        |\n| Constantin Lungu         | [Constantin Lungu](https://www.linkedin.com/in/constantin-lungu-668b8756)                         | 10,000+        |\n| Lakshmi Sontenam         | [Lakshmi Sontenam](https://www.linkedin.com/in/shivaga9esh)                                      | 9,500+         |\n| Dani Pálma               | [Daniel Pálma](https://www.linkedin.com/in/danthelion/)                                          | 9,000+         |\n| Soumil Shah              | [Soumil Shah](https://www.linkedin.com/in/shah-soumil/)                                          | 8,000+         |\n| Arnaud Milleker          | [Arnaud Milleker](https://www.linkedin.com/in/arnaudmilleker/)                                    | 7,000+         |\n| Dimitri Visnadi          | [Dimitri Visnadi](https://www.linkedin.com/in/visnadi/)                                    | 7,000+         |\n| Lenny                    | [Lenny A](https://www.linkedin.com/in/lennyardiles/)                                         | 6,000+         |\n| Dipankar Mazumdar        | [Dipankar Mazumdar](https://www.linkedin.com/in/dipankar-mazumdar/)                                 | 5,000+         |\n| Daniel Ciocirlan         | [Daniel Ciocirlan](https://www.linkedin.com/in/danielciocirlan)                                    | 5,000+         |\n| Hugo Lu                  | [Hugo Lu](https://www.linkedin.com/in/hugo-lu-confirmed/)                                           | 5,000+         |\n| Tobias Macey             | [Tobias Macey](https://www.linkedin.com/in/tmacey)                                                 | 5,000+         |\n| Marcos Ortiz             | [Marcos Ortiz](https://www.linkedin.com/in/mlortiz)                                             | 5,000+         |\n| Julien Hurault           | [Julien Hurault](https://www.linkedin.com/in/julienhuraultanalytics/)                               | 5,000+         |\n| John Kutay               | [John Kutay](https://www.linkedin.com/in/johnkutay/)                                               | 5,000+         |\n| Hassaan Akbar            | [Hassaan Akbar](https://www.linkedin.com/in/ehassaan)                                              | 5,000+         |\n| Subhankar                | [Subhankar](https://www.linkedin.com/in/subhankarumass/)                                            | 5,000+         |\n| Nitin                    | [Nitin](https://www.linkedin.com/in/tomernitin29/)                                                        | N/A           |\n| Hassaan                    | [Hassaan](https://www.linkedin.com/in/shassaan/)                                                        | 5000+           |\n| Javier de la Torre             | [Javier](www.linkedin.com/in/javier-de-la-torre-medina)                                                        | 5000+           |\n\n\n#### X/Twitter\n\n| Name              | X/Twitter Profile                                                 | Follower Count |\n|-------------------|------------------------------------------------------------------|---------------:|\n| ByteByteGo        | [alexxubyte](https://twitter.com/alexxubyte/)            | 100,000+       |\n| Dan Kornas        | [@dankornas](https://www.twitter.com/dankornas)           | 66,000+        |\n| Zach Wilson       | [EcZachly](https://www.twitter.com/EcZachly)          | 30,000+        |\n| Seattle Data Guy  | [SeattleDataGuy](https://www.twitter.com/SeattleDataGuy)   | 10,000+        |\n| SQLBI             | [marcorus](https://x.com/marcorus)                       | 10,000+        |\n| Joseph Machado    | [startdataeng](https://twitter.com/startdataeng)         | 5,000+         |\n| Alex Merced       | [@amdatalakehouse](https://www.twitter.com/amdatalakehouse)      | N/A           |\n| John Kutay        | [@JohnKutay](https://x.com/JohnKutay)                            | N/A           |\n| Mehdi Ouazza      | [mehd_io](https://x.com/mehd_io)                                 | N/A           |\n\n\n#### Instagram\n\n| Name           | Instagram Profile                                                                   | Follower Count |\n|----------------|--------------------------------------------------------------------------------------|---------------:|\n| Sundas Khalid  | [sundaskhalidd](https://www.instagram.com/sundaskhalidd)                              | 300,000+       |\n| Zach Wilson    | [eczachly](https://www.instagram.com/eczachly)                             | 150,000+       |\n| Andreas Kretz  | [learndataengineering](https://www.instagram.com/learndataengineering)          | 5,000+         |\n| Alex Merced    | [@alexmercedcoder](https://www.instagram.com/alexmercedcoder)                       | N/A           |\n\n#### TikTok\n\n| Name            | TikTok Profile                                                                   | Follower Count |\n|-----------------|----------------------------------------------------------------------------------|---------------:|\n| Zach Wilson     | [@eczachly](https://www.tiktok.com/@eczachly)                            | 70,000+        |\n| Alex Freberg    | [@alex_the_analyst](https://www.tiktok.com/@alex_the_analyst)             | 10,000+        |\n| Mehdi Ouazza    | [@mehdio_datatv](https://www.tiktok.com/@mehdio_datatv)                          | N/A           |\n\n\n### Great Podcasts\n\n- [The Data Engineering Show](https://www.dataengineeringshow.com/)\n- [Data Engineering Podcast](https://www.dataengineeringpodcast.com/)\n- [DataTopics](https://www.datatopics.io/)\n- [The Data Engineering Side Of Data](https://podcasts.apple.com/us/podcast/the-engineering-side-of-data/id1566999533)\n- [DataWare](https://www.ascend.io/dataaware-podcast/)\n- [The Data Coffee Break Podcast](https://www.deezer.com/us/show/5293247)\n- [The Datastack show](https://datastackshow.com/)\n- [Intricity101 Data Sharks Podcast](https://www.intricity.com/learningcenter/podcast)\n- [Drill to Detail with Mark Rittman](https://www.rittmananalytics.com/drilltodetail/)\n- [Analytics Power Hour](https://analyticshour.io/)\n- [Catalog & cocktails](https://listen.casted.us/public/127/Catalog-%26-Cocktails-2fcf8728)\n- [Datatalks](https://datatalks.club/podcast.html)\n- [Data Brew by Databricks](https://www.databricks.com/discover/data-brew)\n- [The Data Cloud Podcast by Snowflake](https://rise-of-the-data-cloud.simplecast.com/)\n- [What's New in Data](https://www.striim.com/podcast/)\n- [Open||Source||Data by Datastax](https://www.datastax.com/resources/podcast/open-source-data)\n- [Streaming Audio by confluent](https://developer.confluent.io/podcast/)\n- [The Data Scientist Show](https://podcasts.apple.com/us/podcast/the-data-scientist-show/id1584430381)\n- [MLOps.community](https://podcast.mlops.community/)\n- [Monday Morning Data Chat](https://open.spotify.com/show/3Km3lBNzJpc1nOTJUtbtMh)\n- [The Data Chief](https://www.thoughtspot.com/data-chief/podcast)\n\n### Great [list of 20+ newsletters](newsletters.md)\n\nTop must follow newsletters for data engineering:\n- [DataEngineer.io Newsletter](https://blog.dataengineer.io)\n- [Joe Reis](https://joereis.substack.com)\n- [Start Data Engineering](https://www.startdataengineering.com)\n- [Data Engineering Weekly](https://www.dataengineeringweekly.com)\n- [Data Engineer Things](https://dataengineerthings.substack.com/)\n\n### Glossaries:\n- [Data Engineering Vault](https://www.ssp.sh/brain/data-engineering/)\n- [Airbyte Data Glossary](https://glossary.airbyte.com/)\n- [Data Engineering Wiki by Reddit](https://dataengineering.wiki/Index)\n- [Seconda Glossary](https://www.secoda.co/glossary/)\n- [Glossary Databricks](https://www.databricks.com/glossary)\n- [Airtable Glossary](https://airtable.com/shrGh8BqZbkfkbrfk/tbluZ3ayLHC3CKsDb)\n- [Data Engineering Glossary by Dagster](https://dagster.io/glossary)\n\n\n### Design Patterns\n\n- [Cumulative Table Design](https://www.github.com/DataExpert-io/cumulative-table-design)\n- [Microbatch Deduplication](https://www.github.com/EcZachly/microbatch-hourly-deduped-tutorial)\n- [The Little Book of Pipelines](https://www.github.com/EcZachly/little-book-of-pipelines)\n- [Data Developer Platform](https://datadeveloperplatform.org/architecture/)\n\n### Courses / Academies\n\n- [DataExpert.io course](https://www.dataexpert.io) use code **HANDBOOK10** for a discount!\n- [LearnDataEngineering.com](https://www.learndataengineering.com)\n- [Technical Freelancer Academy](https://www.technicalfreelanceracademy.com/) Use code **zwtech** for a discount!\n- [IBM Data Engineering for Everyone](https://www.edx.org/learn/data-engineering/ibm-data-engineering-basics-for-everyone)\n- [Qwiklabs](https://www.qwiklabs.com/)\n- [DataCamp](https://www.datacamp.com/)\n- [Udemy Courses from Shruti Mantri](https://www.udemy.com/user/shruti-mantri-5/)\n- [Rock the JVM](https://rockthejvm.com/) teaches Spark (in Scala), Flink and others\n- [Data Engineering Zoomcamp by DataTalksClub](https://datatalks.club/)\n- [Efficient Data Processing in Spark](https://josephmachado.podia.com/efficient-data-processing-in-spark)\n- [Scaler](https://www.scaler.com/)\n- [DataTeams - Data Engingeer hiring platform](https://www.datateams.ai/)\n- [Udemy Courses from Daniel Blanco](https://danielblanco.dev/links)\n\n### Certifications Courses\n\n- [Google Cloud Certified - Professional Data Engineer](https://cloud.google.com/certification/data-engineer)\n- [Databricks - Certified Associate Developer for Apache Spark](https://www.databricks.com/learn/certification/apache-spark-developer-associate)\n- [Databricks - Data Engineer Associate](https://www.databricks.com/learn/certification/data-engineer-associate)\n- [Databricks - Data Engineer Professional](https://www.databricks.com/learn/certification/data-engineer-professional)\n- [Microsoft DP-203: Data Engineering on Microsoft Azure](https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-203/?tab=tab-learning-paths)\n- [Microsoft DP-600: Fabric Analytics Engineer Associate](https://learn.microsoft.com/credentials/certifications/fabric-analytics-engineer-associate/)\n- [Microsoft DP-700: Fabric Data Engineer Associate](https://learn.microsoft.com/en-us/credentials/certifications/fabric-data-engineer-associate/?practice-assessment-type=certification)\n- [AWS Certified Data Engineer - Associate](https://aws.amazon.com/certification/certified-data-engineer-associate/)\n"
        },
        {
            "url": "https://github.com/rasbt/LLMs-from-scratch",
            "language": "Jupyter Notebook",
            "description": "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
            "readme_summary": "# Build a Large Language Model (From Scratch)\n\nThis repository contains the code for developing, pretraining, and finetuning a GPT-like LLM and is the official code repository for the book [Build a Large Language Model (From Scratch)](https://amzn.to/4fqvn0D).\n\n<br>\n<br>\n\n<a href=\"https://amzn.to/4fqvn0D\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover.jpg?123\" width=\"250px\"></a>\n\n<br>\n\nIn [*Build a Large Language Model (From Scratch)*](http://mng.bz/orYv), you'll learn and understand how large language models (LLMs) work from the inside out by coding them from the ground up, step by step. In this book, I'll guide you through creating your own LLM, explaining each stage with clear text, diagrams, and examples.\n\nThe method described in this book for training and developing your own small-but-functional model for educational purposes mirrors the approach used in creating large-scale foundational models such as those behind ChatGPT. In addition, this book includes code for loading the weights of larger pretrained models for finetuning.\n\n- Link to the official [source code repository](https://github.com/rasbt/LLMs-from-scratch)\n- [Link to the book at Manning (the publisher's website)](http://mng.bz/orYv)\n- [Link to the book page on Amazon.com](https://www.amazon.com/gp/product/1633437167)\n- ISBN 9781633437166\n\n<a href=\"http://mng.bz/orYv#reviews\"><img src=\"https://sebastianraschka.com//images/LLMs-from-scratch-images/other/reviews.png\" width=\"220px\"></a>\n\n\n<br>\n<br>\n\nTo download a copy of this repository, click on the [Download ZIP](https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip) button or execute the following command in your terminal:\n\n```bash\ngit clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git\n```\n\n<br>\n\n(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) for the latest updates.)\n\n<br>\n<br>\n\n\n# Table of Contents\n\nPlease note that this `README.md` file is a Markdown (`.md`) file. If you have downloaded this code bundle from the Manning website and are viewing it on your local computer, I recommend using a Markdown editor or previewer for proper viewing. If you haven't installed a Markdown editor yet, [Ghostwriter](https://ghostwriter.kde.org) is a good free option.\n\nYou can alternatively view this and other files on GitHub at [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) in your browser, which renders Markdown automatically.\n\n<br>\n<br>\n\n\n> **Tip:**\n> If you're seeking guidance on installing Python and Python packages and setting up your code environment, I suggest reading the [README.md](setup/README.md) file located in the [setup](setup) directory.\n\n<br>\n<br>\n\n[![Code tests Linux](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml/badge.svg)](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml)\n[![Code tests Windows](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml/badge.svg)](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml)\n[![Code tests macOS](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml/badge.svg)](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml)\n\n\n\n\n<br>\n\n| Chapter Title                                              | Main Code (for Quick Access)                                                                                                    | All Code + Supplementary      |\n|------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|-------------------------------|\n| [Setup recommendations](setup)                             | -                                                                                                                               | -                             |\n| Ch 1: Understanding Large Language Models                  | No code                                                                                                                         | -                             |\n| Ch 2: Working with Text Data                               | - [ch02.ipynb](ch02/01_main-chapter-code/ch02.ipynb)<br/>- [dataloader.ipynb](ch02/01_main-chapter-code/dataloader.ipynb) (summary)<br/>- [exercise-solutions.ipynb](ch02/01_main-chapter-code/exercise-solutions.ipynb)               | [./ch02](./ch02)            |\n| Ch 3: Coding Attention Mechanisms                          | - [ch03.ipynb](ch03/01_main-chapter-code/ch03.ipynb)<br/>- [multihead-attention.ipynb](ch03/01_main-chapter-code/multihead-attention.ipynb) (summary) <br/>- [exercise-solutions.ipynb](ch03/01_main-chapter-code/exercise-solutions.ipynb)| [./ch03](./ch03)             |\n| Ch 4: Implementing a GPT Model from Scratch                | - [ch04.ipynb](ch04/01_main-chapter-code/ch04.ipynb)<br/>- [gpt.py](ch04/01_main-chapter-code/gpt.py) (summary)<br/>- [exercise-solutions.ipynb](ch04/01_main-chapter-code/exercise-solutions.ipynb) | [./ch04](./ch04)           |\n| Ch 5: Pretraining on Unlabeled Data                        | - [ch05.ipynb](ch05/01_main-chapter-code/ch05.ipynb)<br/>- [gpt_train.py](ch05/01_main-chapter-code/gpt_train.py) (summary) <br/>- [gpt_generate.py](ch05/01_main-chapter-code/gpt_generate.py) (summary) <br/>- [exercise-solutions.ipynb](ch05/01_main-chapter-code/exercise-solutions.ipynb) | [./ch05](./ch05)              |\n| Ch 6: Finetuning for Text Classification                   | - [ch06.ipynb](ch06/01_main-chapter-code/ch06.ipynb)  <br/>- [gpt_class_finetune.py](ch06/01_main-chapter-code/gpt_class_finetune.py)  <br/>- [exercise-solutions.ipynb](ch06/01_main-chapter-code/exercise-solutions.ipynb) | [./ch06](./ch06)              |\n| Ch 7: Finetuning to Follow Instructions                    | - [ch07.ipynb](ch07/01_main-chapter-code/ch07.ipynb)<br/>- [gpt_instruction_finetuning.py](ch07/01_main-chapter-code/gpt_instruction_finetuning.py) (summary)<br/>- [ollama_evaluate.py](ch07/01_main-chapter-code/ollama_evaluate.py) (summary)<br/>- [exercise-solutions.ipynb](ch07/01_main-chapter-code/exercise-solutions.ipynb) | [./ch07](./ch07)  |\n| Appendix A: Introduction to PyTorch                        | - [code-part1.ipynb](appendix-A/01_main-chapter-code/code-part1.ipynb)<br/>- [code-part2.ipynb](appendix-A/01_main-chapter-code/code-part2.ipynb)<br/>- [DDP-script.py](appendix-A/01_main-chapter-code/DDP-script.py)<br/>- [exercise-solutions.ipynb](appendix-A/01_main-chapter-code/exercise-solutions.ipynb) | [./appendix-A](./appendix-A) |\n| Appendix B: References and Further Reading                 | No code                                                                                                                         | -                             |\n| Appendix C: Exercise Solutions                             | No code                                                                                                                         | -                             |\n| Appendix D: Adding Bells and Whistles to the Training Loop | - [appendix-D.ipynb](appendix-D/01_main-chapter-code/appendix-D.ipynb)                                                          | [./appendix-D](./appendix-D)  |\n| Appendix E: Parameter-efficient Finetuning with LoRA       | - [appendix-E.ipynb](appendix-E/01_main-chapter-code/appendix-E.ipynb)                                                          | [./appendix-E](./appendix-E) |\n\n<br>\n&nbsp;\n\nThe mental model below summarizes the contents covered in this book.\n\n<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg\" width=\"650px\">\n\n\n<br>\n&nbsp;\n\n## Prerequisites\n\nThe most important prerequisite is a strong foundation in Python programming.\nWith this knowledge, you will be well prepared to explore the fascinating world of LLMs\nand understand the concepts and code examples presented in this book.\n\nIf you have some experience with deep neural networks, you may find certain concepts more familiar, as LLMs are built upon these architectures.\n\nThis book uses PyTorch to implement the code from scratch without using any external LLM libraries. While proficiency in PyTorch is not a prerequisite, familiarity with PyTorch basics is certainly useful. If you are new to PyTorch, Appendix A provides a concise introduction to PyTorch. Alternatively, you may find my book, [PyTorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs](https://sebastianraschka.com/teaching/pytorch-1h/), helpful for learning about the essentials.\n\n\n\n<br>\n&nbsp;\n\n## Hardware Requirements\n\nThe code in the main chapters of this book is designed to run on conventional laptops within a reasonable timeframe and does not require specialized hardware. This approach ensures that a wide audience can engage with the material. Additionally, the code automatically utilizes GPUs if they are available. (Please see the [setup](https://github.com/rasbt/LLMs-from-scratch/blob/main/setup/README.md) doc for additional recommendations.)\n\n\n&nbsp;\n## Video Course\n\n[A 17-hour and 15-minute companion video course](https://www.manning.com/livevideo/master-and-build-large-language-models) where I code through each chapter of the book. The course is organized into chapters and sections that mirror the book's structure so that it can be used as a standalone alternative to the book or complementary code-along resource.\n\n<a href=\"https://www.manning.com/livevideo/master-and-build-large-language-models\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/video-screenshot.webp?123\" width=\"350px\"></a>\n\n\n\n&nbsp;\n## Exercises\n\nEach chapter of the book includes several exercises. The solutions are summarized in Appendix C, and the corresponding code notebooks are available in the main chapter folders of this repository (for example,  [./ch02/01_main-chapter-code/exercise-solutions.ipynb](./ch02/01_main-chapter-code/exercise-solutions.ipynb).\n\nIn addition to the code exercises, you can download a free 170-page PDF titled  [Test Yourself On Build a Large Language Model (From Scratch)](https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch) from the Manning website. It contains approximately 30 quiz questions and solutions per chapter to help you test your understanding.\n\n<a href=\"https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/test-yourself-cover.jpg?123\" width=\"150px\"></a>\n\n\n\n&nbsp;\n## Bonus Material\n\nSeveral folders contain optional materials as a bonus for interested readers:\n\n- **Setup**\n  - [Python Setup Tips](setup/01_optional-python-setup-preferences)\n  - [Installing Python Packages and Libraries Used In This Book](setup/02_installing-python-libraries)\n  - [Docker Environment Setup Guide](setup/03_optional-docker-environment)\n- **Chapter 2: Working with text data**\n  - [Byte Pair Encoding (BPE) Tokenizer From Scratch](ch02/05_bpe-from-scratch/bpe-from-scratch.ipynb)\n  - [Comparing Various Byte Pair Encoding (BPE) Implementations](ch02/02_bonus_bytepair-encoder)\n  - [Understanding the Difference Between Embedding Layers and Linear Layers](ch02/03_bonus_embedding-vs-matmul)\n  - [Dataloader Intuition with Simple Numbers](ch02/04_bonus_dataloader-intuition)\n- **Chapter 3: Coding attention mechanisms**\n  - [Comparing Efficient Multi-Head Attention Implementations](ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb)\n  - [Understanding PyTorch Buffers](ch03/03_understanding-buffers/understanding-buffers.ipynb)\n- **Chapter 4: Implementing a GPT model from scratch**\n  - [FLOPS Analysis](ch04/02_performance-analysis/flops-analysis.ipynb)\n  - [KV Cache](ch04/03_kv-cache)\n- **Chapter 5: Pretraining on unlabeled data:**\n  - [Alternative Weight Loading Methods](ch05/02_alternative_weight_loading/)\n  - [Pretraining GPT on the Project Gutenberg Dataset](ch05/03_bonus_pretraining_on_gutenberg)\n  - [Adding Bells and Whistles to the Training Loop](ch05/04_learning_rate_schedulers)\n  - [Optimizing Hyperparameters for Pretraining](ch05/05_bonus_hparam_tuning)\n  - [Building a User Interface to Interact With the Pretrained LLM](ch05/06_user_interface)\n  - [Converting GPT to Llama](ch05/07_gpt_to_llama)\n  - [Llama 3.2 From Scratch](ch05/07_gpt_to_llama/standalone-llama32.ipynb)\n  - [Qwen3 Dense and Mixture-of-Experts (MoE) From Scratch](ch05/11_qwen3/)\n  - [Gemma 3 From Scratch](ch05/12_gemma3/)\n  - [Memory-efficient Model Weight Loading](ch05/08_memory_efficient_weight_loading/memory-efficient-state-dict.ipynb)\n  - [Extending the Tiktoken BPE Tokenizer with New Tokens](ch05/09_extending-tokenizers/extend-tiktoken.ipynb)\n  - [PyTorch Performance Tips for Faster LLM Training](ch05/10_llm-training-speed)\n- **Chapter 6: Finetuning for classification**\n  - [Additional experiments finetuning different layers and using larger models](ch06/02_bonus_additional-experiments)\n  - [Finetuning different models on 50k IMDB movie review dataset](ch06/03_bonus_imdb-classification)\n  - [Building a User Interface to Interact With the GPT-based Spam Classifier](ch06/04_user_interface)\n- **Chapter 7: Finetuning to follow instructions**\n  - [Dataset Utilities for Finding Near Duplicates and Creating Passive Voice Entries](ch07/02_dataset-utilities)\n  - [Evaluating Instruction Responses Using the OpenAI API and Ollama](ch07/03_model-evaluation)\n  - [Generating a Dataset for Instruction Finetuning](ch07/05_dataset-generation/llama3-ollama.ipynb)\n  - [Improving a Dataset for Instruction Finetuning](ch07/05_dataset-generation/reflection-gpt4.ipynb)\n  - [Generating a Preference Dataset with Llama 3.1 70B and Ollama](ch07/04_preference-tuning-with-dpo/create-preference-data-ollama.ipynb)\n  - [Direct Preference Optimization (DPO) for LLM Alignment](ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb)\n  - [Building a User Interface to Interact With the Instruction Finetuned GPT Model](ch07/06_user_interface)\n\n<br>\n&nbsp;\n\n## Questions, Feedback, and Contributing to This Repository\n\n\nI welcome all sorts of feedback, best shared via the [Manning Forum](https://livebook.manning.com/forum?product=raschka&page=1) or [GitHub Discussions](https://github.com/rasbt/LLMs-from-scratch/discussions). Likewise, if you have any questions or just want to bounce ideas off others, please don't hesitate to post these in the forum as well.\n\nPlease note that since this repository contains the code corresponding to a print book, I currently cannot accept contributions that would extend the contents of the main chapter code, as it would introduce deviations from the physical book. Keeping it consistent helps ensure a smooth experience for everyone.\n\n\n&nbsp;\n## Citation\n\nIf you find this book or code useful for your research, please consider citing it.\n\nChicago-style citation:\n\n> Raschka, Sebastian. *Build A Large Language Model (From Scratch)*. Manning, 2024. ISBN: 978-1633437166.\n\nBibTeX entry:\n\n```\n@book{build-llms-from-scratch-book,\n  author       = {Sebastian Raschka},\n  title        = {Build A Large Language Model (From Scratch)},\n  publisher    = {Manning},\n  year         = {2024},\n  isbn         = {978-1633437166},\n  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},\n  github       = {https://github.com/rasbt/LLMs-from-scratch}\n}\n```\n"
        },
        {
            "url": "https://github.com/enescingoz/awesome-n8n-templates",
            "language": "Unknown",
            "description": "Supercharge your workflow automation with this curated collection of n8n templates! Instantly connect your favorite apps-like Gmail, Telegram, Google Drive, Slack, and more-with ready-to-use, AI-powered automations. Save time, boost productivity, and unlock the true potential of n8n in just a few clicks.",
            "readme_summary": "# n8n_automations\n\n[![English](https://img.shields.io/badge/English-Click-yellow)](README.md)\n[![中文文档](https://img.shields.io/badge/中文文档-点击查看-orange)](README-zh.md)\n\nThis repository contains a collection of n8n automation templates sourced from the internet. These templates are designed to help automate a wide range of tasks and workflows using [n8n](https://n8n.partnerlinks.io/h1pwwf5m4toe), making it easier for users to discover and use ready-made automations for various platforms and services.\n\n👉 [Join n8n and start automating now! 💎](https://n8n.partnerlinks.io/h1pwwf5m4toe)\n<a href=\"https://n8n.partnerlinks.io/h1pwwf5m4toe\">\n  <img src=\"/img/n8n.png\" alt=\"n8n\" style=\"max-height: 300px;\">\n</a>\n\n\n---\n\n## Disclaimer\nAll automation templates in this repository were found online and are uploaded here solely for easy access and sharing. None of the templates are created or owned by the repository author. If you encounter any issues, errors, or damages resulting from the use of these templates, the repository author assumes no responsibility or liability. All rights to the original templates belong to their respective creators.\n\n---\n\n☕ Before diving into the long list of categories and templates, grab your coffee-and if you enjoy my work, don’t forget to buy me a coffee! \n\n<a href=\"https://buymeacoffee.com/enescingoz\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/default-orange.png\" alt=\"Buy Me A Coffee\" height=\"41\" width=\"174\"></a>\n\n--- \n\n## Categories & Template List\n\n---\n\n🤖 Want to translate, rewrite, and repost Twitter (X) threads automatically?\n\nLooking to effortlessly transform and publish entire Twitter (X) threads in multiple languages?  \nCheck out my [n8n](https://n8n.partnerlinks.io/h1pwwf5m4toe) Twitter Thread (Flood) Translator & Poster workflow—it automates extraction, translation, rewriting, and posting in one seamless process.  \nPerfect for creators, marketers, and anyone aiming to reach new audiences with minimal effort and ultra-low cost!\n\n👉 [Try the workflow here](https://n8n.io/workflows/4233-translate-and-repost-twitter-threads-in-multiple-languages-with-openai/)\n\n---\n\n## 🧵 If you want to scrape Twitter (X) threads, definitely check this workflow\n\nLooking to extract and merge entire Twitter (X) threads quickly and affordably?  \nCheck out my [n8n Twitter Thread Fetcher workflow](https://n8n.io/workflows/4088-extract-and-merge-twitter-x-threads-using-twitterapiio/)-it’s lightning-fast, cost-effective, and perfect for automating Twitter thread extraction for research, content curation, or archiving!\n\n---\n### Gmail & Email Automation\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Auto-label incoming Gmail messages with AI nodes | Automatically labels incoming Gmail messages using AI. The workflow retrieves message content, suggests labels like Partnership or Inquiry, and assigns them for better organization. | Ops | [Link to Template](Gmail_and_Email_Automation/Auto-label%20incoming%20Gmail%20messages%20with%20AI%20nodes.json) |\n| Basic Automatic Gmail Email Labelling with OpenAI and Gmail API | Uses OpenAI and Gmail API to trigger on new emails, analyze content, and assign or create labels automatically. Helps categorize emails efficiently using AI. | Ops | [Link to Template](Gmail_and_Email_Automation/Basic%20Automatic%20Gmail%20Email%20Labelling%20with%20OpenAI%20and%20Gmail%20API.json) |\n| Compose reply draft in Gmail with OpenAI Assistant | Generates draft replies in Gmail using OpenAI. Triggers on new emails, extracts content, and creates a suggested reply draft to streamline responses. | Executive | [Link to Template](Gmail_and_Email_Automation/Compose%20reply%20draft%20in%20Gmail%20with%20OpenAI%20Assistant.json) |\n| Analyze & Sort Suspicious Email Contents with ChatGPT | Analyzes suspicious emails using ChatGPT, classifies them, and can generate screenshots for review. Helps identify and sort potentially dangerous emails. | Security | [Link to Template](Gmail_and_Email_Automation/Analyze%20&%20Sort%20Suspicious%20Email%20Contents%20with%20ChatGPT.json) |\n| Analyze Suspicious Email Contents with ChatGPT Vision | Uses both text and image analysis (ChatGPT Vision) to evaluate suspicious emails. Extracts screenshots, analyzes headers and content, and flags phishing attempts. | Security | [Link to Template](Gmail_and_Email_Automation/Analyze%20Suspicious%20Email%20Contents%20with%20ChatGPT%20Vision.json) |\n| A Very Simple \"Human in the Loop\" Email Response System Using AI and IMAP | Implements a simple workflow for human-in-the-loop email responses. Uses IMAP to fetch emails, summarizes content with AI, and drafts professional replies for review before sending. | Support | [Link to Template](Gmail_and_Email_Automation/A%20Very%20Simple%20_Human%20in%20the%20Loop_%20Email%20Response%20System%20Using%20AI%20and%20IMAP.json) |\n| Auto Categorise Outlook Emails with AI | Automatically categorizes Outlook emails using AI models. Moves messages to folders and assigns categories based on content, reducing manual sorting. | Ops | [Link to Template](Gmail_and_Email_Automation/Auto%20Categorise%20Outlook%20Emails%20with%20AI.json) |\n| Microsoft Outlook AI Email Assistant with contact support from Monday and Airtable | An AI-powered assistant for Outlook that processes emails, sanitizes content, and assigns categories using rules from Airtable. Integrates with Monday.com for contact support. | Ops | [Link to Template](Gmail_and_Email_Automation/Microsoft%20Outlook%20AI%20Email%20Assistant%20with%20contact%20support%20from%20Monday%20and%20Airtable.json) |\n| 📈 Receive Daily Market News from FT.com to your Microsoft outlook inbox | Extracts financial news from FT.com and delivers daily updates to your Outlook inbox. Automates content extraction and email delivery for timely market insights. | Executive | [Link to Template](Gmail_and_Email_Automation/📈%20Receive%20Daily%20Market%20News%20from%20FT.com%20to%20your%20Microsoft%20outlook%20inbox.json) |\n\n### Telegram\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Agentic Telegram AI bot with LangChain nodes and new tools | An advanced Telegram bot leveraging LangChain and OpenAI for conversational AI. Supports memory, dynamic tool use, and handles incoming events for rich, context-aware chat interactions. | Support | [Link to Template](Telegram/Agentic%20Telegram%20AI%20bot%20with%20with%20LangChain%20nodes%20and%20new%20tools.json) |\n| AI-Powered Children’s Arabic Storytelling on Telegram | A Telegram bot that uses OpenAI to generate and narrate children’s stories in Arabic, making storytelling interactive and educational for young users. | Support | [Link to Template](Telegram/AI-Powered%20Children_s%20Arabic%20Storytelling%20on%20Telegram.json) |\n| AI-Powered Children’s English Storytelling on Telegram with OpenAI | Creates and tells children’s stories in English using OpenAI to engage young audiences in an interactive way. | Support | [Link to Template](Telegram/AI-Powered%20Children_s%20English%20Storytelling%20on%20Telegram%20with%20OpenAI.json) |\n| Automated AI image analysis and response via Telegram | Lets users send images to Telegram and receive AI-based analysis and feedback automatically. | Ops | [Link to Template](Telegram/Automated%20AI%20image%20analysis%20and%20response%20via%20Telegram.json) |\n| Angie, Personal AI Assistant with Telegram Voice and Text | Personal voice & text assistant bot that answers queries, manages tasks, and interacts naturally using AI. | Support | [Link to Template](Telegram/Angie,%20Personal%20AI%20Assistant%20with%20Telegram%20Voice%20and%20Text.json) |\n| Chat with OpenAI’s GPT via a simple Telegram Bot | A minimal Telegram bot that forwards user messages to GPT and returns AI-generated replies. Ideal starting point for AI chat. | Support | [Link to Template](Telegram/Chat%20with%20OpenAIs%20GPT%20via%20a%20simple%20Telegram%20Bot.json) |\n| Telegram AI bot assistant: ready-made template for voice & text messages | Ready-made assistant bot handling both voice and text input, leveraging AI for smart conversational responses in Telegram. | Support | [Link to Template](Telegram/Telegram%20AI%20bot%20assistant_%20ready-made%20template%20for%20voice%20&%20text%20messages.json) |\n| Telegram AI Bot: NeurochainAI Text & Image | Integrates NeurochainAI API for text and image generation inside Telegram, enabling creative media interactions. | Marketing | [Link to Template](Telegram/Telegram%20AI%20Bot_%20NeurochainAI%20Text%20&%20Image%20-%20NeurochainAI%20Basic%20API%20Integration.json) |\n| Telegram AI bot with LangChain nodes | Uses LangChain nodes for advanced AI conversations and tool use in Telegram. | Support | [Link to Template](Telegram/Telegram%20AI%20bot%20with%20LangChain%20nodes.json) |\n| Telegram AI Chatbot | A general-purpose AI chatbot template for Telegram that can be customized for various use cases. | Support | [Link to Template](Telegram/Telegram%20AI%20Chatbot.json) |\n| Telegram Bot with Supabase memory and OpenAI assistant integration | Adds long-term memory with Supabase to a Telegram bot, coupled with OpenAI for rich, context-aware conversations. | Support | [Link to Template](Telegram/Telegram%20Bot%20with%20Supabase%20memory%20and%20OpenAI%20assistant%20integration.json) |\n| Telegram chat with PDF | Allows users to upload a PDF to Telegram and chat with its contents using AI-powered summarization and Q&A. | Ops | [Link to Template](Telegram/Telegram%20chat%20with%20PDF.json) |\n| 🤖 Telegram Messaging Agent for Text_Audio_Images | Multi-modal agent that processes text, audio, and images in Telegram chats using AI for responses. | Support | [Link to Template](Telegram/%F0%9F%A4%96%20Telegram%20Messaging%20Agent%20for%20Text_Audio_Images.json) |\n| Telegram to Spotify with OpenAI | Lets users request songs or playlists in Telegram and automatically create them in Spotify via OpenAI. | Marketing | [Link to Template](Telegram/Telegram%20to%20Spotify%20with%20OpenAI.json) |\n| Send a random recipe once a day to Telegram | Scheduled workflow that fetches a random recipe daily and posts it to a Telegram chat. | Marketing | [Link to Template](Telegram/Send%20a%20random%20recipe%20once%20a%20day%20to%20Telegram.json) |\n| Detect toxic language in Telegram messages | Monitors Telegram chats and flags messages containing toxic language using AI moderation. | Security | [Link to Template](Telegram/Detect%20toxic%20language%20in%20Telegram%20messages.json) |\n| Translate Telegram audio messages with AI (55 supported languages) | Receives voice messages, transcribes them, and sends back translations in over 50 languages. | Support | [Link to Template](Telegram/Translate%20Telegram%20audio%20messages%20with%20AI%20(55%20supported%20languages).json) |\n| Empower Your AI Chatbot with Long-Term Memory and Dynamic Tool Routing | External workflow enhancing an AI chatbot with long-term memory and dynamic tool routing capabilities. | Support | [Link to Template](https://n8n.io/workflows/3025-empower-your-ai-chatbot-with-long-term-memory-and-dynamic-tool-routing/) |\n\n### Google Drive & Google Sheets\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Automated End-to-End Fine-Tuning of OpenAI Models with Google Drive Integration | Automates the fine-tuning of OpenAI models by integrating with Google Drive for data input and output, streamlining custom AI model training. | Engineering | [Link to Template](Google_Drive_and_Google_Sheets/Automated%20End-to-End%20Fine-Tuning%20of%20OpenAI%20Models%20with%20Google%20Drive%20Integration.json) |\n| Automatic Background Removal for Images in Google Drive | Automatically removes backgrounds from images stored in Google Drive, preparing them for various uses like product catalogs or marketing materials. | Marketing | [Link to Template](Google_Drive_and_Google_Sheets/Automatic%20Background%20Removal%20for%20Images%20in%20Google%20Drive.json) |\n| Build an OpenAI Assistant with Google Drive Integration | Demonstrates building an OpenAI Assistant that accesses and utilizes files in Google Drive, enabling it to answer questions or perform tasks based on document content. | Support | [Link to Template](Google_Drive_and_Google_Sheets/Build%20an%20OpenAI%20Assistant%20with%20Google%20Drive%20Integration.json) |\n| RAG Chatbot for Company Documents using Google Drive and Gemini | Creates a Retrieval-Augmented Generation (RAG) chatbot that answers questions based on company documents stored in Google Drive, leveraging Google Gemini. | Support | [Link to Template](Google_Drive_and_Google_Sheets/RAG%20Chatbot%20for%20Company%20Documents%20using%20Google%20Drive%20and%20Gemini.json) |\n| RAG_Context-Aware Chunking: Google Drive to Pinecone via OpenRouter & Gemini | Implements context-aware chunking for Google Drive documents, sending them to Pinecone for vector storage and using OpenRouter & Gemini for advanced RAG. | Engineering | [Link to Template](Google_Drive_and_Google_Sheets/RAG_Context-Aware%20Chunking%20_%20Google%20Drive%20to%20Pinecone%20via%20OpenRouter%20&%20Gemini.json) |\n| Summarize the New Documents from Google Drive and Save Summary in Google Sheet | Monitors Google Drive for new documents, summarizes their content using AI, and saves these summaries into a Google Sheet for quick overview and analysis. | Ops | [Link to Template](Google_Drive_and_Google_Sheets/Summarize%20the%20New%20Documents%20from%20Google%20Drive%20and%20Save%20Summary%20in%20Google%20Sheet.json) |\n| Upload to Instagram and Tiktok from Google Drive | Automates uploading media from Google Drive directly to Instagram and TikTok, streamlining social media content publishing. | Marketing | [Link to Template](Google_Drive_and_Google_Sheets/Upload%20to%20Instagram%20and%20Tiktok%20from%20Google%20Drive.json) |\n| Author and Publish Blog Posts From Google Sheets | Enables authoring blog posts in Google Sheets and automatically publishing them to a content management system, simplifying content creation and publishing. | Marketing | [Link to Template](Google_Drive_and_Google_Sheets/Author%20and%20Publish%20Blog%20Posts%20From%20Google%20Sheets.json) |\n| Chat with a Google Sheet using AI | Allows users to interact with and query data within a Google Sheet using natural language via an AI model, making data analysis more accessible. | Ops | [Link to Template](Google_Drive_and_Google_Sheets/Chat%20with%20a%20Google%20Sheet%20using%20AI.json) |\n| Chat with your event schedule from Google Sheets in Telegram | Connects a Google Sheet containing an event schedule to Telegram, allowing users to query their schedule through a Telegram bot. | Ops | [Link to Template](Google_Drive_and_Google_Sheets/Chat%20with%20your%20event%20schedule%20from%20Google%20Sheets%20in%20Telegram.json) |\n| Qualify new leads in Google Sheets via OpenAI’s GPT-4 | Uses OpenAI's GPT-4 to analyze and qualify new leads entered into a Google Sheet, helping sales teams prioritize their outreach. | Sales | [Link to Template](Google_Drive_and_Google_Sheets/Qualify%20new%20leads%20in%20Google%20Sheets%20via%20OpenAI_s%20GPT-4.json) |\n| Screen Applicants With AI, notify HR and save them in a Google Sheet | Automates the screening of job applicants using AI, notifies HR of qualified candidates, and saves applicant data into a Google Sheet. | HR | [Link to Template](Google_Drive_and_Google_Sheets/Screen%20Applicants%20With%20AI,%20notify%20HR%20and%20save%20them%20in%20a%20Google%20Sheet.json) |\n| Summarize Google Sheets form feedback via OpenAI’s GPT-4 | Summarizes feedback collected through Google Forms and stored in Google Sheets using OpenAI's GPT-4, providing quick insights from survey responses. | Marketing | [Link to Template](Google_Drive_and_Google_Sheets/Summarize%20Google%20Sheets%20form%20feedback%20via%20OpenAI_s%20GPT-4.json) |\n\n---\n\n*More sections and tables can be added below as the project expands.\n\n### WordPress\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Auto-Categorize blog posts in wordpress using A.I. | This workflow automates the categorization of WordPress blog posts using AI, streamlining content organization and management. | Marketing/Content | [Link to Template](WordPress/Auto-Categorize%20blog%20posts%20in%20wordpress%20using%20A.I..json) |\n| Auto-Tag Blog Posts in WordPress with AI | This workflow automatically tags WordPress blog posts using AI, improving SEO and content discoverability. | Marketing/Content | [Link to Template](WordPress/Auto-Tag%20Blog%20Posts%20in%20WordPress%20with%20AI.json) |\n| Automate Blog Creation in Brand Voice with AI | This workflow automates the creation of blog posts, ensuring they adhere to a specific brand voice using AI. | Marketing/Content | [Link to Template](WordPress/Automate%20Blog%20Creation%20in%20Brand%20Voice%20with%20AI.json) |\n| Automate Content Generator for WordPress with DeepSeek R1 | This workflow automates content generation for WordPress using the DeepSeek R1 AI model, enabling rapid content creation. | Marketing/Content | [Link to Template](WordPress/Automate%20Content%20Generator%20for%20WordPress%20with%20DeepSeek%20R1.json) |\n| WordPress - AI Chatbot to enhance user experience - with Supabase and OpenAI | This workflow integrates an AI chatbot into WordPress using Supabase and OpenAI to enhance user experience by providing intelligent interactions. | Customer Support/Marketing | [Link to Template](WordPress/WordPress%20-%20AI%20Chatbot%20to%20enhance%20user%20experience%20-%20with%20Supabase%20and%20OpenAI.json) |\n\n### PDF & Document Processing\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Ask questions about a PDF using AI | This workflow fetches a PDF from Google Drive, splits it into chunks, embeds the chunks using OpenAI embeddings, and enables chat interactions with the document content. | Customer Support/Knowledge Management | [Link to Template](PDF_and_Document_Processing/Ask%20questions%20about%20a%20PDF%20using%20AI.json) |\n| Breakdown Documents into Study Notes using Templating MistralAI and Qdrant | This workflow triggers on new files, processes documents with MistralAI embeddings, and stores data in Qdrant vector store for study note generation. | Education/Knowledge Management | [Link to Template](PDF_and_Document_Processing/Breakdown%20Documents%20into%20Study%20Notes%20using%20Templating%20MistralAI%20and%20Qdrant.json) |\n| CV Resume PDF Parsing with Multimodal Vision AI | This workflow converts candidate resume PDFs to images, uses a Vision Language Model to assess candidate fit, and includes logic to bypass hidden AI prompts in resumes. | HR | [Link to Template](PDF_and_Document_Processing/CV%20Resume%20PDF%20Parsing%20with%20Multimodal%20Vision%20AI.json) |\n| Chat with PDF docs using AI (quoting sources) | This workflow enables chat interactions with PDF documents, allowing users to ask questions and receive answers with quoted sources from the document. | Customer Support/Knowledge Management | [Link to Template](PDF_and_Document_Processing/Chat%20with%20PDF%20docs%20using%20AI%20(quoting%20sources).json) |\n| Convert URL HTML to Markdown Format and Get Page Links | This workflow converts HTML content from a given URL into Markdown format and extracts all page links, useful for content scraping and analysis. | Marketing/Content | [Link to Template](PDF_and_Document_Processing/Convert%20URL%20HTML%20to%20Markdown%20Format%20and%20Get%20Page%20Links.json) |\n| ETL pipeline for text processing | This workflow implements an ETL pipeline for text processing, extracting data from Twitter, storing it in MongoDB and PostgreSQL, and sending alerts to Slack based on sentiment analysis. | Data Analytics/IT | [Link to Template](PDF_and_Document_Processing/ETL%20pipeline%20for%20text%20processing.json) |\n| Extract and process information directly from PDF using Claude and Gemini | This workflow extracts and processes information directly from PDFs using advanced AI models like Claude and Gemini, enabling intelligent document analysis. | Data Extraction/IT | [Link to Template](PDF_and_Document_Processing/Extract%20and%20process%20information%20directly%20from%20PDF%20using%20Claude%20and%20Gemini.json) |\n| Extract data from resume and create PDF with Gotenberg | This workflow extracts structured data from resumes using AI, converts it into HTML, and then generates a well-formatted PDF using Gotenberg. | HR | [Link to Template](PDF_and_Document_Processing/Extract%20data%20from%20resume%20and%20create%20PDF%20with%20Gotenberg.json) |\n| Extract license plate number from image uploaded via an n8n form | This workflow extracts license plate numbers from images uploaded via an n8n form using a Vision Language Model, then displays the extracted information. | Operations/Logistics | [Link to Template](PDF_and_Document_Processing/Extract%20license%20plate%20number%20from%20image%20uploaded%20via%20an%20n8n%20form.json) |\n| Extract text from PDF and image using Vertex AI (Gemini) into CSV | This workflow extracts text from PDFs and images using Vertex AI (Gemini), routes based on file type, and converts the extracted data into a CSV format. | Data Extraction/IT | [Link to Template](PDF_and_Document_Processing/Extract%20text%20from%20PDF%20and%20image%20using%20Vertex%20AI%20(Gemini)%20into%20CSV.json) |\n| Invoice data extraction with LlamaParse and OpenAI | This workflow extracts structured data from invoices using LlamaParse and OpenAI, then processes it with a structured output parser for detailed invoice data extraction. | Finance/Admin | [Link to Template](PDF_and_Document_Processing/Invoice%20data%20extraction%20with%20LlamaParse%20and%20OpenAI.json) |\n| Write a WordPress post with AI (starting from a few keywords) | This workflow uses AI to write WordPress posts based on a few keywords, simplifying the content creation process. | Marketing/Content | [Link to Template](WordPress/Write%20a%20WordPress%20post%20with%20AI%20(starting%20from%20a%20few%20keywords).json) |\n\n### Discord\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Discord AI-powered bot | This workflow creates an AI-powered Discord bot that categorizes user messages (success story, urgent issue, ticket) and routes them to the appropriate department (customer success, IT, customer support). | Customer Support | [Link to Template](Discord/Discord%20AI-powered%20bot.json) |\n| Send daily translated Calvin and Hobbes Comics to Discord | This workflow automates the daily retrieval of Calvin and Hobbes comics, translates the dialogues into English and Korean (or other languages), and posts them to Discord. | Marketing/Content | [Link to Template](Discord/Send%20daily%20translated%20Calvin%20and%20Hobbes%20Comics%20to%20Discord.json) |\n| Share YouTube Videos with AI Summaries on Discord | This workflow automatically shares new YouTube videos on Discord along with AI-generated summaries of their content, leveraging caption data. | Marketing | [Link to Template](Discord/Share%20YouTube%20Videos%20with%20AI%20Summaries%20on%20Discord.json) |\n\n### Database & Storage\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Chat with Postgresql Database | This workflow enables an AI assistant to chat with a PostgreSQL database, allowing users to query and retrieve data using natural language. It supports custom SQL queries and schema introspection. | Data Analytics | [Link to Template](Database_and_Storage/Chat%20with%20Postgresql%20Database.json) |\n| Generate SQL queries from schema only - AI-powered | This workflow uses AI to generate SQL queries based on a given database schema, making it easier to interact with databases without manual query writing. | Engineering | [Link to Template](Database_and_Storage/Generate%20SQL%20queries%20from%20schema%20only%20-%20AI-powered.json) |\n| MongoDB AI Agent - Intelligent Movie Recommendations | This workflow creates an AI agent that provides intelligent movie recommendations by interacting with a MongoDB database, using aggregation pipelines to fetch relevant movie data. | Data Analytics | [Link to Template](Database_and_Storage/MongoDB%20AI%20Agent%20-%20Intelligent%20Movie%20Recommendations.json) |\n| Supabase Insertion & Upsertion & Retrieval | This workflow demonstrates how to perform insertion, upsertion, and retrieval operations with Supabase, specifically for handling vector embeddings and associated metadata. | Engineering | [Link to Template](Database_and_Storage/Supabase%20Insertion%20&%20Upsertion%20&%20Retrieval.json) |\n| Talk to your SQLite database with a LangChain AI Agent | This workflow allows users to interact with a SQLite database using a LangChain AI agent, enabling natural language queries and data retrieval from the database. | Data Analytics | [Link to Template](Database_and_Storage/Talk%20to%20your%20SQLite%20database%20with%20a%20LangChain%20AI%20Agent.json) |\n\n### Airtable\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| AI Agent for project management and meetings with Airtable and Fireflies | This workflow uses an AI agent to automate project management tasks and meeting follow-ups by analyzing call transcripts from Fireflies. It creates tasks in Airtable and notifies clients about their tasks. | Operations | [Link to Template](Airtable/AI%20Agent%20for%20project%20management%20and%20meetings%20with%20Airtable%20and%20Fireflies.json) |\n| AI Agent to chat with Airtable and analyze data | This workflow creates an AI agent that can chat with Airtable, analyze data, and perform queries based on user requests. It can handle aggregation functions and generate graphs/images. | Data Analytics | [Link to Template](Airtable/AI%20Agent%20to%20chat%20with%20Airtable%20and%20analyze%20data.json) |\n| Get Airtable data via AI and Obsidian Notes | This workflow retrieves data from Airtable using an AI agent and integrates it with Obsidian Notes, allowing for seamless data access and organization within Obsidian. | Productivity | [Link to Template](Airtable/Get%20Airtable%20data%20via%20AI%20and%20Obsidian%20Notes.json) |\n| Handling Job Application Submissions with AI and n8n Forms | This workflow automates the handling of job application submissions by extracting information from resumes (PDFs) using AI, parsing it into a structured format, and potentially storing it in Airtable. | HR | [Link to Template](Airtable/Handling%20Job%20Application%20Submissions%20with%20AI%20and%20n8n%20Forms.json) |\n| vAssistant for Hubspot Chat using OpenAi and Airtable | This workflow integrates an OpenAI assistant with HubSpot Chat and Airtable to provide automated responses and manage customer interactions. It fetches chat messages, processes them with AI, and can store relevant information in Airtable. | Sales | [Link to Template](Airtable/vAssistant%20for%20Hubspot%20Chat%20using%20OpenAi%20and%20Airtable.json) |\n\n### Notion\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Add positive feedback messages to a table in Notion | Captures positive feedback from Typeform, analyzes sentiment with Google Cloud Natural Language, and adds it to a Notion table, with Slack notifications for high-scoring feedback. | Support | [Link to Template](Notion/Add%20positive%20feedback%20messages%20to%20a%20table%20in%20Notion.json) |\n| Analyse papers from Hugging Face with AI and store them in Notion | Automatically fetches and analyzes papers from Hugging Face, extracts key information using AI, and stores the structured data in a Notion database. | Engineering | [Link to Template](Notion/Analyse%20papers%20from%20Hugging%20Face%20with%20AI%20and%20store%20them%20in%20Notion.json) |\n| Automate Competitor Research with Exa.ai, Notion and AI Agents | Builds a competitor research agent using Exa.ai to find similar companies. AI agents then scour the internet for company overviews, product offerings, and customer reviews, compiling a report into a Notion table. | Marketing | [Link to Template](Notion/Automate%20Competitor%20Research%20with%20Exa.ai,%20Notion%20and%20AI%20Agents.json) |\n| Automate LinkedIn Outreach with Notion and OpenAI | Automates LinkedIn outreach by fetching daily posts from a Notion database, formatting them with OpenAI for LinkedIn engagement, and then posting them to LinkedIn. | Marketing | [Link to Template](Notion/Automate%20LinkedIn%20Outreach%20with%20Notion%20and%20OpenAI.json) |\n| Notion AI Assistant Generator | Generates a custom AI Assistant chatbot workflow for a specific Notion database schema, allowing users to chat with their Notion data. | Engineering | [Link to Template](Notion/Notion%20AI%20Assistant%20Generator.json) |\n| Notion knowledge base AI assistant | Creates an AI assistant that can search and retrieve information from a Notion knowledge base, providing answers to user queries. | Support | [Link to Template](Notion/Notion%20knowledge%20base%20AI%20assistant.json) |\n| Notion to Pinecone Vector Store Integration | Integrates Notion with Pinecone, allowing Notion pages to be converted into vector embeddings and stored in Pinecone for advanced search and retrieval. | Engineering | [Link to Template](Notion/Notion%20to%20Pinecone%20Vector%20Store%20Integration.json) |\n| Store Notion’s Pages as Vector Documents into Supabase with OpenAI | Automates storing Notion pages as vector documents in a Supabase database, using OpenAI to generate embeddings for the content. | Engineering | [Link to Template](Notion/Store%20Notion_s%20Pages%20as%20Vector%20Documents%20into%20Supabase%20with%20OpenAI.json) |\n| Turn Emails into AI-Enhanced Tasks in Notion (Multi-User Support) with Gmail, Airtable and Softr | Transforms emails into AI-enhanced tasks in Notion, supporting multiple users. It integrates with Gmail for email triggers, Airtable for routing, and Softr for a user interface. | Ops | [Link to Template](Notion/Turn%20Emails%20into%20AI-Enhanced%20Tasks%20in%20Notion%20(Multi-User%20Support)%20with%20Gmail,%20Airtable%20and%20Softr.json) |\n| Upsert huge documents in a vector store with Supabase and Notion | Manages large documents by splitting them into chunks, generating embeddings, and upserting them into a Supabase vector store, with Notion serving as the document source. | Engineering | [Link to Template](Notion/Upsert%20huge%20documents%20in%20a%20vector%20store%20with%20Supabase%20and%20Notion.json) |\n\n### Slack\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| AI-Powered Information Monitoring with OpenAI, Google Sheets, Jina AI and Slack | Monitors RSS feeds, summarizes articles with OpenAI and Jina AI, classifies them, and sends formatted notifications to Slack, enabling AI-powered information monitoring. | Marketing | [Link to Template](Slack/AI-Powered%20Information%20Monitoring%20with%20OpenAI,%20Google%20Sheets,%20Jina%20AI%20and%20Slack.json) |\n| Creating a AI Slack Bot with Google Gemini | Builds an AI Slack bot using Google Gemini, handling webhooks, integrating an AI agent, managing memory, and responding to Slack messages. | Engineering | [Link to Template](Slack/Creating%20a%20AI%20Slack%20Bot%20with%20Google%20Gemini.json) |\n| Customer Support Channel and Ticketing System with Slack and Linear | Automates customer support by querying Slack for messages with a ticket emoji, deciding if a new Linear ticket is needed, creating or updating tickets, and notifying Slack. | Support | [Link to Template](Slack/Customer%20Support%20Channel%20and%20Ticketing%20System%20with%20Slack%20and%20Linear.json) |\n| Enhance Security Operations with the Qualys Slack Shortcut Bot! | Creates a Slack shortcut bot for Qualys to enhance security operations, allowing users to trigger actions like creating reports or starting vulnerability scans directly from Slack. | Security | [Link to Template](Slack/Enhance%20Security%20Operations%20with%20the%20Qualys%20Slack%20Shortcut%20Bot!.json) |\n| Enrich Pipedrive's Organization Data with OpenAI GPT-4o & Notify it in Slack | Enriches Pipedrive organization data by scraping website content, using OpenAI GPT-4o to generate a summary, and adding it as a note in Pipedrive, then notifying a Slack channel. | Sales | [Link to Template](Slack/Enrich%20Pipedrive_s%20Organization%20Data%20with%20OpenAI%20GPT-4o%20&%20Notify%20it%20in%20Slack.json) |\n| IT Ops AI SlackBot Workflow - Chat with your knowledge base | Creates an AI Slackbot for IT Operations, enabling users to chat with a knowledge base to retrieve information and get answers directly within Slack. | IT | [Link to Template](Slack/IT%20Ops%20AI%20SlackBot%20Workflow%20-%20Chat%20with%20your%20knowledge%20base.json) |\n| Sentiment Analysis Tracking on Support Issues with Linear and Slack | Tracks sentiment on support issues by integrating with Linear and Slack, performing sentiment analysis using OpenAI on Linear comments, and notifying relevant Slack channels. | Support | [Link to Template](Slack/Sentiment%20Analysis%20Tracking%20on%20Support%20Issues%20with%20Linear%20and%20Slack.json) |\n| Slack slash commands AI Chat Bot | Implements an AI chatbot accessible via Slack slash commands, processing user commands, interacting with an AI model, and responding within Slack. | IT | [Link to Template](Slack/Slack%20slash%20commands%20AI%20Chat%20Bot.json) |\n| Venafi Cloud Slack Cert Bot | Provides a Slack bot that interacts with Venafi Cloud for certificate management, allowing users to check certificate status, receive alerts, or request certificate actions via Slack. | Security | [Link to Template](Slack/Venafi%20Cloud%20Slack%20Cert%20Bot.json) |*\n\n### OpenAI & LLMs\n\n| Title | Description | Department | Link |\n|---|---|---|---|\n| Advanced AI Demo (Presented at AI Developers #14 meetup) | Advanced AI capabilities demo. | AI/Development | [Link to Template](OpenAI_and_LLMs/Advanced%20AI%20Demo%20(Presented%20at%20AI%20Developers%20%2314%20meetup).json) |\n| AI agent chat | Basic AI chat agent. | AI/Customer Service | [Link to Template](OpenAI_and_LLMs/AI%20agent%20chat.json) |\n| AI agent that can scrape webpages | AI agent for web scraping. | AI/Data Extraction | [Link to Template](OpenAI_and_LLMs/AI%20agent%20that%20can%20scrape%20webpages.json) |\n| AI Crew to Automate Fundamental Stock Analysis - Q&A Workflow | Stock analysis automation. | Finance/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI%20Crew%20to%20Automate%20Fundamental%20Stock%20Analysis%20-%20Q&A%20Workflow.json) |\n| AI Customer feedback sentiment analysis | Sentiment analysis on customer feedback. | Customer Service/Marketing/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI%20Customer%20feedback%20sentiment%20analysis.json) |\n| AI Data Extraction with Dynamic Prompts and Airtable | AI-driven data extraction with Airtable integration. | AI/Data Extraction/Database | [Link to Template](OpenAI_and_LLMs/AI%20Data%20Extraction%20with%20Dynamic%20Prompts%20and%20Airtable.json) |\n| AI Data Extraction with Dynamic Prompts and Baserow | AI-driven data extraction with Baserow integration. | AI/Data Extraction/Database | [Link to Template](OpenAI_and_LLMs/AI%20Data%20Extraction%20with%20Dynamic%20Prompts%20and%20Baserow.json) |\n| AI-Driven Lead Management and Inquiry Automation with ERPNext & n8n | Lead management automation. | Sales/CRM/AI | [Link to Template](OpenAI_and_LLMs/AI-Driven%20Lead%20Management%20and%20Inquiry%20Automation%20with%20ERPNext%20&%20n8n.json) |\n| AI Fitness Coach Strava Data Analysis and Personalized Training Insights | Fitness coaching via Strava data analysis. | Fitness/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI%20Fitness%20Coach%20Strava%20Data%20Analysis%20and%20Personalized%20Training%20Insights.json) |\n| AI-Powered Candidate Shortlisting Automation for ERPNext | Candidate shortlisting automation. | HR/AI/Recruitment | [Link to Template](OpenAI_and_LLMs/AI-Powered%20Candidate%20Shortlisting%20Automation%20for%20ERPNext.json) |\n| AI-Powered Email Automation for Business: Summarize & Respond with RAG | Email automation with summarization and response. | Business Automation/AI/Communication | [Link to Template](OpenAI_and_LLMs/AI-Powered%20Email%20Automation%20for%20Business_%20Summarize%20&%20Respond%20with%20RAG.json) |\n| AI-Powered RAG Workflow For Stock Earnings Report Analysis | Stock earnings report analysis with RAG. | Finance/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI-Powered%20RAG%20Workflow%20For%20Stock%20Earnings%20Report%20Analysis.json) |\n| AI-Powered Social Media Amplifier | Amplifies social media presence using AI. | Marketing/AI/Social Media | [Link to Template](OpenAI_and_LLMs/AI-Powered%20Social%20Media%20Amplifier.json) |\n| AI-powered WooCommerce Support-Agent | Creates an AI-powered support agent for WooCommerce stores. | E-commerce/AI/Customer Service | [Link to Template](OpenAI_and_LLMs/AI-powered%20WooCommerce%20Support-Agent.json) |\n| AI-Powered YouTube Video Summarization & Analysis | Summarizes and analyzes YouTube videos using AI. | Content Creation/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/%E2%9A%A1AI-Powered%20YouTube%20Video%20Summarization%20&%20Analysis.json) |\n| AI: Ask questions about any data source (using the n8n workflow retriever) | Allows users to ask questions about various data sources using an n8n workflow retriever. | AI/Data Analysis/Workflow Automation | [Link to Template](OpenAI_and_LLMs/AI_%20Ask%20questions%20about%20any%20data%20source%20(using%20the%20n8n%20workflow%20retriever).json) |\n| AI: Summarize podcast episode and enhance using Wikipedia | Summarizes podcast episodes and enhances the summary with information from Wikipedia using AI. | Content Creation/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI_%20Summarize%20podcast%20episode%20and%20enhance%20using%20Wikipedia.json) |\n\n### WhatsApp\n\n| Title | Description | Department | Link |\n|---|---|---|---|\n| Automate Sales Meeting Prep with AI & APIFY Sent To WhatsApp | This workflow automates sales meeting preparation using AI and Apify, sending relevant information to WhatsApp. | Sales/AI/Automation | [Link to Template](./WhatsApp/Automate%20Sales%20Meeting%20Prep%20with%20AI%20&%20APIFY%20Sent%20To%20WhatsApp.json) |\n| Building Your First WhatsApp Chatbot | This workflow guides you through building your first WhatsApp chatbot. | Customer Service/Development | [Link to Template](./WhatsApp/Building%20Your%20First%20WhatsApp%20Chatbot.json) |\n| Complete business WhatsApp AI-Powered RAG Chatbot using OpenAI | This workflow builds a complete business WhatsApp AI-powered RAG chatbot using OpenAI. | Customer Service/AI/Development | [Link to Template](./WhatsApp/Complete%20business%20WhatsApp%20AI-Powered%20RAG%20Chatbot%20using%20OpenAI.json) |\n| Respond to WhatsApp Messages with AI Like a Pro! | This workflow enables professional AI-powered responses to WhatsApp messages. | Customer Service/AI/Communication | [Link to Template](./WhatsApp/Respond%20to%20WhatsApp%20Messages%20with%20AI%20Like%20a%20Pro!.json) |\n\n### Instagram, Twitter, Social Media\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| AI agent for Instagram DM_inbox. Manychat + Open AI integration | Integrates Manychat with OpenAI to create an AI agent for managing Instagram direct messages. | Marketing/Customer Service/AI | [Link to Template](Instagram_Twitter_Social_Media/AI%20agent%20for%20Instagram%20DM_inbox.%20Manychat%20%2B%20Open%20AI%20integration.json) |\n| Create dynamic Twitter profile banner | Automates the creation of dynamic Twitter profile banners. | Marketing/Social Media | [Link to Template](Instagram_Twitter_Social_Media/Create%20dynamic%20Twitter%20profile%20banner.json) |\n| Generate Instagram Content from Top Trends with AI Image Generation | Creates Instagram content by analyzing top trends and generating relevant images using AI. | Marketing/AI/Content | [Link to Template](Instagram_Twitter_Social_Media/Generate%20Instagram%20Content%20from%20Top%20Trends%20with%20AI%20Image%20Generation.json) |\n| OpenAI-powered tweet generator | Generates tweets using OpenAI's language models. | Marketing/Social Media/AI | [Link to Template](Instagram_Twitter_Social_Media/OpenAI-powered%20tweet%20generator.json) |\n| Post New YouTube Videos to X | Automatically posts new YouTube videos to X (formerly Twitter). | Marketing/Social Media | [Link to Template](Instagram_Twitter_Social_Media/Post%20New%20YouTube%20Videos%20to%20X.json) |\n| Reddit AI digest | Creates an AI-generated digest of Reddit content. | Marketing/Content/AI | [Link to Template](Instagram_Twitter_Social_Media/Reddit%20AI%20digest.json) |\n| Social Media Analysis and Automated Email Generation | Analyzes social media data and generates automated email reports. | Marketing/Analytics | [Link to Template](Instagram_Twitter_Social_Media/Social%20Media%20Analysis%20and%20Automated%20Email%20Generation.json) |\n| Speed Up Social Media Banners With BannerBear.com | Automates the creation of social media banners using BannerBear.com. | Marketing/Design | [Link to Template](Instagram_Twitter_Social_Media/Speed%20Up%20Social%20Media%20Banners%20With%20BannerBear.com.json) |\n| Twitter Virtual AI Influencer | Manages a virtual AI influencer's Twitter account. | Marketing/AI | [Link to Template](Instagram_Twitter_Social_Media/Twitter%20Virtual%20AI%20Influencer.json) |\n| Update Twitter banner using HTTP request | Updates a Twitter banner using HTTP requests. | Marketing/Development | [Link to Template](Instagram_Twitter_Social_Media/Update%20Twitter%20banner%20using%20HTTP%20request.json) |\n\n### Other Integrations & Use Cases\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| API Schema Extractor | Extracts API schemas from web services for documentation or integration purposes. | Development/Integration | [Link to Template](Other_Integrations_and_Use_Cases/API%20Schema%20Extractor.json) |\n| Analyze feedback and send a message on Mattermost | Analyzes user feedback and sends notifications to Mattermost channels. | Support/Communication | [Link to Template](Other_Integrations_and_Use_Cases/Analyze%20feedback%20and%20send%20a%20message%20on%20Mattermost.json) |\n| Analyze feedback using AWS Comprehend | Performs sentiment analysis on feedback using AWS Comprehend and sends results to Mattermost. | Support/AI | [Link to Template](Other_Integrations_and_Use_Cases/Analyze%20feedback%20using%20AWS%20Comprehend%20and%20send%20it%20to%20a%20Mattermost%20channel.json) |\n| Automate Pinterest Analysis & AI-Powered Content Suggestions | Analyzes Pinterest data and provides AI-powered content suggestions. | Marketing/AI | [Link to Template](Other_Integrations_and_Use_Cases/Automate%20Pinterest%20Analysis%20%26%20AI-Powered%20Content%20Suggestions%20With%20Pinterest%20API.json) |\n| Automate SIEM Alert Enrichment | Enriches SIEM alerts with MITRE ATT&CK data and integrates with Zendesk. | Security/IT | [Link to Template](Other_Integrations_and_Use_Cases/Automate%20SIEM%20Alert%20Enrichment%20with%20MITRE%20ATT%26CK,%20Qdrant%20%26%20Zendesk%20in%20n8n.json) |\n| Automate Screenshots with URLbox & Analyze with AI | Takes screenshots of webpages and analyzes them using AI. | Development/Marketing | [Link to Template](Other_Integrations_and_Use_Cases/Automate%20Screenshots%20with%20URLbox%20%26%20Analyze%20them%20with%20AI.json) |\n| Automate testimonials in Strapi | Automates the process of collecting and managing testimonials in Strapi. | Marketing/Content | [Link to Template](Other_Integrations_and_Use_Cases/Automate%20testimonials%20in%20Strapi%20with%20n8n.json) |\n| Bitrix24 Chatbot Application | Example workflow for creating a Bitrix24 chatbot with webhook integration. | Business/Communication | [Link to Template](Other_Integrations_and_Use_Cases/Bitrix24%20Chatbot%20Application%20Workflow%20example%20with%20Webhook%20Integration.json) |\n| ChatGPT Automatic Code Review in Gitlab MR | Automates code reviews in GitLab merge requests using ChatGPT. | Development/DevOps | [Link to Template](Other_Integrations_and_Use_Cases/ChatGPT%20Automatic%20Code%20Review%20in%20Gitlab%20MR.json) |\n| Classify new bugs in Linear with OpenAI's GPT-4 | Automatically classifies and routes new bug reports in Linear using AI. | Development/QA | [Link to Template](Other_Integrations_and_Use_Cases/Classify%20new%20bugs%20in%20Linear%20with%20OpenAI_s%20GPT-4%20and%20move%20them%20to%20the%20right%20team.json) |\n| Create, update, and get a profile in Humantic AI | Manages user profiles in Humantic AI platform. | Marketing/AI | [Link to Template](Other_Integrations_and_Use_Cases/Create,%20update,%20and%20get%20a%20profile%20in%20Humantic%20AI.json) |\n| Enhance Customer Chat with Twilio and Redis | Implements message buffering for customer chats using Twilio and Redis. | Support/Development | [Link to Template](Other_Integrations_and_Use_Cases/Enhance%20Customer%20Chat%20by%20Buffering%20Messages%20with%20Twilio%20and%20Redis.json) |\n| Hacker News Throwback Machine | Shows what was popular on Hacker News on this day in previous years. | Development/Community | [Link to Template](Other_Integrations_and_Use_Cases/Hacker%20News%20Throwback%20Machine%20-%20See%20What%20Was%20Hot%20on%20This%20Day,%20Every%20Year!.json) |\n| Handling Appointment Leads with Twilio, Cal.com and AI | Manages appointment scheduling and follow-ups using Twilio and Cal.com. | Sales/Support | [Link to Template](Other_Integrations_and_Use_Cases/Handling%20Appointment%20Leads%20and%20Follow-up%20With%20Twilio,%20Cal.com%20and%20AI.json) |\n| Integrating AI with Open-Meteo API | Enhances weather forecasting with AI analysis. | Data Science/Weather | [Link to Template](Other_Integrations_and_Use_Cases/Integrating%20AI%20with%20Open-Meteo%20API%20for%20Enhanced%20Weather%20Forecasting.json) |\n| Introduction to the HTTP Tool | Basic tutorial on using HTTP tools in n8n. | Development | [Link to Template](Other_Integrations_and_Use_Cases/Introduction%20to%20the%20HTTP%20Tool.json) |\n| KB Tool - Confluence Knowledge Base | Integrates with Confluence for knowledge base management. | Documentation/IT | [Link to Template](Other_Integrations_and_Use_Cases/KB%20Tool%20-%20Confluence%20Knowledge%20Base.json) |\n| LINE Assistant with Google Calendar and Gmail | Creates a LINE assistant that integrates with Google Calendar and Gmail. | Productivity/Communication | [Link to Template](Other_Integrations_and_Use_Cases/LINE%20Assistant%20with%20Google%20Calendar%20and%20Gmail%20Integration.json) |\n| Monthly Spotify Track Archiving | Archives and classifies monthly Spotify tracks into playlists. | Personal/Music | [Link to Template](Other_Integrations_and_Use_Cases/Monthly%20Spotify%20Track%20Archiving%20and%20Playlist%20Classification.json) |\n| Obsidian Notes Read Aloud | Converts Obsidian notes into audio format as a podcast feed. | Productivity/Content | [Link to Template](Other_Integrations_and_Use_Cases/Obsidian%20Notes%20Read%20Aloud%20using%20AI_%20Available%20as%20a%20Podcast%20Feed.json) |\n| Optimize & Update Printify Title and Description | Automates optimization of Printify product titles and descriptions. | E-commerce | [Link to Template](Other_Integrations_and_Use_Cases/Optimize%20%26%20Update%20Printify%20Title%20and%20Description%20Workflow.json) |\n| Qualify replies from Pipedrive persons with AI | Uses AI to qualify and categorize replies from Pipedrive contacts. | Sales/AI | [Link to Template](Other_Integrations_and_Use_Cases/Qualify%20replies%20from%20Pipedrive%20persons%20with%20AI.json) |\n| Siri AI Agent with Apple Shortcuts | Creates a Siri-powered AI agent using Apple Shortcuts. | Personal/Productivity | [Link to Template](Other_Integrations_and_Use_Cases/Siri%20AI%20Agent_%20Apple%20Shortcuts%20powered%20voice%20template.json) |\n| Text automations using Apple Shortcuts | Implements text-based automations with Apple Shortcuts. | Personal/Productivity | [Link to Template](Other_Integrations_and_Use_Cases/Text%20automations%20using%20Apple%20Shortcuts.json) |\n| UTM Link Creator & QR Code Generator | Creates UTM links, generates QR codes, and schedules Google Analytics reports. | Marketing/Analytics | [Link to Template](Other_Integrations_and_Use_Cases/UTM%20Link%20Creator%20%26%20QR%20Code%20Generator%20with%20Scheduled%20Google%20Analytics%20Reports.json) |\n| Use AI to organize your Todoist Inbox | Automatically organizes tasks in Todoist using AI. | Productivity | [Link to Template](Other_Integrations_and_Use_Cases/Use%20AI%20to%20organize%20your%20Todoist%20Inbox.json) |\n| Using External Workflows as Tools in n8n | Demonstrates how to use external workflows as tools within n8n. | Development | [Link to Template](Other_Integrations_and_Use_Cases/Using%20External%20Workflows%20as%20Tools%20in%20n8n.json) |\n| Visualize SQL Agent queries with OpenAI and Quickchart.io | Creates visualizations from SQL queries using OpenAI and Quickchart.io. | Data Analysis/Visualization | [Link to Template](Other_Integrations_and_Use_Cases/Visualize%20your%20SQL%20Agent%20queries%20with%20OpenAI%20and%20Quickchart.io.json) |\n| Zoom AI Meeting Assistant | Creates meeting summaries, ClickUp tasks, and schedules follow-ups from Zoom meetings. | Productivity/Communication | [Link to Template](Other_Integrations_and_Use_Cases/Zoom%20AI%20Meeting%20Assistant%20creates%20mail%20summary,%20ClickUp%20tasks%20and%20follow-up%20call.json) |\n\n### Forms & Surveys\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Conversational Interviews with AI Agents and n8n Forms | Implements AI-powered conversational interviews using n8n Forms for interactive data collection. | Research/Marketing | [Link to Template](Forms_and_Surveys/Conversational%20Interviews%20with%20AI%20Agents%20and%20n8n%20Forms.json) |\n| Email Subscription Service with n8n Forms, Airtable and AI | Manages email subscriptions with n8n Forms, stores data in Airtable, and uses AI for processing. | Marketing/Communication | [Link to Template](Forms_and_Surveys/Email%20Subscription%20Service%20with%20n8n%20Forms,%20Airtable%20and%20AI.json) |\n| Qualifying Appointment Requests with AI & n8n Forms | Uses AI to qualify and process appointment requests submitted through n8n Forms. | Sales/Support | [Link to Template](Forms_and_Surveys/Qualifying%20Appointment%20Requests%20with%20AI%20&%20n8n%20Forms.json) |\n\n### AI Research, RAG, and Data Analysis\n\n| Workflow Title | Description | Department | Link to Template |\n|---|---|---|---|\n| Analyze tradingview.com charts with Chrome extension, N8N and OpenAI | Analyzes TradingView charts using a Chrome extension, n8n, and OpenAI for automated insights. | Data Analysis | [Analyze tradingview.com charts with Chrome extension, N8N and OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Analyze%20tradingview.com%20charts%20with%20Chrome%20extension,%20N8N%20and%20OpenAI.json) |\n| Automated Hugging Face Paper Summary Fetching & Categorization Workflow | Automates fetching, summarizing, and categorizing research papers from Hugging Face. | AI Research | [Automated Hugging Face Paper Summary Fetching & Categorization Workflow.txt](./AI_Research_RAG_and_Data_Analysis/Automated%20Hugging%20Face%20Paper%20Summary%20Fetching%20%26%20Categorization%20Workflow.json) |\n| Autonomous AI crawler | An autonomous AI-powered web crawler for data collection and analysis. | AI Research | [Autonomous AI crawler.txt](./AI_Research_RAG_and_Data_Analysis/Autonomous%20AI%20crawler.json) |\n| Build Your Own Image Search Using AI Object Detection, CDN and ElasticSearch | Builds an image search engine using AI object detection, CDN, and Elasticsearch for efficient image retrieval. | AI Research | [Build Your Own Image Search Using AI Object Detection, CDN and ElasticSearchBuild Your Own Image Search Using AI Object Detection, CDN and ElasticSearch.txt](./AI_Research_RAG_and_Data_Analysis/Build%20Your%20Own%20Image%20Search%20Using%20AI%20Object%20Detection,%20CDN%20and%20ElasticSearchBuild%20Your%20Own%20Image%20Search%20Using%20AI%20Object%20Detection,%20CDN%20and%20ElasticSearch.json) |\n| Build a Financial Documents Assistant using Qdrant and Mistral.ai | Creates an AI assistant for financial document analysis using Qdrant for vector search and Mistral.ai for language processing. | Finance, AI Research | [Build a Financial Documents Assistant using Qdrant and Mistral.ai.txt](./AI_Research_RAG_and_Data_Analysis/Build%20a%20Financial%20Documents%20Assistant%20using%20Qdrant%20and%20Mistral.ai.json) |\n| Build a Tax Code Assistant with Qdrant, Mistral.ai and OpenAI | Develops an AI assistant for tax code queries using Qdrant, Mistral.ai, and OpenAI for comprehensive responses. | Finance, AI Research | [Build a Tax Code Assistant with Qdrant, Mistral.ai and OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Build%20a%20Tax%20Code%20Assistant%20with%20Qdrant,%20Mistral.ai%20and%20OpenAI.json) |\n| Building RAG Chatbot for Movie Recommendations with Qdrant and Open AI | Constructs a RAG-based chatbot for movie recommendations, leveraging Qdrant for retrieval and OpenAI for generation. | AI Research, Entertainment | [Building RAG Chatbot for Movie Recommendations with Qdrant and Open AI.txt](./AI_Research_RAG_and_Data_Analysis/Building%20RAG%20Chatbot%20for%20Movie%20Recommendations%20with%20Qdrant%20and%20Open%20AI.json) |\n| Chat with GitHub API Documentation: RAG-Powered Chatbot with Pinecone & OpenAI | Implements a RAG-powered chatbot for interacting with GitHub API documentation using Pinecone and OpenAI. | Development, AI Research | [Chat with GitHub API Documentation_ RAG-Powered Chatbot with Pinecone & OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Chat%20with%20GitHub%20API%20Documentation_%20RAG-Powered%20Chatbot%20with%20Pinecone%20%26%20OpenAI.json) |\n| Create a Google Analytics Data Report with AI and sent it to E-Mail and Telegram | Generates Google Analytics data reports using AI and sends them via email and Telegram. | Data Analysis, Marketing | [Create a Google Analytics Data Report with AI and sent it to E-Mail and Telegram.txt](./AI_Research_RAG_and_Data_Analysis/Create%20a%20Google%20Analytics%20Data%20Report%20with%20AI%20and%20sent%20it%20to%20E-Mail%20and%20Telegram.json) |\n| Customer Insights with Qdrant, Python and Information Extractor | Extracts customer insights using Qdrant, Python, and an information extraction module. | Data Analysis, Customer Service | [Customer Insights with Qdrant, Python and Information Extractor.txt](./AI_Research_RAG_and_Data_Analysis/Customer%20Insights%20with%20Qdrant,%20Python%20and%20Information%20Extractor.json) |\n| Deduplicate Scraping AI Grants for Eligibility using AI | Automates the deduplication and eligibility assessment of scraped AI grant data using AI. | AI Research, Data Management | [Deduplicate Scraping AI Grants for Eligibility using AI.txt](./AI_Research_RAG_and_Data_Analysis/Deduplicate%20Scraping%20AI%20Grants%20for%20Eligibility%20using%20AI.json) |\n| Enrich Property Inventory Survey with Image Recognition and AI Agent | Enhances property inventory surveys with image recognition and AI agents for automated data enrichment. | Real Estate, AI Research | [Enrich Property Inventory Survey with Image Recognition and AI Agent.txt](./AI_Research_RAG_and_Data_Analysis/Enrich%20Property%20Inventory%20Survey%20with%20Image%20Recognition%20and%20AI%20Agent.json) |\n| Extract insights & analyse YouTube comments via AI Agent chat | Extracts insights and analyzes YouTube comments through an AI agent chat interface. | Social Media, Data Analysis | [Extract insights & analyse YouTube comments via AI Agent chat.txt](./AI_Research_RAG_and_Data_Analysis/Extract%20insights%20%26%20analyse%20YouTube%20comments%20via%20AI%20Agent%20chat.json) |\n| Generate SEO Seed Keywords Using AI | Generates SEO seed keywords using AI to optimize content for search engines. | Marketing, AI Research | [Generate SEO Seed Keywords Using AI.txt](./AI_Research_RAG_and_Data_Analysis/Generate%20SEO%20Seed%20Keywords%20Using%20AI.json) |\n| Hacker News Job Listing Scraper and Parser | Scrapes and parses job listings from Hacker News for job seekers or recruiters. | Data Collection, HR | [Hacker News Job Listing Scraper and Parser.txt](./AI_Research_RAG_and_Data_Analysis/Hacker%20News%20Job%20Listing%20Scraper%20and%20Parser.json) |\n| Hacker News to Video Content | Converts Hacker News articles into video content automatically. | Content Creation, Media | [Hacker News to Video Content.txt](./AI_Research_RAG_and_Data_Analysis/Hacker%20News%20to%20Video%20Content.json) |\n| Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3 | Sets up a self-hosted AI deep research agent using n8n, Apify, and OpenAI. | AI Research, Automation | [Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt](./AI_Research_RAG_and_Data_Analysis/Host%20Your%20Own%20AI%20Deep%20Research%20Agent%20with%20n8n,%20Apify%20and%20OpenAI%20o3.json) |\n| Intelligent Web Query and Semantic Re-Ranking Flow using Brave and Google Gemini | Performs intelligent web queries and semantic re-ranking using Brave browser and Google Gemini AI. | AI Research, Data Analysis | [Intelligent Web Query and Semantic Re-Ranking Flow using Brave and Google Gemini.txt](./AI_Research_RAG_and_Data_Analysis/Intelligent%20Web%20Query%20and%20Semantic%20Re-Ranking%20Flow%20using%20Brave%20and%20Google%20Gemini.json) |\n| Learn Anything from HN - Get Top Resource Recommendations from Hacker News | Extracts top resource recommendations from Hacker News to facilitate learning on any topic. | Education, Data Analysis | [Learn Anything from HN - Get Top Resource Recommendations from Hacker News.txt](./AI_Research_RAG_and_Data_Analysis/Learn%20Anything%20from%20HN%20-%20Get%20Top%20Resource%20Recommendations%20from%20Hacker%20News.json) |\n| Make OpenAI Citation for File Retrieval RAG | Generates citations for file retrieval in RAG systems using OpenAI. | AI Research, Documentation | [Make OpenAI Citation for File Retrieval RAG.txt](./AI_Research_RAG_and_Data_Analysis/Make%20OpenAI%20Citation%20for%20File%20Retrieval%20RAG.json) |\n| Open Deep Research - AI-Powered Autonomous Research Workflow | An AI-powered autonomous workflow for conducting deep research. | AI Research, Automation | [Open Deep Research - AI-Powered Autonomous Research Workflow.txt](./AI_Research_RAG_and_Data_Analysis/Open%20Deep%20Research%20-%20AI-Powered%20Autonomous%20Research%20Workflow.json) |\n| Query Perplexity AI from your n8n workflows | Integrates Perplexity AI into n8n workflows for advanced querying capabilities. | AI Research, Automation | [Query Perplexity AI from your n8n workflows.txt](./AI_Research_RAG_and_Data_Analysis/Query%20Perplexity%20AI%20from%20your%20n8n%20workflows.json) |\n| Recipe Recommendations with Qdrant and Mistral | Provides recipe recommendations using Qdrant for vector search and Mistral AI for content generation. | Food, AI Research | [Recipe Recommendations with Qdrant and Mistral.txt](./AI_Research_RAG_and_Data_Analysis/Recipe%20Recommendations%20with%20Qdrant%20and%20Mistral.json) |\n| Reconcile Rent Payments with Local Excel Spreadsheet and OpenAI | Reconciles rent payments by comparing local Excel spreadsheets with data processed by OpenAI. | Finance, Data Management | [Reconcile Rent Payments with Local Excel Spreadsheet and OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Reconcile%20Rent%20Payments%20with%20Local%20Excel%20Spreadsheet%20and%20OpenAI.json) |\n| Scrape Trustpilot Reviews with DeepSeek, Analyze Sentiment with OpenAI | Scrapes Trustpilot Reviews using DeepSeek and analyzes sentiment with OpenAI. | Marketing, Data Analysis | [Scrape Trustpilot Reviews with DeepSeek, Analyze Sentiment with OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Scrape%20Trustpilot%20Reviews%20with%20DeepSeek,%20Analyze%20Sentiment%20with%20OpenAI.json) |\n| Scrape and summarize posts of a news site without RSS feed using AI and save them to a NocoDB | Scrapes and summarizes news posts without RSS feeds using AI, saving the output to NocoDB. | Content Curation, Data Management | [Scrape and summarize posts of a news site without RSS feed using AI and save them to a NocoDB.txt](./AI_Research_RAG_and_Data_Analysis/Scrape%20and%20summarize%20posts%20of%20a%20news%20site%20without%20RSS%20feed%20using%20AI%20and%20save%20them%20to%20a%20NocoDB.json) |\n| Scrape and summarize webpages with AI | Scrapes and summarizes content from webpages using AI. | Content Curation, Data Analysis | [Scrape and summarize webpages with AI.txt](./AI_Research_RAG_and_Data_Analysis/Scrape%20and%20summarize%20webpages%20with%20AI.json) |\n| Send Google analytics data to A.I. to analyze then save results in Baserow | Sends Google Analytics data to AI for analysis and saves the results in Baserow. | Data Analysis, Marketing | [Send Google analytics data to A.I. to analyze then save results in Baserow.txt](./AI_Research_RAG_and_Data_Analysis/Send%20Google%20analytics%20data%20to%20A.I.%20to%20analyze%20then%20save%20results%20in%20Baserow.json) |\n| Spot Workplace Discrimination Patterns with AI | Identifies patterns of workplace discrimination using AI-driven analysis. | HR, AI Research | [Spot Workplace Discrimination Patterns with AI.txt](./AI_Research_RAG_and_Data_Analysis/Spot%20Workplace%20Discrimination%20Patterns%20with%20AI.json) |\n| Summarize SERPBear data with AI (via Openrouter) and save it to Baserow | Summarizes SERPBear data using AI (via Openrouter) and saves the insights to Baserow. | SEO, Data Analysis | [Summarize SERPBear data with AI (via Openrouter) and save it to Baserow.txt](./AI_Research_RAG_and_Data_Analysis/Summarize%20SERPBear%20data%20with%20AI%20(via%20Openrouter)%20and%20save%20it%20to%20Baserow.json) |\n| Summarize Umami data with AI (via Openrouter) and save it to Baserow | Summarizes Umami analytics data using AI (via Openrouter) and saves the insights to Baserow. | Data Analysis, Marketing | [Summarize Umami data with AI (via Openrouter) and save it to Baserow.txt](./AI_Research_RAG_and_Data_Analysis/Summarize%20Umami%20data%20with%20AI%20(via%20Openrouter)%20and%20save%20it%20to%20Baserow.json) |\n| Survey Insights with Qdrant, Python and Information Extractor | Extracts and analyzes insights from survey data using Qdrant, Python, and an information extractor. | Data Analysis, Market Research | [Survey Insights with Qdrant, Python and Information Extractor.txt](./AI_Research_RAG_and_Data_Analysis/Survey%20Insights%20with%20Qdrant,%20Python%20and%20Information%20Extractor.json) |\n| Ultimate Scraper Workflow for n8n | A comprehensive scraping workflow for n8n to extract data from various sources. | Data Collection, Automation | [Ultimate Scraper Workflow for n8n.txt](./AI_Research_RAG_and_Data_Analysis/Ultimate%20Scraper%20Workflow%20for%20n8n.json) |\n| Vector Database as a Big Data Analysis Tool for AI Agents [1/3 anomaly][1/2 KNN] | Utilizes a vector database for big data analysis, focusing on anomaly detection and KNN classification for AI agents. | AI Research, Data Analysis | [Vector Database as a Big Data Analysis Tool for AI Agents [1_3 anomaly][1_2 KNN].txt](./AI_Research_RAG_and_Data_Analysis/Vector%20Database%20as%20a%20Big%20Data%20Analysis%20Tool%20for%20AI%20Agents%20[1_3%20anomaly][1_2%20KNN].json) |\n| Vector Database as a Big Data Analysis Tool for AI Agents [2/2 KNN] | Continues the use of a vector database for big data analysis, focusing on KNN classification for AI agents. | AI Research, Data Analysis | [Vector Database as a Big Data Analysis Tool for AI Agents [2_2 KNN].txt](./AI_Research_RAG_and_Data_Analysis/Vector%20Database%20as%20a%20Big%20Data%20Analysis%20Tool%20for%20AI%20Agents%20[2_2%20KNN].json) |\n| Vector Database as a Big Data Analysis Tool for AI Agents [2/3 - anomaly] | Explores the use of a vector database for big data analysis, focusing on anomaly detection for AI agents. | AI Research, Data Analysis | [Vector Database as a Big Data Analysis Tool for AI Agents [2_3 - anomaly].txt](./AI_Research_RAG_and_Data_Analysis/Vector%20Database%20as%20a%20Big%20Data%20Analysis%20Tool%20for%20AI%20Agents%20[2_3%20-%20anomaly].json) |\n| Vector Database as a Big Data Analysis Tool for AI Agents [3/3 - anomaly] | Concludes the use of a vector database for big data analysis, focusing on anomaly detection for AI agents. | AI Research, Data Analysis | [Vector Database as a Big Data Analysis Tool for AI Agents [3_3 - anomaly].txt](./AI_Research_RAG_and_Data_Analysis/Vector%20Database%20as%20a%20Big%20Data%20Analysis%20Tool%20for%20AI%20Agents%20[3_3%20-%20anomaly].json) |\n| Visual Regression Testing with Apify and AI Vision Model | Performs visual regression testing using Apify and an AI vision model to detect UI changes. | QA, AI Research | [Visual Regression Testing with Apify and AI Vision Model.txt](./AI_Research_RAG_and_Data_Analysis/Visual%20Regression%20Testing%20with%20Apify%20and%20AI%20Vision%20Model.json) |\n| 🔍 Perplexity Research to HTML: AI-Powered Content Creation | Transforms Perplexity AI research into HTML content for AI-powered content creation. | Content Creation, AI Research | [🔍 Perplexity Research to HTML_ AI-Powered Content Creation.txt](./AI_Research_RAG_and_Data_Analysis/%F0%9F%94%8D%20Perplexity%20Research%20to%20HTML_%20AI-Powered%20Content%20Creation.json) |\n\n\n### **Other**\n\n- ALL_unique_nodes.txt (node reference)\n\n... and more !\n\n---\n\nIf you would like to contribute additional templates or suggest new categories, feel free to open an issue or pull request!\n\n---\n\n👉 [Join n8n and start automating now! 💎](https://n8n.partnerlinks.io/h1pwwf5m4toe)\n<a href=\"https://n8n.partnerlinks.io/h1pwwf5m4toe\">\n  <img src=\"/img/n8n.png\" alt=\"n8n\" style=\"max-height: 300px;\">\n</a>\n\n---\n\n### **Sponsors**\n- [mahezsh](https://github.com/mahezsh)\n"
        },
        {
            "url": "https://github.com/PixiEditor/PixiEditor",
            "language": "C#",
            "description": "PixiEditor is a Universal Editor for all your 2D needs",
            "readme_summary": "<div align=\"center\">\n\n[![Release](https://img.shields.io/github/v/release/flabbet/PixiEditor)](https://github.com/flabbet/PixiEditor/releases) \n[![Downloads](https://img.shields.io/github/downloads/PixiEditor/PixiEditor/total)](https://github.com/flabbet/PixiEditor/releases)\n[![Discord Server](https://badgen.net/badge/discord/join%20chat/7289DA?icon=discord)](https://discord.gg/qSRMYmq)\n[![Subreddit subscribers](https://img.shields.io/reddit/subreddit-subscribers/PixiEditor?label=%20r%2FPixiEditor&logoColor=%23e3002d)](https://reddit.com/r/PixiEditor)\n[![Forum](https://img.shields.io/badge/PixiEditor-Forum-red?link=https%3A%2F%2Fforum.pixieditor.net%2F)](https://forum.pixieditor.net/)\n\n<img width=\"50%\" align=\"center\" src=\"https://github.com/user-attachments/assets/bd08c8bd-f610-449d-b1e2-6a990e562518\">\n\n## The only 2D Graphics Editor you'll ever need\n\n**PixiEditor** is a universal 2D editor that was made to provide you with tools and features for all your 2D needs. Create beautiful sprites for your games, animations, edit images, create logos. All packed up in an intuitive and familiar interface.\n\n<a href=\"https://pixieditor.net/download\"><img src=\"https://github.com/nnakocaj/supreme-train/blob/main/download1.png\" width=\"250\" alt=\"Download\"/></a>\n\n</div>\n\n![](https://github.com/nnakocaj/supreme-train/blob/main/interface.png)\n\n### Toolsets for any scenario\n\nPixiEditor 2.0 comes by default with 3 toolsets: \n- **Pixel art** - it contains tool suited for pixel-perfect scenarios\n- **Painting** - basic painting tools, soft brushes, anti aliased shapes\n- **Vector** - shapes and paths for creating vectors\n\nAll **toolsets can be used on one canvas**. Mix vector with raster. Export to png, jpg, svg, gif, mp4 and more!\n\n<p align=\"center\">\n  <img src=\"https://github.com/nnakocaj/supreme-train/blob/main/toolsets.gif?raw=true\" width=\"70%\" />\n</p>\n\n### Animations\n\nVersion 2.0 comes with a timeline and animation capabilities. You can create frame by frame animations or use nodes to animate your custom shaders.\nKey frame animations with vectors are on our roadmap.\n\n![](https://github.com/nnakocaj/supreme-train/blob/main/timeline1.png)\n\n### Nodes\n\nNode render system is what powers such extensive capabilities. All layers, effects and the layer structure are nodes or a result of its connections. PixiEditor exposes node graph for every document, so you are free to customize your image however you want and create procedural art/animations!\n\n![](https://github.com/nnakocaj/supreme-train/blob/main/node.png)\n\n## Building from source\n\n<p>Check out our <a href=\"https://pixieditor.net/docs/contribution/compileguide/\">Compile Guide</a></p>\n\n## Contributing\n\n<p>For a seamless collaboration <a href=\"https://pixieditor.net/docs/contribution/starthere//\">Start Here</a></p>\n\n## Help\n\n<p>Got stuck? We are here to <a href=\"https://pixieditor.net/help\">Help</a></p>\n\n\n</br></br>\n\n\n<div align=\"center\">\n    <a href=\"https://discord.gg/DwaXAuXVzv\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/discord.png\" alt=\"discord\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://store.steampowered.com/app/2218560/PixiEditor__Pixel_Art_Editor/\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/steam.png\" alt=\"steam\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://www.youtube.com/@PixiEditor\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/youtube.png\" alt=\"youtube\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://twitter.com/PixiEditor\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/twitter.png\" alt=\"twitter\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://www.reddit.com/r/PixiEditor\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/reddit.png\" alt=\"reddit\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://www.linkedin.com/company/pixieditor\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/linkedin.png\" alt=\"linkedin\" width=50/></a>\n</div>\n"
        },
        {
            "url": "https://github.com/immich-app/immich",
            "language": "TypeScript",
            "description": "High performance self-hosted photo and video management solution.",
            "readme_summary": "<p align=\"center\"> \n  <br/>\n  <a href=\"https://opensource.org/license/agpl-v3\"><img src=\"https://img.shields.io/badge/License-AGPL_v3-blue.svg?color=3F51B5&style=for-the-badge&label=License&logoColor=000000&labelColor=ececec\" alt=\"License: AGPLv3\"></a>\n  <a href=\"https://discord.immich.app\">\n    <img src=\"https://img.shields.io/discord/979116623879368755.svg?label=Discord&logo=Discord&style=for-the-badge&logoColor=000000&labelColor=ececec\" alt=\"Discord\"/>\n  </a>\n  <br/>\n  <br/>\n</p>\n\n<p align=\"center\">\n<img src=\"design/immich-logo-stacked-light.svg\" width=\"300\" title=\"Login With Custom URL\">\n</p>\n<h3 align=\"center\">High performance self-hosted photo and video management solution</h3>\n<br/>\n<a href=\"https://immich.app\">\n<img src=\"design/immich-screenshots.png\" title=\"Main Screenshot\">\n</a>\n<br/>\n\n<p align=\"center\">\n  <a href=\"readme_i18n/README_ca_ES.md\">Català</a>\n  <a href=\"readme_i18n/README_es_ES.md\">Español</a>\n  <a href=\"readme_i18n/README_fr_FR.md\">Français</a>\n  <a href=\"readme_i18n/README_it_IT.md\">Italiano</a>\n  <a href=\"readme_i18n/README_ja_JP.md\">日本語</a>\n  <a href=\"readme_i18n/README_ko_KR.md\">한국어</a>\n  <a href=\"readme_i18n/README_de_DE.md\">Deutsch</a>\n  <a href=\"readme_i18n/README_nl_NL.md\">Nederlands</a>\n  <a href=\"readme_i18n/README_tr_TR.md\">Türkçe</a>\n  <a href=\"readme_i18n/README_zh_CN.md\">中文</a>\n  <a href=\"readme_i18n/README_uk_UA.md\">Українська</a>\n  <a href=\"readme_i18n/README_ru_RU.md\">Русский</a>\n  <a href=\"readme_i18n/README_pt_BR.md\">Português Brasileiro</a>\n  <a href=\"readme_i18n/README_sv_SE.md\">Svenska</a>\n  <a href=\"readme_i18n/README_ar_JO.md\">العربية</a>\n  <a href=\"readme_i18n/README_vi_VN.md\">Tiếng Việt</a>\n  <a href=\"readme_i18n/README_th_TH.md\">ภาษาไทย</a>\n</p>\n\n## Disclaimer\n\n- ⚠️ The project is under **very active** development.\n- ⚠️ Expect bugs and breaking changes.\n- ⚠️ **Do not use the app as the only way to store your photos and videos.**\n- ⚠️ Always follow [3-2-1](https://www.backblaze.com/blog/the-3-2-1-backup-strategy/) backup plan for your precious photos and videos!\n\n> [!NOTE]\n> You can find the main documentation, including installation guides, at https://immich.app/.\n\n## Links\n\n- [Documentation](https://immich.app/docs)\n- [About](https://immich.app/docs/overview/introduction)\n- [Installation](https://immich.app/docs/install/requirements)\n- [Roadmap](https://immich.app/roadmap)\n- [Demo](#demo)\n- [Features](#features)\n- [Translations](https://immich.app/docs/developer/translations)\n- [Contributing](https://immich.app/docs/overview/support-the-project)\n\n## Demo\n\nAccess the demo [here](https://demo.immich.app). For the mobile app, you can use `https://demo.immich.app` for the `Server Endpoint URL`.\n\n### Login credentials\n\n| Email           | Password |\n| --------------- | -------- |\n| demo@immich.app | demo     |\n\n## Features\n\n| Features                                     | Mobile | Web |\n| :------------------------------------------- | ------ | --- |\n| Upload and view videos and photos            | Yes    | Yes |\n| Auto backup when the app is opened           | Yes    | N/A |\n| Prevent duplication of assets                | Yes    | Yes |\n| Selective album(s) for backup                | Yes    | N/A |\n| Download photos and videos to local device   | Yes    | Yes |\n| Multi-user support                           | Yes    | Yes |\n| Album and Shared albums                      | Yes    | Yes |\n| Scrubbable/draggable scrollbar               | Yes    | Yes |\n| Support raw formats                          | Yes    | Yes |\n| Metadata view (EXIF, map)                    | Yes    | Yes |\n| Search by metadata, objects, faces, and CLIP | Yes    | Yes |\n| Administrative functions (user management)   | No     | Yes |\n| Background backup                            | Yes    | N/A |\n| Virtual scroll                               | Yes    | Yes |\n| OAuth support                                | Yes    | Yes |\n| API Keys                                     | N/A    | Yes |\n| LivePhoto/MotionPhoto backup and playback    | Yes    | Yes |\n| Support 360 degree image display             | No     | Yes |\n| User-defined storage structure               | Yes    | Yes |\n| Public Sharing                               | Yes    | Yes |\n| Archive and Favorites                        | Yes    | Yes |\n| Global Map                                   | Yes    | Yes |\n| Partner Sharing                              | Yes    | Yes |\n| Facial recognition and clustering            | Yes    | Yes |\n| Memories (x years ago)                       | Yes    | Yes |\n| Offline support                              | Yes    | No  |\n| Read-only gallery                            | Yes    | Yes |\n| Stacked Photos                               | Yes    | Yes |\n| Tags                                         | No     | Yes |\n| Folder View                                  | Yes    | Yes |\n\n## Translations\n\nRead more about translations [here](https://immich.app/docs/developer/translations).\n\n<a href=\"https://hosted.weblate.org/engage/immich/\">\n<img src=\"https://hosted.weblate.org/widget/immich/immich/multi-auto.svg\" alt=\"Translation status\" />\n</a>\n\n## Repository activity\n\n![Activities](https://repobeats.axiom.co/api/embed/9e86d9dc3ddd137161f2f6d2e758d7863b1789cb.svg \"Repobeats analytics image\")\n\n## Star history\n\n<a href=\"https://star-history.com/#immich-app/immich&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=immich-app/immich&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=immich-app/immich&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=immich-app/immich&type=Date\" width=\"100%\" />\n </picture>\n</a>\n\n## Contributors\n\n<a href=\"https://github.com/alextran1502/immich/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=immich-app/immich\" width=\"100%\"/>\n</a>\n"
        },
        {
            "url": "https://github.com/Shubhamsaboo/awesome-llm-apps",
            "language": "Python",
            "description": "Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.",
            "readme_summary": "<p align=\"center\">\n  <a href=\"http://www.theunwindai.com\">\n    <img src=\"docs/banner/unwind_black.png\" width=\"900px\" alt=\"Unwind AI\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.linkedin.com/in/shubhamsaboo/\">\n    <img src=\"https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&style=flat-square\" alt=\"LinkedIn\">\n  </a>\n  <a href=\"https://twitter.com/Saboo_Shubham_\">\n    <img src=\"https://img.shields.io/twitter/follow/Shubham_Saboo\" alt=\"Twitter\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <!-- Keep these links. Translations will automatically update with the README. -->\n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de\">Deutsch</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es\">Español</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr\">français</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja\">日本語</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko\">한국어</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt\">Português</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru\">Русский</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh\">中文</a>\n</p>\n\n<hr/>\n\n# 🌟 Awesome LLM Apps\n\nA curated collection of **Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.** This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/9876\" target=\"_blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/9876\" alt=\"Shubhamsaboo%2Fawesome-llm-apps | Trendshift\" style=\"width: 250px; height: 55px;\" />\n  </a>\n</p>\n\n## 🤔 Why Awesome LLM Apps?\n\n- 💡 Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.\n- 🔥 Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP & RAG.\n- 🎓 Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.\n\n## 📂 Featured AI Projects\n\n### AI Agents\n\n### 🌱 Starter AI Agents\n\n*   [🎙️ AI Blog to Podcast Agent](starter_ai_agents/ai_blog_to_podcast_agent/)\n*   [❤️‍🩹 AI Breakup Recovery Agent](starter_ai_agents/ai_breakup_recovery_agent/)\n*   [📊 AI Data Analysis Agent](starter_ai_agents/ai_data_analysis_agent/)\n*   [🩻 AI Medical Imaging Agent](starter_ai_agents/ai_medical_imaging_agent/)\n*   [😂 AI Meme Generator Agent (Browser)](starter_ai_agents/ai_meme_generator_agent_browseruse/)\n*   [🎵 AI Music Generator Agent](starter_ai_agents/ai_music_generator_agent/)\n*   [🛫 AI Travel Agent (Local & Cloud)](starter_ai_agents/ai_travel_agent/)\n*   [✨ Gemini Multimodal Agent](starter_ai_agents/gemini_multimodal_agent_demo/)\n*   [🌐 Local News Agent (OpenAI Swarm)](starter_ai_agents/local_news_agent_openai_swarm/)\n*   [🔄 Mixture of Agents](starter_ai_agents/mixture_of_agents/)\n*   [📊 xAI Finance Agent](starter_ai_agents/xai_finance_agent/)\n*   [🔍 OpenAI Research Agent](starter_ai_agents/opeani_research_agent/)\n*   [🕸️ Web Scrapping AI Agent (Local & Cloud)](starter_ai_agents/web_scrapping_ai_agent/)\n\n### 🚀 Advanced AI Agents\n\n*   [🔍 AI Deep Research Agent](advanced_ai_agents/single_agent_apps/ai_deep_research_agent/)\n*   [🤝 AI Consultant Agent](advanced_ai_agents/single_agent_apps/ai_consultant_agent)\n*   [🏗️ AI System Architect Agent](advanced_ai_agents/single_agent_apps/ai_system_architect_r1/)\n*   [🎯 AI Lead Generation Agent](advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/)\n*   [💰 AI Financial Coach Agent](advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/)\n*   [🎬 AI Movie Production Agent](advanced_ai_agents/single_agent_apps/ai_movie_production_agent/)\n*   [📈 AI Investment Agent](advanced_ai_agents/single_agent_apps/ai_investment_agent/)\n*   [🏋️‍♂️ AI Health & Fitness Agent](advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/)\n*   [🚀 AI Product Launch Intelligence Agent](advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent)\n*   [🗞️ AI Journalist Agent](advanced_ai_agents/single_agent_apps/ai_journalist_agent/)\n*   [🧠 AI Mental Wellbeing Agent](advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/)\n*   [📑 AI Meeting Agent](advanced_ai_agents/single_agent_apps/ai_meeting_agent/)\n*   [🧬 AI Self-Evolving Agent](advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/)\n*   [🎧 AI Social Media News and Podcast Agent](advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/)\n\n### 🎮 Autonomous Game Playing Agents\n\n*   [🎮 AI 3D Pygame Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/)\n*   [♜ AI Chess Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/)\n*   [🎲 AI Tic-Tac-Toe Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/)\n\n### 🤝 Multi-agent Teams\n\n*   [🧲 AI Competitor Intelligence Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/)\n*   [💲 AI Finance Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/)\n*   [🎨 AI Game Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/)\n*   [👨‍⚖️ AI Legal Agent Team (Cloud & Local)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/)\n*   [💼 AI Recruitment Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/)\n*   [🏠 AI Real Estate Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team)\n*   [👨‍💼 AI Services Agency (CrewAI)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/)\n*   [👨‍🏫 AI Teaching Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/)\n*   [💻 Multimodal Coding Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/)\n*   [✨ Multimodal Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/)\n*   [🌏 AI Travel Planner Agent Team](/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/)\n\n### 🗣️ Voice AI Agents\n\n*   [🗣️ AI Audio Tour Agent](voice_ai_agents/ai_audio_tour_agent/)\n*   [📞 Customer Support Voice Agent](voice_ai_agents/customer_support_voice_agent/)\n*   [🔊 Voice RAG Agent (OpenAI SDK)](voice_ai_agents/voice_rag_openaisdk/)\n\n\n### 🌐 MCP AI Agents\n\n*   [♾️ Browser MCP Agent](mcp_ai_agents/browser_mcp_agent/)\n*   [🐙 GitHub MCP Agent](mcp_ai_agents/github_mcp_agent/)\n*   [📑 Notion MCP Agent](mcp_ai_agents/notion_mcp_agent) \n*   [🌍 AI Travel Planner MCP Agent](mcp_ai_agents/ai_travel_planner_mcp_agent_team)\n\n### 📀 RAG (Retrieval Augmented Generation)\n*   [🔗 Agentic RAG](rag_tutorials/agentic_rag/)\n*   [🧐 Agentic RAG with Reasoning](rag_tutorials/agentic_rag_with_reasoning/)\n*   [📰 AI Blog Search (RAG)](rag_tutorials/ai_blog_search/)\n*   [🔍 Autonomous RAG](rag_tutorials/autonomous_rag/)\n*   [🔄 Corrective RAG (CRAG)](rag_tutorials/corrective_rag/)\n*   [🐋 Deepseek Local RAG Agent](rag_tutorials/deepseek_local_rag_agent/)\n*   [🤔 Gemini Agentic RAG](rag_tutorials/gemini_agentic_rag/)\n*   [👀 Hybrid Search RAG (Cloud)](rag_tutorials/hybrid_search_rag/)\n*   [🔄 Llama 3.1 Local RAG](rag_tutorials/llama3.1_local_rag/)\n*   [🖥️ Local Hybrid Search RAG](rag_tutorials/local_hybrid_search_rag/)\n*   [🦙 Local RAG Agent](rag_tutorials/local_rag_agent/)\n*   [🧩 RAG-as-a-Service](rag_tutorials/rag-as-a-service/)\n*   [✨ RAG Agent with Cohere](rag_tutorials/rag_agent_cohere/)\n*   [⛓️ Basic RAG Chain](rag_tutorials/rag_chain/)\n*   [📠 RAG with Database Routing](rag_tutorials/rag_database_routing/)\n*   [🖼️ Vision RAG](rag_tutorials/vision_rag/)\n\n### 💾 LLM Apps with Memory Tutorials\n\n*   [💾 AI ArXiv Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/)\n*   [🛩️ AI Travel Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/)\n*   [💬 Llama3 Stateful Chat](advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/)\n*   [📝 LLM App with Personalized Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/)\n*   [🗄️ Local ChatGPT Clone with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/)\n*   [🧠 Multi-LLM Application with Shared Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/)\n\n\n### 💬 Chat with X Tutorials\n\n*   [💬 Chat with GitHub (GPT & Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_github/)\n*   [📨 Chat with Gmail](advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/)\n*   [📄 Chat with PDF (GPT & Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/)\n*   [📚 Chat with Research Papers (ArXiv) (GPT & Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/)\n*   [📝 Chat with Substack](advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/)\n*   [📽️ Chat with YouTube Videos](advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/)\n\n### 🔧 LLM Fine-tuning Tutorials\n\n*   [🔧 Llama 3.2 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/)\n\n### 🧑‍🏫 AI Agent Framework Crash Course\n\n- [Google ADK Crash Course](ai_agent_framework_crash_course/google_adk_crash_course/)\n  - Starter agent; model‑agnostic (OpenAI, Claude)\n  - Structured outputs (Pydantic)\n  - Tools: built‑in, function, third‑party, MCP tools\n  - Memory; callbacks; Plugins\n  - Simple multi‑agent; Multi‑agent patterns\n\n## 🚀 Getting Started\n\n1. **Clone the repository** \n\n    ```bash \n    git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git \n    ```\n\n2. **Navigate to the desired project directory**\n\n    ```bash \n    cd awesome-llm-apps/starter_ai_agents/ai_travel_agent\n    ```\n\n3. **Install the required dependencies**\n\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n4. **Follow the project-specific instructions** in each project's `README.md` file to set up and run the app.\n\n## 🤝 Contributing to Open Source\n\nContributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new [GitHub Issue](https://github.com/Shubhamsaboo/awesome-llm-apps/issues) or submit a pull request. Make sure to follow the existing project structure and include a detailed `README.md` for each new app.\n\n### Thank You, Community, for the Support! 🙏\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&type=Date)](https://star-history.com/#Shubhamsaboo/awesome-llm-apps&Date)\n\n🌟 **Don’t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.**\n"
        },
        {
            "url": "https://github.com/MotiaDev/motia",
            "language": "TypeScript",
            "description": "Modern Backend Framework that unifies APIs, background jobs, workflows, and AI agents into a single cohesive system with built-in observability and state management.",
            "readme_summary": "<a href=\"https://motia.dev\">\n  <img src=\"assets/github-readme-banner.png\" alt=\"Motia Banner\" width=\"100%\">\n</a>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/14032\" style=\"margin-right:8px;\">\n    <img src=\"https://trendshift.io/api/badge/repositories/14032\" alt=\"Motia\" style=\"width: 250px; height: 55px; margin-right:8px;\" width=\"250\" height=\"55\"/>\n  </a>\n  <a href=\"https://vercel.com/blog/summer-2025-oss-program#motia\" target=\"_blank\" style=\"margin-left:8px;\">\n    <img alt=\"Vercel OSS Program\" src=\"https://vercel.com/oss/program-badge.svg\" style=\"width: 250px; height: 55px; margin-left:8px;\" width=\"250\" height=\"55\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <strong>🔥 The Unified Backend Framework That Eliminates Runtime Fragmentation 🔥</strong>\n</p>\n<p align=\"center\">\n  <em>APIs, background jobs, workflows, and AI agents in one system. JavaScript, TypeScript, Python, and more in one codebase.</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/motia\">\n    <img src=\"https://img.shields.io/npm/v/motia?style=flat&logo=npm&logoColor=white&color=CB3837&labelColor=000000\" alt=\"npm version\">\n  </a>\n  <a href=\"https://github.com/MotiaDev/motia/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-MIT-green?style=flat&logo=opensourceinitiative&logoColor=white&labelColor=000000\" alt=\"license\">\n  </a>\n  <a href=\"https://github.com/MotiaDev/motia\">\n    <img src=\"https://img.shields.io/github/stars/MotiaDev/motia?style=flat&logo=github&logoColor=white&color=yellow&labelColor=000000\" alt=\"GitHub stars\">\n  </a>\n  <a href=\"https://twitter.com/motiadev\" target=\"_blank\">\n    <img src=\"https://img.shields.io/badge/Follow-@motiadev-1DA1F2?style=flat&logo=twitter&logoColor=white&labelColor=000000\" alt=\"Twitter Follow\">\n  </a>\n  <a href=\"https://discord.gg/motia\" target=\"_blank\">\n    <img src=\"https://img.shields.io/discord/1322278831184281721?style=flat&logo=discord&logoColor=white&color=5865F2&label=Discord&labelColor=000000\" alt=\"Discord\">\n  </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://www.motia.dev/manifesto\">💡 Motia Manifesto</a> •\n  <a href=\"https://www.motia.dev/docs/getting-started/quick-start\">🚀 Quick Start</a> •\n  <a href=\"https://www.motia.dev/docs/concepts/steps/defining-steps\">📋 Defining Steps</a> •\n  <a href=\"https://www.motia.dev/docs\">📚 Docs</a>\n</p>\n\n---\n\n## 🎯 What is Motia?\n\n**Motia solves backend fragmentation.** \n\nModern software engineering is splintered – APIs live in one framework, background jobs in another, queues have their own tooling, and AI agents are springing up in yet more isolated runtimes. **This fragmentation demands a unified system.**\n\nMotia unifies APIs, background jobs, workflows, and AI agents into a **single coherent system** with shared observability and developer experience. Similar to how React simplified frontend development where everything is a component, **Motia simplifies backend development where everything is a Step**.\n\nWrite **JavaScript, TypeScript, Python, and more** in the same workflow. **What used to take 5 frameworks to build now comes out of the box with Motia.**\n\n[![Motia combines APIs, background queues, and AI agents into one system](assets/Motia_Github_Repository_GIF.gif)](https://motia.dev)\n\n## 🚀 Quickstart\n\nGet Motia project up and running in **under 60 seconds**:\n\n### 1. Bootstrap a New Motia Project\n\n```bash\nnpx motia@latest create -i   # runs the interactive terminal\n```\n\nFollow the prompts to pick a template, project name, and language.\n\n### 2. Start the Workbench\n\nInside your new project folder, launch the dev server:\n\n```bash\nnpx motia dev # ➜ http://localhost:3000\n```\n\nThis spins up the Motia Workbench – a local UI for building, testing & observing your backend in real-time.\n\n![motia-terminal](assets/motia-terminal.gif)\n\n### 3. Hit Your First Endpoint\n\nOpen a new terminal tab and run:\n\n```bash\ncurl http://localhost:3000/default\n```\n\nYou should see the JSON response:\n\n```json\n{ \"message\": \"Hello World from Motia!\" }\n```\n\n### 4. Explore the Workbench UI\n\n![new-workbench](assets/new-workbench.png)\nThe Workbench is your command centre:\n\n- **🌊 Flows** – Visualise how your Steps connect.\n- **🔌 Endpoints** – Test APIs with one click and stream results live.\n- **👁️ Traces** – Inspect end-to-end traces of every execution.\n- **📊 Logs** – View structured logs grouped by trace.\n- **🏪 State** – Inspect the key-value store across Steps.\n\n---\n\n🎉 **That's it!** You now have a production-ready backend with everything you need:\n\n- ✅ **REST API endpoints** with automatic validation and error handling\n- ✅ **Visual debugger** with real-time flow inspection and tracing  \n- ✅ **Built-in observability** - logs, traces, and state visualization\n- ✅ **Hot-reload** for instant feedback during development\n- ✅ **Event-driven architecture** ready for complex workflows\n- ✅ **Multi-language support** - add Python, Javascript, or other languages anytime\n- ✅ **Zero configuration** - no infrastructure setup required\n\n\n> 💡 **Want a more detailed walkthrough?**  \n> Check out the [Quick Start guide in our docs](https://www.motia.dev/docs/getting-started/quick-start) for step-by-step instructions and more examples.\n\n### 🧱 The Step Philosophy\n\n**Everything is a Step** – similar to how React made everything a component, Motia makes every backend pattern a Step:\n\n- **🎯 Steps Represent Distinct Entry Points**: APIs, background jobs, scheduled tasks, and AI agents – all unified under a single primitive\n- **🌍 Any Language, One Workflow**: Write **JavaScript, TypeScript, Python, and more** in the same project. Use Python for AI agents, TypeScript for APIs, JavaScript for workflows – all sharing state effortlessly  \n- **⚡ Enterprise-Grade, Out of the Box**: Get **event-driven architecture, fault tolerance, observability, and real-time streaming** without complex infrastructure setup\n- **👁️ Automatic Observability**: Complete end-to-end tracing, structured logging, and state visualization. **No setup required** – works in both local development and production\n- **🌊 Composable Workflows**: Connect Steps by emitting and subscribing to events. Build complex, multi-stage processes with simple, declarative code\n- **🏪 Unified State Management**: All Steps share a traced key-value store. Every `get`, `set`, and `delete` is automatically tracked across your entire workflow\n- **🔄 Built-in Fault Tolerance**: Retry mechanisms, error handling, and queue infrastructure abstracted away – focus on business logic, not infrastructure\n\n---\n\n## 🚧 The Fragmentation Problem\n\nToday, backend engineers face several recurring challenges:\n\n- **🧩 Fragmented Systems**: APIs in Express, background jobs in Celery/BullMQ, AI agents in LangChain – each with different deployment, debugging, and scaling patterns\n- **🌐 Multi-Language Barriers**: AI tools in Python, business logic in TypeScript – forcing teams to choose between cutting-edge tech and their existing skillset  \n- **🔍 Observability Gaps**: Tracing requests across multiple frameworks and runtimes is complex and often incomplete\n- **⚖️ Scalability vs. Velocity**: Choose between fast development (monolith) or proper scaling (microservices complexity)\n- **🚀 Deployment Complexity**: Multiple runtimes mean multiple deploy targets, configs, and failure points\n\n**The rapid advancement of AI has made this worse** – many cutting-edge AI tools are only available in specific languages, forcing companies to abandon their existing tech stack or miss out on breakthrough technologies.\n\n---\n\n## ✅ The Motia Solution\n\n**Motia removes this limitation** by unifying your entire backend into a single runtime where everything is a **Step**:\n\n### 🎯 **Unified vs. Fragmented**\n- **Before**: APIs in Express, jobs in BullMQ, AI agents in LangChain\n- **After**: All backend patterns as composable Steps with shared state and observability\n\n### 🌐 **True Multi-Language Support**  \n- **Before**: Choose between Python AI tools OR your existing TypeScript stack\n- **After**: Each Step can be written in any language while sharing common state – use Python for AI, TypeScript for APIs, JavaScript for workflows\n\n### 🔍 **Built-in Observability**\n- **Before**: Complex tracing setups across multiple frameworks\n- **After**: Complete observability toolkit available in both cloud and local environments out of the box\n\n### ⚖️ **Scalability Without Complexity**\n- **Before**: Choose between monolith simplicity or microservice complexity  \n- **After**: Each Step scales independently, avoiding bottlenecks while maintaining development velocity\n\n### 🚀 **One-Click Everything**\n- **Before**: Multiple deployment pipelines, configs, and failure points\n- **After**: Single deployable with atomic blue/green deployments and instant rollbacks\n\n| **Traditional Stack**       | **Motia**                               |\n| --------------------------- | --------------------------------------- |\n| Multiple deployment targets | **Single unified deployment**           |\n| Fragmented observability    | **End-to-end tracing**                  |\n| Language silos              | **JavaScript, TypeScript, Python, etc** |\n| Context-switching overhead  | **Single intuitive model**              |\n| Manual error handling       | **Automatic retries & fault tolerance** |\n| Complex infrastructure      | **Zero-config queue & streaming**       |\n\n---\n\n## 🔧 Supported Step Types\n\n| Type        | Trigger               | Use Case                              |\n| ----------- | --------------------- | ------------------------------------- |\n| **`api`**   | HTTP Request          | Expose REST endpoints                 |\n| **`event`** | Emitted Topics        | React to internal or external events  |\n| **`cron`**  | Scheduled Time (cron) | Automate recurring jobs               |\n| **`noop`**  | None                  | Placeholder for manual/external tasks |\n\n---\n\n### 🤔 How it Works\n\n**One framework. All backend patterns.** Motia replaces your entire backend stack with a single, event-driven system:\n\n**🚀 Replace Multiple Frameworks:**\n- **Instead of**: Express/Nest.js + BullMQ + Temporal + LangChain + custom observability\n- **Use**: Motia Steps with automatic observability, queuing, and multi-language support\n\n**⚡ Simple but Powerful:**\n- **Need a REST API?** Create an `api` step → instant HTTP endpoint with validation, tracing, and error handling\n- **Need background processing?** Emit an event → `event` steps pick it up asynchronously with built-in retries and fault tolerance  \n- **Need scheduled jobs?** Use a `cron` step → automatic scheduling with full observability\n- **Need AI agents?** Write Python steps with access to the entire ecosystem (PyTorch, transformers, etc.) while sharing state with TypeScript APIs\n\n**🔄 Event-Driven by Design:**\nEach Step can emit events that trigger other Steps, creating powerful workflows that automatically handle:\n- **Parallel processing** across multiple languages\n- **Fault tolerance** with automatic retries  \n- **Real-time updates** streamed to clients\n- **Complete traceability** of every operation\n\n**The result?** What used to require 5+ frameworks, complex deployment pipelines, and weeks of infrastructure setup now works out of the box with Motia.\n\n## ⚡ Core Concepts\n\nThe **Step** is Motia's core primitive. The following concepts are deeply integrated with Steps to help you build powerful, complex, and scalable backends:\n\n### 🔑 Steps & Step Types\n\nUnderstand the three ways Steps are triggered:\n\n- **HTTP (`api`)** – Build REST/GraphQL endpoints with zero boilerplate.\n- **Events (`event`)** – React to internal or external events emitted by other steps.\n- **Cron (`cron`)** – Schedule recurring jobs with a familiar cron syntax.\n\n### 📣 Emit & Subscribe (Event-Driven Workflows)\n\nSteps talk to each other by **emitting** and **subscribing** to topics. This decouples producers from consumers and lets you compose complex workflows with simple, declarative code.\n\n### 🏪 State Management\n\nAll steps share a unified key-value state store. Every `get`, `set`, and `delete` is automatically traced so you always know when and where your data changed.\n\n### 📊 Structured Logging\n\nMotia provides structured, JSON logs correlated with trace IDs and step names. Search and filter your logs without regex hassle.\n\n### 📡 Streams: Real-time Messaging\n\nPush live updates from long-running or asynchronous workflows to clients without polling. Perfect for dashboards, progress indicators, and interactive AI agents.\n\n### 👁️ End-to-End Observability with Traces\n\nEvery execution generates a full trace, capturing step timelines, state operations, emits, stream calls, and logs. Visualise everything in the Workbench's Traces UI and debug faster.\n\n---\n\n## 🗂 Production-Ready Examples\n\n**⭐ Explore 20+ sophisticated examples** demonstrating real-world use cases from AI agents to enterprise workflows: **[View All Examples →](https://github.com/MotiaDev/motia-examples)**\n\n### 🤖 **AI Agents & Workflows**\n\n| **AI Deep Research Agent** | **Finance Analysis Agent** | **PDF RAG System** |\n|----------------------------|----------------------------|-------------------|\n| Comprehensive web research with iterative analysis and synthesis | Real-time financial data + AI insights for investment analysis | Document processing with Docling, Weaviate, and OpenAI RAG |\n| [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-deep-research-agent) | [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/finance-agent) | [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate) |\n\n| **GitHub PR Manager** | **Gmail Intelligence** | **Vision Analysis** |\n|-----------------------|------------------------|-------------------|\n| AI-powered PR classification, labeling, and reviewer assignment | Smart email analysis, auto-responses, and Discord summaries | Multi-modal conversation analysis with visual understanding |\n| [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow) | [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/gmail-workflow) | [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/conversation-analyzer-vision) |\n\n### 🌊 **Real-Time Streaming & Chat**\n\n| **Streaming AI Chatbot** | **Real-Time Chat App** | **Live Health Monitor** |\n|--------------------------|------------------------|------------------------|\n| Token-by-token AI responses with WebSocket streaming | Multi-user chat with real-time message processing and moderation | Production uptime monitoring with intelligent Discord alerts |\n| [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/streaming-ai-chatbot) | [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/realtime-chat-application) | [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/realtime-uptime-monitor) |\n\n### ⚡ **Parallel Processing & Workflows** \n\n| **Parallel Execution Demo** | **Content Automation** | **Task Management** |\n|-----------------------------|------------------------|-------------------|\n| Concurrent task processing with workload distribution | Blog-to-Tweet automation with AI content optimization | Trello workflow automation with AI task validation |\n| [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-parallel-execution) | [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/blog-to-tweet-automation) | [View Example →](https://github.com/MotiaDev/motia-examples/tree/main/examples/trello-flow) |\n\n### 🎯 **Key Features Demonstrated:**\n- ✅ **Multi-Language Workflows** - JavaScript, TypeScript, Python working together\n- ✅ **Real-Time Streaming** - WebSocket integration with live updates  \n- ✅ **AI Integration** - OpenAI, Claude, vision models, and custom AI workflows\n- ✅ **Event-Driven Architecture** - Complex workflows with automatic retry and fault tolerance\n- ✅ **Production Monitoring** - Health checks, uptime monitoring, and intelligent alerting\n- ✅ **Parallel Processing** - Concurrent execution and workload distribution\n- ✅ **Enterprise Integration** - GitHub, Gmail, Trello, Discord, and social media APIs\n\n**🚀 Each example includes:** Complete source code • Step-by-step tutorials • Production deployment guides • Docker configurations\n\n---\n\n## 🌐 Language Support\n\nWrite steps in your preferred language:\n\n| Language       | Status         | Example           |\n| -------------- | -------------- | ----------------- |\n| **JavaScript** | ✅ Stable      | `handler.step.js` |\n| **TypeScript** | ✅ Stable      | `handler.step.ts` |\n| **Python**     | ✅ Stable      | `handler.step.py` |\n| **Ruby**       | 🚧 Beta        | `handler.step.rb` |\n| **Go**         | 🔄 Coming Soon | `handler.step.go` |\n| **Rust**       | 🔄 Coming Soon | `handler.step.rs` |\n\n---\n\n### 💬 **Get Help**\n\n- **📋 Questions**: Use our [Discord community](https://discord.gg/motia)\n- **🐛 Bug Reports**: [GitHub Issues](https://github.com/MotiaDev/motia/issues)\n- **📖 Documentation**: [Official Docs](https://motia.dev/docs)\n- **📰 Blog**: [Motia Blog](https://blog.motia.dev)\n- **🎥 Youtube**: [Motia Youtube](https://www.youtube.com/@motiadev)\n\n### 🤝 **Contributing**\n\nWe welcome contributions! Whether it's:\n\n- 🐛 Bug fixes and improvements\n- ✨ New features and step types\n- 📚 Documentation and examples\n- 🌍 Language support additions\n- 🎨 Workbench UI enhancements\n\nCheck out our [Contributing Guide](https://github.com/MotiaDev/motia/blob/main/CONTRIBUTING.md) to get started.\n\n---\n\n<div align=\"center\">\n\n**🌟 Ready to unify your backend?**\n\n[🚀 **Get Started Now**](https://motia.dev) • [📖 **Read the Docs**](https://motia.dev/docs) • [💬 **Join Discord**](https://discord.com/invite/nJFfsH5d6v)\n\n</div>\n\n---\n\n<div align=\"center\">\n\n[![Star History Chart](https://api.star-history.com/svg?repos=motiadev/motia&type=Date)](https://www.star-history.com/#motiadev/motia&Date)\n\n<sub>Built with ❤️ by the Motia team • **Star us if you find [Motia](https://github.com/orgs/MotiaDev/motia) useful!** ⭐</sub>\n\n</div>\n\n### 🚧 Roadmap\n\nWe have a public roadmap for Motia, you can view it [here](https://github.com/orgs/MotiaDev/projects/2/views/4).\n\nFeel free to add comments to the issues, or create a new issue if you have a feature request.\n\n| Feature                               | Status  | Link                                                 | Description                            |\n| ------------------------------------- | ------- | ---------------------------------------------------- | -------------------------------------- |\n| Python Types                          | Planned | [#485](https://github.com/MotiaDev/motia/issues/485) | Add support for Python types           |\n| Streams: RBAC                         | Planned | [#495](https://github.com/MotiaDev/motia/issues/495) | Add support for RBAC                   |\n| Streams: Workbench UI                 | Planned | [#497](https://github.com/MotiaDev/motia/issues/497) | Add support for Workbench UI           |\n| Queue Strategies                      | Planned | [#476](https://github.com/MotiaDev/motia/issues/476) | Add support for Queue Strategies       |\n| Reactive Steps                        | Planned | [#477](https://github.com/MotiaDev/motia/issues/477) | Add support for Reactive Steps         |\n| Allow cloud configuration             | Planned | [#478](https://github.com/MotiaDev/motia/issues/478) | Add support for cloud configuration    |\n| BYOC: Bring your own Cloud: AWS       | Planned | [#479](https://github.com/MotiaDev/motia/issues/479) | Add support for AWS                    |\n| Point in time triggers                | Planned | [#480](https://github.com/MotiaDev/motia/issues/480) | Add support for Point in time triggers |\n| Workbench plugins                     | Planned | [#481](https://github.com/MotiaDev/motia/issues/481) | Add support for Workbench plugins      |\n| Rewrite our Core in either Go or Rust | Planned | [#482](https://github.com/MotiaDev/motia/issues/482) | Rewrite our Core in either Go or Rust  |\n| Decrease deployment time              | Planned | [#483](https://github.com/MotiaDev/motia/issues/483) | Decrease deployment time               |\n| Built-in database support             | Planned | [#484](https://github.com/MotiaDev/motia/issues/484) | Add support for built-in database      |\n| BYOC: Google Cloud Platform           | Planned | [#486](https://github.com/MotiaDev/motia/issues/486) | Add support for Google Cloud Platform  |\n| BYOC: Microsoft Azure                 | Planned | [#487](https://github.com/MotiaDev/motia/issues/487) | Add support for Microsoft Azure        |\n| BYOC: Vercel                          | Planned | [#488](https://github.com/MotiaDev/motia/issues/488) | Add support for Vercel                 |\n| BYOC: Cloudflare                      | Planned | [#489](https://github.com/MotiaDev/motia/issues/489) | Add support for Cloudflare             |\n| New languages: Go                     | Planned | [#490](https://github.com/MotiaDev/motia/issues/490) | Add support for Go                     |\n| New languages: Rust                   | Planned | [#491](https://github.com/MotiaDev/motia/issues/491) | Add support for Rust                   |\n| New languages: Java                   | Planned | [#492](https://github.com/MotiaDev/motia/issues/492) | Add support for Java                   |\n| New languages: Ruby                   | Planned | [#493](https://github.com/MotiaDev/motia/issues/493) | Add support for Ruby                   |\n| New languages: C#                     | Planned | [#494](https://github.com/MotiaDev/motia/issues/494) | Add support for C#                     |\n| BYOC: Kubernetes                      | Planned | [#496](https://github.com/MotiaDev/motia/issues/496) | Add support for Kubernetes             |\n"
        },
        {
            "url": "https://github.com/OpenBB-finance/OpenBB",
            "language": "Python",
            "description": "Financial data aggregator for humans and AI agents.",
            "readme_summary": "<br />\n<img src=\"https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-light.svg?raw=true#gh-light-mode-only\" alt=\"OpenBB Platform logo\" width=\"600\">\n<img src=\"https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only\" alt=\"OpenBB Platform logo\" width=\"600\">\n<br />\n<br />\n\n[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)\n[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)\n[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)\n<a href=\"https://codespaces.new/OpenBB-finance/OpenBB\">\n  <img src=\"https://github.com/codespaces/badge.svg\" height=\"20\" />\n</a>\n<a target=\"_blank\" href=\"https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&label=PyPI%20Package)](https://pypi.org/project/openbb/)\n\nThe first financial Platform that is open source.\n\nThe OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.\n\nGet started with: `pip install openbb`\n\n```python\nfrom openbb import obb\noutput = obb.equity.price.historical(\"AAPL\")\ndf = output.to_dataframe()\n```\n\nYou can sign up to the [OpenBB Hub](https://my.openbb.co/login) to get the most out of the OpenBB ecosystem.\n\nData integrations available can be found here: <https://docs.openbb.co/platform/reference>\n\n---\n\n## OpenBB Workspace\n\nWhile the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.\n\nIf you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at <https://pro.openbb.co>.\n\n<a href=\"https://pro.openbb.co\">\n  <div align=\"center\">\n  <img src=\"https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png\" alt=\"Logo\" width=\"1000\">\n  </div>\n</a>\n\nData integration:\n\n- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).\n\nAI Agents integration:\n\n- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).\n\n### Integrating OpenBB Platform to the OpenBB Workspace\n\nConnect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.\n\n#### Run OpenBB Platform backend\n\n- Install the packages.\n\n```sh\npip install \"openbb[all]\"\n```\n\n- Start the API server over localhost.\n\n```sh\nopenbb-api\n```\n\nThis will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.\n\nYou can check that it works by going to <http://127.0.0.1:6900>.\n\n#### Integrate OpenBB Platform backend to OpenBB Workspace\n\nSign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:\n\n![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)\n\n1. Go to the \"Apps\" tab\n2. Click on \"Connect backend\"\n3. Fill in the form with:\n   Name: OpenBB Platform\n   URL: <http://127.0.0.1:6900>\n4. Click on \"Test\". You should get a \"Test successful\" with the number of apps found.\n5. Click on \"Add\".\n\nThat's it.\n\n---\n\n<!-- TABLE OF CONTENTS -->\n<details closed=\"closed\">\n  <summary><h2 style=\"display: inline-block\">Table of Contents</h2></summary>\n  <ol>\n    <li><a href=\"#1-installation\">Installation</a></li>\n    <li><a href=\"#2-contributing\">Contributing</a></li>\n    <li><a href=\"#3-license\">License</a></li>\n    <li><a href=\"#4-disclaimer\">Disclaimer</a></li>\n    <li><a href=\"#5-contacts\">Contacts</a></li>\n    <li><a href=\"#6-star-history\">Star History</a></li>\n    <li><a href=\"#7-contributors\">Contributors</a></li>\n  </ol>\n</details>\n\n## 1. Installation\n\nThe OpenBB Platform can be installed as a [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`\n\nor by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.\n\nPlease find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/platform/installation).\n\n### OpenBB Platform CLI installation\n\nThe OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.\n\nIt can be installed by running `pip install openbb-cli`\n\nor by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.\n\nPlease find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).\n\n## 2. Contributing\n\nThere are three main ways of contributing to this project. (Hopefully you have starred the project by now ⭐️)\n\n### Become a Contributor\n\n- More information on our [Contributing Documentation](https://docs.openbb.co/platform/developer_guide/misc/contributing).\n\n### Create a GitHub ticket\n\nBefore creating a ticket make sure the one you are creating doesn't exist already [here](https://github.com/OpenBB-finance/OpenBB/issues)\n\n- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&labels=bug&template=bug_report.md&title=%5BBug%5D)\n- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&labels=enhancement&template=enhancement.md&title=%5BIMPROVE%5D)\n- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&labels=new+feature&template=feature_request.md&title=%5BFR%5D)\n\n### Provide feedback\n\nWe are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.\n\n## 3. License\n\nDistributed under the AGPLv3 License. See\n[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.\n\n## 4. Disclaimer\n\nTrading in financial instruments involves high risks including the risk of losing some, or all, of your investment\namount, and may not be suitable for all investors.\n\nBefore deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.\n\nThe data contained in the OpenBB Platform is not necessarily accurate.\n\nOpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.\n\nAll names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.\n\nOur use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.\n\n## 5. Contacts\n\nIf you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`\n\nIf you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`\n\nAny of our social media platforms: [openbb.co/links](https://openbb.co/links)\n\n## 6. Star History\n\nThis is a proxy of our growth and that we are just getting started.\n\nBut for more metrics important to us check [openbb.co/open](https://openbb.co/open).\n\n[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&type=Date&theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&type=Date&theme=dark)\n\n## 7. Contributors\n\nOpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.\n\n<a href=\"https://github.com/OpenBB-finance/OpenBB/graphs/contributors\">\n   <img src=\"https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB\" width=\"800\"/>\n</a>\n\n<!-- MARKDOWN LINKS & IMAGES -->\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n\n[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge\n[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge\n[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members\n[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge\n[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers\n[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&color=blue\n[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues\n[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&color=yellow\n[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen\n[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&color=success\n[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed\n[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge\n[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555\n[linkedin-url]: https://linkedin.com/in/DidierRLopes\n"
        }
    ],
    "L2 Summary": [
        "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual   Mathematical Reasoning\n\n多模态大型语言模型（MLLMs）在多项任务中展现了出色的能力，但在复杂数学推理方面仍存在不足。现有研究主要集中于数据集构建和方法优化，往往忽视了两个关键方面：全面的知识驱动设计和以模型为中心的数据空间建模。为此，本文提出了We-Math 2.0，这是一个统一系统，集成了结构化的数学知识体系、以模型为中心的数据空间建模以及基于强化学习的训练范式，以全面提升MLLMs的数学推理能力。\n\nWe-Math 2.0的主要贡献包括四个方面：首先，构建了一个名为MathBook的知识系统，包含五个层级的491个知识点和1819条基本原则。其次，开发了MathBook-Standard数据集，确保广泛的概念覆盖和灵活性，并通过双重扩展实现。此外，定义了一个三维难度空间，为每个问题生成7个渐进变体，形成了MathBook-Pro，这是一个用于强健训练的挑战性数据集。第三，提出了MathBook-RL，一个两阶段的强化学习框架，包括冷启动微调，旨在将模型与知识导向的思维链推理对齐，以及渐进对齐强化学习，利用平均奖励学习和动态数据调度实现不同难度水平的渐进对齐。\n\n最后，We-Math 2.0引入了MathBookEval，一个全面的基准测试，涵盖所有491个知识点，并具有多样的推理步骤分布。实验结果表明，MathBook-RL在四个广泛使用的基准测试中表现出色，并在MathBookEval上取得了强劲的结果，显示出在数学推理方面的良好泛化能力。",
        "NextStep-1: Toward Autoregressive Image Generation with Continuous   Tokens at Scale\n\n当前主流的自回归（AR）模型在文本到图像生成中，通常依赖于计算量大的扩散模型来处理连续的图像标记，或者使用向量量化（VQ）来获取离散标记，但这会导致量化损失。本文提出了NextStep-1，这是一个拥有140亿参数的自回归模型，配备了一个1.57亿参数的流匹配头，采用离散文本标记和连续图像标记进行训练，目标是下一个标记的预测。NextStep-1在文本到图像生成任务中实现了自回归模型的最先进性能，展现了在高保真图像合成方面的强大能力。\n\n此外，我们的方法在图像编辑方面也表现出色，突显了我们统一方法的强大和多样性。为了促进开放研究，我们计划向社区发布我们的代码和模型，以便更多的研究者能够使用和改进这一技术。这一创新不仅推动了自回归模型的发展，也为文本到图像生成领域带来了新的可能性，展示了在生成和编辑图像方面的广泛应用潜力。",
        "ToonComposer: Streamlining Cartoon Production with Generative   Post-Keyframing\n\n传统的卡通和动漫制作过程包括关键帧、补间和上色等多个阶段，这些阶段通常需要大量的人工努力。尽管近年来人工智能技术有所进步，但现有的方法往往将这些阶段分开处理，导致错误累积和伪影的产生。例如，补间方法在处理大幅度运动时表现不佳，而上色方法则需要密集的逐帧草图。为了解决这些问题，我们提出了ToonComposer，这是一种将补间和上色统一为单一后关键帧阶段的生成模型。\n\nToonComposer采用稀疏草图注入机制，通过关键帧草图提供精确控制。此外，它还使用空间低秩适配器的卡通适应方法，将现代视频基础模型调整到卡通领域，同时保持其时间先验不变。ToonComposer只需一个草图和一个上色参考帧，就能在稀疏输入下表现出色，同时还支持在任何时间位置使用多个草图，以实现更精确的运动控制。这种双重能力减少了人工工作量，提高了灵活性，使艺术家在实际应用中更加得心应手。\n\n为了评估我们的模型，我们进一步创建了PKBench，这是一个包含人手绘制草图的基准，模拟真实世界的使用场景。我们的评估结果表明，ToonComposer在视觉质量、运动一致性和生产效率方面优于现有方法，提供了一种更优越和灵活的AI辅助卡通制作解决方案。",
        "PRELUDE: A Benchmark Designed to Require Global Comprehension and   Reasoning over Long Contexts\n\n我们介绍了PRELUDE，这是一个用于评估长文本理解能力的基准，任务是判断一个角色的前传故事是否与原著的叙述一致。与现有基准相比，这一任务对整体理解和深度推理的要求更高，因为前传并不是原故事的一部分，评估其合理性通常需要搜索和整合间接相关的信息。实证研究表明，88%的案例需要从叙述的多个部分获取证据。\n\n实验结果突显了这一任务的挑战性：在上下文学习、检索增强生成（RAG）和使用最先进的大型语言模型（LLM）进行领域内训练，以及商业深度研究服务的表现上，模型的表现普遍落后于人类超过15%。进一步的人类研究显示，尽管模型经常能给出正确答案，但其推理过程存在缺陷，导致推理准确性与人类相比存在超过30%的差距。这些发现强调了在长文本理解和推理方面仍有很大的改进空间。",
        "UI-Venus Technical Report: Building High-performance UI Agents with RFT\n\n我们介绍了UI-Venus，这是一种基于多模态大语言模型的原生用户界面代理，能够仅通过截图作为输入。UI-Venus在用户界面定位和导航任务上实现了当前的最佳性能，使用了仅数十万个高质量的训练样本，并通过基于Qwen2.5-VL的强化微调（RFT）进行优化。具体而言，UI-Venus的7B和72B版本在标准定位基准测试Screenspot-V2和Pro上分别获得了94.1%和50.8%、95.3%和61.9%的成绩，超越了包括开源的GTA1和闭源的UI-TARS-1.5在内的先前最佳基线。\n\n为了展示UI-Venus的总结和规划能力，我们还在AndroidWorld这一在线用户界面导航平台上进行了评估，结果显示7B和72B版本的成功率分别为49.1%和65.9%，同样优于现有模型。为实现这一成果，我们引入了精心设计的奖励函数，针对用户界面定位和导航任务，并制定了相应的高效数据清理策略。为了进一步提升导航性能，我们提出了自我演变轨迹历史对齐与稀疏动作增强的方法，这一方法能够优化历史推理轨迹，并平衡稀疏但关键动作的分布，从而实现更连贯的规划和在复杂用户界面任务中的更好泛化能力。\n\n我们的贡献包括发布当前最佳的开源用户界面代理、全面的数据清理协议以及一种新颖的自我演变框架，以提升导航性能，这些都为社区的进一步研究和开发提供了支持。相关代码可在https://github.com/inclusionAI/UI-Venus获取。",
        "Puppeteer: Rig and Animate Your 3D Models\n\n现代互动应用对动态3D内容的需求日益增加，但将静态3D模型转化为动画资产的过程在内容创作中仍然是一个重要瓶颈。尽管最近生成性人工智能在静态3D模型创建方面取得了突破，但绑定和动画制作仍然高度依赖专家的干预。为此，我们提出了Puppeteer，这是一个全面的框架，旨在实现多样化3D对象的自动绑定和动画。\n\n该系统首先通过自回归变换器预测合理的骨骼结构，采用基于关节的标记策略以实现紧凑表示，并结合层次化排序方法和随机扰动，增强双向学习能力。接着，它利用基于注意力的架构推断皮肤权重，该架构结合了拓扑感知的关节注意力，明确编码了基于骨骼图距离的关节间关系。最后，我们通过可微优化的动画管道补充了这些绑定进展，生成稳定且高保真的动画，同时在计算效率上优于现有方法。\n\n在多个基准测试中的广泛评估表明，我们的方法在骨骼预测准确性和皮肤质量方面显著优于当前最先进的技术。该系统能够稳健地处理多样化的3D内容，从专业设计的游戏资产到AI生成的形状，生成的动画时间上连贯，消除了现有方法中常见的抖动问题。",
        "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer\n\n我们提出了STream3R，这是一种新颖的3D重建方法，将点图预测重新定义为仅使用解码器的Transformer问题。现有的多视角重建最先进方法通常依赖于昂贵的全局优化，或是依赖于简单的记忆机制，这些机制在序列长度增加时表现不佳。与此不同，STream3R引入了一种流式框架，利用因果注意力高效处理图像序列，这一思路受到现代语言建模进展的启发。通过从大规模3D数据集中学习几何先验，STream3R在多样化和具有挑战性的场景中表现出良好的泛化能力，尤其是在动态场景中，传统方法往往难以应对。\n\n大量实验表明，我们的方法在静态和动态场景基准测试中均持续超越以往的研究成果。此外，STream3R与大型语言模型（LLM）风格的训练基础设施天然兼容，使得在各种下游3D任务中实现高效的大规模预训练和微调成为可能。我们的结果强调了因果Transformer模型在在线3D感知中的潜力，为流媒体环境中的实时3D理解铺平了道路。更多细节可以在我们的项目页面找到。",
        "A Survey on Diffusion Language Models\n\n扩散语言模型（DLMs）正在迅速崛起，成为一种强大且有前景的替代方案，取代了主流的自回归（AR）模型。DLMs通过迭代去噪过程并行生成标记，具有减少推理延迟和捕捉双向上下文的固有优势，从而实现对生成过程的细粒度控制。近期的进展使得DLMs在速度上实现了数倍的提升，同时在性能上与自回归模型相当，使其成为各种自然语言处理任务的有力选择。\n\n本调查提供了当前DLM领域的全面概述，追溯其发展历程及与其他模型（如自回归和掩蔽语言模型）的关系，涵盖了基础原理和最先进的模型。我们的研究提供了最新的分类法，并深入分析了当前技术，从预训练策略到先进的后训练方法。此外，我们还对DLM推理策略和优化进行了详尽的回顾，包括解码并行性、缓存机制和生成质量的改进。\n\n我们还强调了DLM在多模态扩展方面的最新方法，并阐明了其在各种实际场景中的应用。同时，讨论中也提及了DLMs的局限性和挑战，包括效率、长序列处理和基础设施需求，并概述了未来的研究方向，以推动这一快速发展的领域的进步。",
        "Pass@k Training for Adaptively Balancing Exploration and Exploitation of   Large Reasoning Models\n\n强化学习中的可验证奖励（RLVR）通常采用Pass@1作为奖励，但在探索与利用之间的平衡上存在问题，导致策略倾向于保守行为，从而收敛到局部最优解。因此，确定合适的奖励指标显得尤为重要。尽管以往的研究中使用了Pass@k进行评估，但其与RLVR中大语言模型（LLM）探索能力的关系却未得到充分关注。为此，我们首先使用Pass@k作为奖励来训练策略模型（即“Pass@k训练”），并观察其在探索能力上的提升。\n\n接下来，我们推导出Pass@k训练的优势的解析解，从而形成一个高效且有效的过程。我们的分析表明，探索与利用并非固有的对立目标，反而可以相互促进。此外，基于解析推导的Pass@k训练本质上涉及直接设计优势函数。受到这一发现的启发，我们初步探索了RLVR中的优势设计，显示出良好的结果，并强调了未来研究的潜在方向。这些研究不仅为RLVR提供了新的视角，也为优化策略的设计提供了理论基础，推动了强化学习领域的进一步发展。",
        "HumanSense: From Multimodal Perception to Empathetic Context-Aware   Responses through Reasoning MLLMs\n\n多模态大型语言模型（MLLMs）在实现人类般的互动方面展现出巨大潜力，但由于缺乏针对人本场景的细致评估框架，进展受到限制。这些框架需要涵盖对复杂人类意图的理解以及提供富有同情心和上下文意识的回应。为此，我们提出了HumanSense，这是一个全面的基准，旨在评估MLLMs的人本感知和互动能力，特别关注对扩展多模态上下文的深刻理解和合理反馈的形成。\n\n我们的评估结果显示，领先的MLLMs在高级互动任务上仍有相当大的改进空间。通过将视觉输入与音频和文本信息相结合，可以显著提升模型的表现，而全模态模型在这些任务上表现出优势。此外，我们认为，适当的反馈源于对对话者需求和情感的上下文分析，而推理能力则是解锁这一反馈的关键。因此，我们采用多阶段、模态渐进的强化学习方法来增强全模态模型的推理能力，从而在评估结果上取得显著提升。\n\n我们还观察到，成功的推理过程展现出高度一致的思维模式。通过设计相应的提示，我们也在无训练的情况下提升了非推理模型的表现。这些研究成果为进一步推动多模态大型语言模型的应用和发展提供了重要的理论基础和实践指导。",
        "Processing and acquisition traces in visual encoders: What does CLIP   know about your camera?\n\n以往的研究主要集中在视觉编码器对图像变换和损坏的鲁棒性，尤其是在训练过程中未见过的情况下。这种情况会在测试时引入分布偏移，通常导致性能下降。研究的重点多集中在严重的损坏上，这些损坏在强烈应用时会扭曲进行准确语义预测所需的有用信号。然而，我们采取了不同的视角，分析了图像获取过程和变换的参数，这些参数可能是微妙的，甚至对人眼不可察觉。我们的研究发现，这些参数在学习的视觉表征中被系统性地编码，并且可以轻松恢复。\n\n更引人注目的是，这些参数的存在对语义预测有着深远的影响，可能是积极的也可能是消极的。这种影响取决于语义标签与这些基于获取或处理的标签之间是否存在强相关性或反相关性。通过这种分析，我们揭示了图像获取过程中的细微变化如何影响视觉编码器的性能，强调了在实际应用中考虑这些因素的重要性。我们的代码和数据已公开，供研究者进一步探索这一领域。",
        "From Black Box to Transparency: Enhancing Automated Interpreting   Assessment with Explainable AI in College Classrooms\n\n近年来，机器学习的进步引发了对自动化口译质量评估的关注。然而，现有研究在语言使用质量的检验上存在不足，模型效果因数据稀缺和不平衡而不尽如人意，同时对模型预测的解释性也缺乏足够的关注。为了解决这些问题，我们提出了一种多维建模框架，结合了特征工程、数据增强和可解释的机器学习。该方法优先考虑可解释性，避免“黑箱”预测，采用与构建相关的透明特征，并进行Shapley值（SHAP）分析。\n\n我们的研究结果在一个新的英汉连续口译数据集上显示出强大的预测性能，发现BLEURT和CometKiwi评分是评估忠实度的最强预测特征，而与停顿相关的特征则与流畅度密切相关，中文特有的短语多样性指标则用于语言使用的评估。总体而言，通过强调可解释性，我们提供了一种可扩展、可靠且透明的替代传统人工评估的方法。这种方法不仅能够为学习者提供详细的诊断反馈，还支持自我调节学习的优势，而这些是单纯依赖自动评分所无法实现的。",
        "When Explainability Meets Privacy: An Investigation at the Intersection   of Post-hoc Explainability and Differential Privacy in the Context of Natural   Language Processing\n\n在可信自然语言处理（NLP）的研究中，解释性和隐私保护成为了两个重要的研究领域。尽管近年来对可解释性和隐私保护的NLP研究兴趣显著增加，但两者交叉领域的研究仍然不足。这使得我们对实现可解释性与隐私保护是否可能存在较大空白，或者两者是否存在矛盾的理解不够深入。本研究通过实证调查，探讨了NLP中的隐私与可解释性之间的权衡，主要依托于差分隐私（DP）和事后解释性等流行方法。\n\n我们的研究结果揭示了隐私与可解释性之间复杂的关系，这种关系受到多个因素的影响，包括下游任务的性质以及文本隐私化和解释性方法的选择。在这一过程中，我们强调了隐私与可解释性共存的潜力，并总结出一系列实用建议，以指导未来在这一重要交叉领域的研究工作。这些建议旨在帮助研究者更好地理解和应对隐私与可解释性之间的挑战，从而推动NLP技术的可信性和实用性发展。",
        "https://github.com/coleam00/Archon\n\nArchon OS目前处于测试阶段，旨在为AI编码助手提供知识和任务管理的核心支持。作为一个命令中心，Archon为用户提供了一个简洁的界面，以管理项目的知识、上下文和任务，同时为AI助手提供了一个模型上下文协议（MCP）服务器，使其能够共享相同的知识和任务。用户可以将多个AI工具连接到Archon，利用其智能搜索、任务管理和实时更新等功能，从而提升AI驱动编码的效率。\n\nArchon的设计理念是替代之前的agenteer，成为一个更强大的工具。无论是新项目还是现有代码库，Archon的知识和任务管理能力都能显著改善输出效果。用户可以通过GitHub讨论区参与交流，贡献代码或反馈问题，帮助团队不断改进Archon。\n\n在快速启动方面，用户需要安装Docker和Supabase，并获取OpenAI API密钥。设置过程包括克隆代码库、配置环境变量、设置数据库以及启动服务。Archon的架构采用微服务结构，确保各个服务之间的独立性和灵活性，支持实时协作和多用户操作。\n\nArchon的核心功能包括智能网页爬虫、文档处理、代码示例提取和向量搜索等知识管理工具，以及与AI助手的无缝集成。项目和任务管理功能允许用户以层次化的方式组织工作，并通过AI助手生成项目需求和任务。此外，Archon还支持实时更新和健康监测，确保系统的稳定性和高效性。\n\n总之，Archon OS为AI编码助手提供了一个强大的知识和任务管理平台，旨在通过集成多种功能和服务，提升开发者的工作效率和协作体验。",
        "https://github.com/emcie-co/parlant\n\nParlant是一种新型的AI代理开发框架，旨在解决开发者在构建生产级AI代理时常遇到的问题，如系统提示被忽视、关键时刻的错误响应以及无法一致处理边缘案例等。传统的AI开发方法往往依赖复杂的系统提示和不确定的行为，而Parlant则通过自然语言定义规则，确保代理遵循这些规则，从而实现可预测和一致的行为。\n\n使用Parlant，开发者可以在短短60秒内启动代理。通过简单的代码，用户可以定义代理的行为和响应，确保其在实际应用中能够有效地满足用户需求。Parlant的设计理念是将规则的定义与自然语言结合，使得开发过程更加直观和高效。\n\n该框架特别适用于金融服务、医疗保健、电子商务和法律科技等领域，具备合规性设计、风险管理、客户服务自动化等功能。Parlant还提供了一系列企业级特性，如对话旅程引导、动态规则匹配、可靠的工具集成和深入的对话分析，帮助开发者不断优化代理的响应。\n\n目前，已有超过5000名开发者在使用Parlant，许多金融机构、医疗提供者和法律公司等企业已将其应用于生产环境。开发者们对Parlant的评价普遍积极，认为其是一个优雅且高效的对话AI框架，极大地简化了开发流程。\n\n总之，Parlant为AI代理的开发提供了一种全新的解决方案，确保代理能够在真实环境中稳定运行，满足用户的实际需求。",
        "https://github.com/DataExpert-io/data-engineer-handbook\n\n该项目是一个数据工程学习资源的汇总库，旨在帮助用户成为优秀的数据工程师。对于初学者，建议从2024年数据工程入门路线图开始学习，此外还提供了为期六周的免费YouTube训练营，涵盖了软件需求、项目实践、面试技巧等内容。用户可以通过项目部分获取更多实践案例，通过面试部分获取面试建议，通过书籍部分找到高质量的参考书籍，并加入相关社区以获取更多支持。\n\n资源部分列出了超过25本书籍，其中推荐的三本书包括《数据工程基础》、《设计数据密集型应用》和《设计机器学习系统》。此外，还推荐了10个数据工程和机器学习相关的社区，供用户加入以拓展人脉和获取信息。项目还列出了多家相关公司的信息，涵盖了数据湖、数据仓库、数据质量等多个领域，帮助用户了解行业现状和技术趋势。\n\n在博客、白皮书和社交媒体方面，项目提供了多家公司的数据工程博客链接、重要的白皮书以及数据工程领域的社交媒体账号，便于用户获取最新的行业动态和技术分享。项目还推荐了一些优秀的播客和通讯，帮助用户通过不同的媒介持续学习。\n\n最后，项目还提供了课程和认证信息，涵盖了多个在线学习平台和认证课程，帮助用户在数据工程领域获得专业资格和技能提升。整体而言，该项目为希望进入数据工程领域的学习者提供了全面的资源和支持。",
        "https://github.com/rasbt/LLMs-from-scratch\n\n该项目旨在从零开始使用PyTorch实现一个类似ChatGPT的大型语言模型（LLM），并提供了相关的代码和教程。该代码库是书籍《从零开始构建大型语言模型》的官方代码库，书中详细讲解了大型语言模型的工作原理，逐步指导读者创建自己的LLM，涵盖了每个阶段的清晰文本、图示和示例。书中所描述的训练和开发方法与创建大型基础模型的方式相似，同时也提供了加载更大预训练模型权重以进行微调的代码。\n\n读者需要具备扎实的Python编程基础，了解深度神经网络的概念将有助于理解LLM的构建。书中使用PyTorch实现代码，尽管不要求精通PyTorch，但熟悉其基本知识会有所帮助。书中还提供了附录，介绍了PyTorch的基础知识。代码设计为能够在普通笔记本电脑上运行，并能自动利用可用的GPU，确保广泛的受众能够参与学习。\n\n此外，书中每章都包含多个练习，解决方案汇总在附录中，读者还可以下载免费的170页PDF文件进行自测。项目还提供了额外的材料和视频课程，帮助读者更深入地理解内容。对于有兴趣的读者，项目欢迎反馈和讨论，但由于代码与书籍内容紧密相关，暂不接受扩展内容的贡献。\n\n如果读者在研究中发现该书或代码有用，建议引用该书籍。整体而言，该项目为希望深入了解和构建大型语言模型的学习者提供了全面的资源和指导。",
        "https://github.com/enescingoz/awesome-n8n-templates\n\n该项目旨在通过提供一系列n8n自动化模板来提升工作流程的自动化效率。这些模板可以快速连接用户常用的应用程序，如Gmail、Telegram、Google Drive和Slack，利用人工智能技术实现即用型自动化，帮助用户节省时间、提高生产力。项目的文档中包含了从互联网收集的多种n8n自动化模板，旨在简化用户的任务和工作流程，使其更容易发现和使用现成的自动化解决方案。\n\n项目中包含的模板涵盖了多个领域，包括社交媒体自动化、电子邮件管理、数据处理和分析等。例如，用户可以使用模板自动翻译和发布Twitter线程，或通过Gmail自动标记和分类邮件。此外，项目还提供了与Telegram和Google Drive的集成，用户可以通过AI助手与这些平台进行交互，提升工作效率。\n\n需要注意的是，所有模板均为在线收集，项目作者不对使用过程中可能出现的问题或损失承担责任。用户在使用这些模板时应自行承担风险。项目鼓励用户参与贡献新的模板或建议新类别，以进一步丰富资源库。\n\n总之，该项目为希望通过自动化提升工作效率的用户提供了丰富的工具和资源，用户只需简单几步即可开始使用n8n进行自动化操作。",
        "https://github.com/PixiEditor/PixiEditor\n\nPixiEditor是一款通用的2D编辑器，旨在为用户提供满足各种2D需求的工具和功能。用户可以利用PixiEditor创建精美的游戏精灵、动画、编辑图像以及设计标志，所有这些功能都集成在一个直观且熟悉的界面中。该软件的2.0版本默认提供三种工具集，分别是像素艺术工具、基础绘画工具和矢量工具，用户可以在同一画布上混合使用这些工具，支持导出为多种格式，如png、jpg、svg、gif和mp4等。\n\n在动画方面，PixiEditor 2.0引入了时间轴和动画功能，用户可以逐帧创建动画，或使用节点来动画自定义着色器。未来的版本计划支持关键帧动画与矢量结合。节点渲染系统是该软件强大功能的核心，所有图层、效果和层结构都以节点的形式存在，用户可以自由定制图像，创造程序化艺术和动画。\n\n此外，PixiEditor还提供了从源代码构建的指南，鼓励用户参与贡献和协作。对于遇到问题的用户，PixiEditor团队也提供了帮助和支持。总之，PixiEditor是一个功能强大且灵活的2D编辑工具，适合各种创作需求。",
        "https://github.com/immich-app/immich\n\n该项目是一个高性能的自托管照片和视频管理解决方案，正在积极开发中，用户需注意可能存在的错误和重大变更。项目不建议作为唯一的照片和视频存储方式，用户应遵循3-2-1备份策略以确保数据安全。项目的主要文档和安装指南可在官方网站找到。\n\n该解决方案支持多种语言，提供了丰富的功能，包括在移动端和网页上上传和查看视频及照片、自动备份、避免重复资产、选择性备份相册、下载本地设备、支持多用户、共享相册、支持原始格式、元数据查看、以及基于元数据和对象的搜索等。移动应用还具备后台备份、虚拟滚动、OAuth支持等功能。\n\n用户可以通过提供的演示链接体验该应用，演示账户的登录信息也已公开。项目的文档中详细列出了功能特性，并提供了安装和使用的相关指导。用户还可以查看项目的开发路线图和贡献方式，参与到项目的进一步发展中。\n\n此外，项目还具备面部识别、记忆功能、离线支持等先进特性，旨在为用户提供全面的照片和视频管理体验。整体而言，该项目为用户提供了一个灵活且功能强大的工具，适合个人和团队使用。",
        "https://github.com/Shubhamsaboo/awesome-llm-apps\n\n该项目是一个汇集了众多优秀大型语言模型（LLM）应用的集合，主要利用OpenAI、Anthropic、Gemini等模型以及开源模型如DeepSeek、Qwen和Llama，支持本地运行。项目旨在展示LLM在各个领域的实际应用，包括代码库、电子邮件等，鼓励用户探索结合AI代理、代理团队、MCP和RAG的应用。\n\n项目中包含了多种AI代理的示例，包括初级和高级代理，如AI博客转播代理、AI数据分析代理、AI医疗影像代理等。此外，还有自主游戏代理、多个代理团队的协作应用，以及语音AI代理和MCP AI代理等多种类型的应用。RAG（检索增强生成）技术也被广泛应用于多个项目中，提供了多种检索和生成的组合方式。\n\n用户可以通过克隆项目库、进入特定项目目录并安装所需依赖来快速上手。同时，项目鼓励社区贡献，欢迎用户提出新想法或改进建议，并通过GitHub提交问题或拉取请求。项目的目标是促进开源生态系统的发展，让更多人参与到LLM驱动的应用开发中。\n\n总之，该项目不仅提供了丰富的LLM应用实例，还为开发者提供了学习和贡献的机会，推动了AI技术的普及与应用。",
        "https://github.com/MotiaDev/motia\n\nMotia是一个现代化的后端框架，旨在解决当前后端开发中的碎片化问题。传统的后端开发通常涉及多个框架和工具，例如API、后台作业、队列和AI代理等，导致开发过程复杂且难以管理。Motia通过将这些功能统一到一个系统中，提供了共享的可观察性和开发体验，使得后端开发变得更加简洁高效。开发者可以在同一个工作流中使用JavaScript、TypeScript和Python等多种语言，极大地简化了开发过程。\n\nMotia的核心概念是“步骤”（Step），每个步骤代表一个独立的入口点，可以是API、后台作业、定时任务或AI代理。通过这种方式，开发者可以在同一个项目中灵活地使用不同的编程语言，同时共享状态和数据。Motia还提供了内置的可观察性工具，支持完整的端到端追踪、结构化日志记录和状态可视化，帮助开发者快速调试和监控应用。\n\n使用Motia，开发者可以在不到60秒的时间内启动一个新项目，并通过简单的命令创建REST API、处理后台任务或调度定时作业。Motia的工作台提供了可视化的界面，方便开发者实时构建、测试和观察后端应用。该框架还支持事件驱动架构，允许开发者通过发出和订阅事件来构建复杂的工作流。\n\nMotia的设计理念是消除后端开发中的复杂性，提供一个统一的运行时环境，使得开发者能够专注于业务逻辑而非基础设施。通过Motia，开发者可以实现快速开发、灵活扩展和简化部署，适应现代软件开发的需求。总之，Motia为后端开发提供了一种全新的解决方案，旨在提升开发效率和系统的可维护性。",
        "https://github.com/OpenBB-finance/OpenBB\n\nOpenBB平台是一个开源的金融数据聚合工具，旨在为用户和人工智能代理提供丰富的金融数据访问，包括股票、期权、加密货币、外汇、宏观经济和固定收益等。用户可以通过简单的Python命令安装和使用该平台，获取所需的金融数据。OpenBB还提供了多种扩展功能，以满足不同用户的需求。\n\n该平台的接口支持Python和命令行界面（CLI），用户可以通过OpenBB工作区实现数据可视化和AI代理的集成。用户只需按照简单的步骤将OpenBB平台与工作区连接，即可开始使用。OpenBB工作区允许用户在一个集中的环境中管理和分析数据，提升用户体验。\n\n安装OpenBB平台非常简单，用户可以通过PyPI包或直接克隆代码库来完成安装。此外，OpenBB还鼓励用户参与贡献，提供反馈或报告问题，以帮助项目不断改进。平台的使用涉及一定的风险，用户在进行金融交易前应充分了解相关风险和成本，并根据自身的投资目标和风险承受能力做出明智决策。\n\nOpenBB平台在不断发展壮大，欢迎更多用户加入这个开源社区。用户可以通过社交媒体或电子邮件与团队联系，获取更多信息或寻求支持。总之，OpenBB致力于通过开放的金融数据平台，推动金融行业的创新与变革。"
    ],
    "L1 Summary": "- We-Math 2.0: 该系统旨在提升多模态大型语言模型在数学推理方面的能力，集成了结构化知识体系和强化学习训练框架。通过构建MathBook知识系统和MathBook-RL强化学习方法，实验结果显示其在数学推理任务中表现优异。\n\n- NextStep-1: 这是一个140亿参数的自回归模型，专注于文本到图像生成，采用离散文本和连续图像标记进行训练。该模型在图像生成和编辑任务中展现出强大的性能，并计划向社区发布代码和模型以促进研究。\n\n- ToonComposer: 该生成模型将卡通制作中的补间和上色过程统一为后关键帧阶段，减少了人工工作量。通过稀疏草图注入机制和空间低秩适配器，ToonComposer在视觉质量和生产效率上优于现有方法。\n\n- PRELUDE: 这是一个评估长文本理解能力的基准，要求判断角色前传故事与原著叙述的一致性。实验表明，当前模型在这一任务上表现不佳，强调了长文本理解和推理的改进空间。\n\n- UI-Venus Technical Report: 该用户界面代理通过截图作为输入，在定位和导航任务上实现了最佳性能。引入了强化微调和自我演变方法，提升了导航能力，并发布了开源代码供社区使用。\n\n- Puppeteer: 这是一个自动绑定和动画制作的框架，旨在简化3D内容创作过程。通过自回归变换器和基于注意力的架构，Puppeteer在骨骼预测和动画质量上显著优于现有技术。\n\n- STream3R: 该方法将3D重建问题重新定义为仅使用解码器的Transformer问题，利用因果注意力高效处理图像序列。实验结果显示其在动态场景中的表现优于传统方法，并兼容大型语言模型的训练基础设施。\n\n- A Survey on Diffusion Language Models: 本调查提供了扩散语言模型的全面概述，分析了其与自回归模型的关系及应用。强调了DLM在多模态扩展和实际场景中的潜力，同时讨论了其局限性和未来研究方向。\n\n- Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models: 该研究探讨了在强化学习中使用Pass@k作为奖励的优势，强调探索与利用的相互促进。通过解析推导，提出了优化策略设计的新视角。\n\n- HumanSense: 这是一个评估多模态大型语言模型人本感知和互动能力的基准，强调对复杂人类意图的理解。研究表明，结合视觉和音频输入可以显著提升模型表现，并提出了增强推理能力的方法。\n\n- Processing and acquisition traces in visual encoders: 该研究分析了图像获取过程中的参数如何影响视觉编码器的性能。发现这些参数在学习的视觉表征中被编码，并对语义预测有深远影响。\n\n- From Black Box to Transparency: 该研究提出了一种多维建模框架，结合可解释的机器学习和特征工程，提升自动化口译质量评估的透明性。结果显示该方法在评估忠实度和流畅度方面表现优异。\n\n- When Explainability Meets Privacy: 该研究探讨了自然语言处理中的隐私与可解释性之间的权衡，揭示了两者之间复杂的关系。总结了一系列实用建议，以指导未来在这一交叉领域的研究。\n\n- Archon: 这是一个为AI编码助手提供知识和任务管理的核心支持平台，旨在提升开发效率。用户可以通过简单的设置连接多个AI工具，利用智能搜索和任务管理功能。\n\n- Parlant: 该框架通过自然语言定义规则，解决AI代理开发中的一致性问题。开发者可以快速启动代理，并确保其在实际应用中满足用户需求，适用于多个行业。\n\n- Data Engineer Handbook: 这是一个数据工程学习资源的汇总库，提供了入门路线图、实践案例和社区支持。项目旨在帮助用户提升数据工程技能，了解行业动态。\n\n- LLMs from Scratch: 该项目提供了从零开始使用PyTorch实现大型语言模型的代码和教程，适合希望深入了解LLM的学习者。书中详细讲解了模型构建过程，并提供了练习和额外材料。\n\n- Awesome n8n Templates: 该项目提供了一系列n8n自动化模板，旨在提升工作流程的自动化效率。用户可以快速连接常用应用程序，利用现成的自动化解决方案。\n\n- PixiEditor: 这是一个通用的2D编辑器，支持用户创建游戏精灵、动画和图像设计。软件提供多种工具集，用户可以在同一画布上灵活使用，支持多种格式导出。\n\n- Immich: 该项目是一个高性能的自托管照片和视频管理解决方案，支持多种功能如自动备份和元数据搜索。用户需遵循数据安全策略，并可参与项目的进一步发展。\n\n- Awesome LLM Apps: 该项目汇集了众多大型语言模型应用，展示了LLM在各个领域的实际应用。鼓励用户探索和贡献新想法，推动开源生态系统的发展。\n\n- Motia: 这是一个现代化的后端框架，旨在简化后端开发过程。通过统一的系统，开发者可以灵活使用多种语言，提升开发效率和系统可维护性。\n\n- OpenBB: 该平台是一个开源金融数据聚合工具，提供丰富的金融数据访问。用户可以通过简单的命令获取数据，并参与项目的改进和发展。"
}